<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[基于KotlinMultiPlatform构建跨平台项目]]></title>
    <url>%2F2019%2F06%2F06%2F%E5%9F%BA%E4%BA%8EKotlinMultiPlatform%E6%9E%84%E5%BB%BA%E8%B7%A8%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[前言当下市场上的跨端解决方案, 不管使用的是React Native, Flutter 还是Weex, 常见的项目组成是, 业务UI界面由上述框架解决, 而涉及不论是性能问题, 还是平台通用共享逻辑问题, 我们更侧重于原生开发, 而这一块我们必不可免需要至少两个原生开发同学通过沟通和开发统一Native层的功能逻辑, 而针对于这些原生通用代码, 现有常见的解决方案还是主要通过传统的C/C++来解决. 而现在, JetBrains的Kotlin/Native为我们提供了另外一个解决方案. 什么是Kotlin/Native Kotlin/Native 是一种将 Kotlin 代码编译为无需虚拟机就可运行的原生二进制文件的技术。 它是一个基于 LLVM 的 Kotlin 编译器后端以及 Kotlin 标准库的原生实现。 LLVM是一种编译器基础结构，它基于具有可重新定位性的三阶段设计的概念。简单来说，这意味着可以为具有LLVM后端编译器的任何目标编译具有前端LLVM编译器的任何语言。(Swift可以编译Android工程也是基于LLVM实现) Kotlin/Native 支持以下平台： iOS（arm32、 arm64、 模拟器 x86_64） MacOS（x86_64） Android（arm32、arm64） Windows（mingw x86_64、x86） Linux（x86_64、 arm32、 MIPS、 MIPS 小端次序、树莓派） WebAssembly（wasm32） Kotlin支持两种与Native的互操作行为方式: 通过Kotlin/Native内包含的cinterop tool通过自创建def文件解析C头文件, 快速生成与Kotlin需要交互的所有内容(包括类型, 函数, 常量) 直接使用现有库的互操作, 其中包括 静态或动态 C 语言库 C 语言、 Swift 以及 Objective-C 框架 当前POSIX、 gzip、 OpenGL、 Metal、 Foundation 以及许多其他流行库与 Apple 框架都已预先导入并作为 Kotlin/Native 库包含在编译器包中 Kotlin MultiPlatform(KMP)在Kotlin/Native(Beta)1.3.30版本开始, Kotlin/Native是作为KMP中的目标平台之一, 当前我们可以基于KMP构建我们的跨端共享代码项目 在KMP DSL中我们有几个基础概念需要了解 Target 它表示KMP工程的产出变体, 根据配置可生成对应的android库, ios的framework, jvm应用等等.. Present 用来定义对应Target的预配置, 譬如可通过fromPreset(&lt;PRESET_KIND&gt;, &lt;TARGET_NAME&gt;)设置, PRESET_KIND需要使用当前存在的值, 当前目标预设值如下: androidNativeArm32 and androidNativeArm64 for Android NDK; android for Android iosArm32, iosArm64, iosX64 for iOS; linuxArm32Hfp, linuxMips32, linuxMipsel32, linuxX64 for Linux; macosX64 for MacOS; mingwX64 for Windows; wasm32 for WebAssembly. 同时, TARGET_NAMAE值如下: jvm for Kotlin/JVM. js for Kotlin/JS; android for Android applications and libraries. (AGP插件的引用需要在targets生成之前) 上手试验开发前置准备我们可以使用Android Studio或者IntelliJ IDEA进行开发, 对应IDE需要安装Kotlin插件1.3.21及以上版本. 安装XCode(跑ios工程), 同时Gradle版本需要在4.7以上, 另需要安装Xcode 共享代码模块的新建创建Kotlin-MultiPlatform工程, 我们需要创建一个基于Gradle构建工程, 这个原生Android工程就可以满足, 然后我们通过引用kotlin-multiplatform`插件进行部署工作. 通过kotlin.targets设置目标平台, 下方代码是设置ios平台和android平台, 当然也可以设置jvm和js端. 1234567891011121314kotlin &#123; targets &#123; final def iOSTarget = System.getenv('SDK_NAME')?.startsWith("iphoneos") \ ? presets.iosArm64 : presets.iosX64 fromPreset(iOSTarget, 'ios') &#123; binaries &#123; framework(project.name) &#125; &#125; fromPreset(presets.android, 'android') &#125;&#125; 不同targets依赖的三方库可能不同, 可以通过kotlin.sourceSets设置. 12345678910111213141516171819202122232425262728293031323334kotlin&#123; sourceSets &#123; commonMain &#123; dependencies&#123; api 'org.jetbrains.kotlin:kotlin-stdlib-common' implementation "io.ktor:ktor-client-core:$ktor_version" implementation "io.ktor:ktor-client-json:$ktor_version" implementation "org.jetbrains.kotlinx:kotlinx-coroutines-core-common:$coroutines_version" // implementation "org.jetbrains.kotlinx:kotlinx-serialization-runtime-common:$serializer_version" &#125; &#125; androidMain &#123; dependencies &#123; api 'org.jetbrains.kotlin:kotlin-stdlib' implementation "org.jetbrains.kotlinx:kotlinx-coroutines-core:$coroutines_version" implementation "org.jetbrains.kotlinx:kotlinx-coroutines-android:$coroutines_version" // implementation "org.jetbrains.kotlinx:kotlinx-serialization-runtime:$serializer_version" implementation "io.ktor:ktor-client-android:$ktor_version" &#125; &#125; iosMain&#123; dependencies&#123; implementation "org.jetbrains.kotlinx:kotlinx-coroutines-core-native:$coroutines_version" implementation "io.ktor:ktor-client-ios:$ktor_version" implementation "io.ktor:ktor-client-core-native:$ktor_version" implementation "io.ktor:ktor-client-json-native:$ktor_version" // implementation "org.jetbrains.kotlinx:kotlinx-serialization-runtime-native:$serializer_version" &#125; &#125; &#125;&#125; 同时不同源集工程目录构建如下图, 需要注意的是, 源集的命名需要遵循KMP的强加的特定命名, 它是根据target + compilation来命名的, 如果我们这里需要一个ios特性的测试模块, 那么新增的源集命名应该为iosTest expect / actual当两端实现存在各自差异化代码时, 可以通过expect/actual关键字进行表示, expect需要在common中进行声明, 它可以被理解为接口的声明, 不过它不仅能修饰类, 也可以修饰单独的对象.actual修饰对应的实现. 如下方代码, 线程调度在不同平台上的实现是不同的, 所以我们需要指定对应Dispatcher 12// in commonMain Module Dispatcher.ktinternal expect val applicationDispatcher: CoroutineDispatcher 12// in androidMain Module Dispatcher.ktinternal actual val applicationDispatcher: CoroutineDispatcher = Dispatchers.Default 12345678910// in iosMain Module Dispatcher.ktinternal actual val applicationDispatcher: CoroutineDispatcher = NsQueueDispatcher(dispatch_get_main_queue())internal class NsQueueDispatcher(private val dispatchQueue: dispatch_queue_t) : CoroutineDispatcher() &#123; override fun dispatch(context: CoroutineContext, block: Runnable) &#123; dispatch_async(dispatchQueue) &#123; block.run() &#125; &#125;&#125; 同样, 像基于各端自身特性的API的兼容, 我们基本都需要通过expect/actual进行分别实现. ios上的互操作在执行build后, 构建目录下会生成供ios使用的静态库, 然后通过XCode新建工程, 配置引入对应的framework, 并在构建流程上添加对应的脚本配置, 使其编译的时候可以自动通过gradle编译kt库更新framework.(由于我们的Demo工程是基于RN框架的, 所以在通过react-native init后我们在对应生成的ios工程下直接配置即可) 我们通过引用component, 可以直接调到kt的编译生成的二进制代码. 1234567891011121314151617181920RCT_EXPORT_METHOD (requestWith:(NSString *)url params:(NSString *)params resolver:(RCTPromiseResolveBlock)resolve rejecter:(RCTPromiseRejectBlock)reject)&#123; ComponentBaseHttpClient *o = [ComponentBaseHttpClient new]; [o requestRequestUrl:url block:^ComponentKotlinUnit * _Nonnull(ComponentKtor_client_coreHttpRequestBuilder * _Nonnull httpBuilder) &#123; return [ComponentKotlinUnit unit]; &#125; success:^ComponentKotlinUnit * _Nonnull(NSString * _Nonnull responce) &#123; resolve(responce); return [ComponentKotlinUnit unit]; &#125; failure:^ComponentKotlinUnit * _Nonnull(ComponentKotlinThrowable * _Nullable e) &#123; if(e != nil)&#123; reject(@&quot;1&quot;, e.message, nil); &#125; return [ComponentKotlinUnit unit]; &#125;]; &#125; 这样就实现了双端底层的代码共享. 其他多平台三方库的支持 序列化 Kotlin Serialization IO Kotlin io 网络 Ktor 数据库 sqldelight 学习成本 Kotlin语言学习 双端一定开发基础 多平台库的学习 引用 ktor官方文档 kotlin官方社区 Swift for Android Interop Kotlin Native Github]]></content>
      <categories>
        <category>新框架学习</category>
      </categories>
      <tags>
        <tag>kotlin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入了解TransformApi]]></title>
    <url>%2F2019%2F04%2F24%2F%E6%B7%B1%E5%85%A5%E4%BA%86%E8%A7%A3TransformApi%2F</url>
    <content type="text"><![CDATA[前言其实Transform API在一个android工程的打包流程中作用非常大, 像是我们熟知的混淆处理, 类文件转dex文件的处理, 都是通过Transform API去完成的.本篇内容主要围绕Transform做展开: Transform API的使用及原理 字节码处理框架ASM使用技巧 Transform API在应用工程上的使用摸索 Transform的使用及原理什么是Transform自从1.5.0-beta1版本开始, android gradle插件就包含了一个Transform API, 它允许第三方插件在编译后的类文件转换为dex文件之前做处理操作.而使用Transform API, 我们完全可以不用去关注相关task的生成与执行流程, 它让我们可以只聚焦在如何对输入的类文件进行处理 Transform的使用Transform的注册和使用非常易懂, 在我们自定义的plugin内, 我们可以通过android.registerTransform(theTransform)或者android.registerTransform(theTransform, dependencies).就可以进行注册.123456class DemoPlugin: Plugin&lt;Project&gt; &#123; override fun apply(target: Project) &#123; val android = target.extensions.findByType(BaseExtension::class.java) android?.registerTransform(DemoTransform()) &#125;&#125; 而我们自定义的Transform继承于com.android.build.api.transform.Transform, 具体我们可以看javaDoc, 以下代码是比较常见的transform处理模板12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class DemoTransform: Transform() &#123; /** * transform 名字 */ override fun getName(): String = "DemoTransform" /** * 输入文件的类型 * 可供我们去处理的有两种类型, 分别是编译后的java代码, 以及资源文件(非res下文件, 而是assests内的资源) */ override fun getInputTypes(): MutableSet&lt;QualifiedContent.ContentType&gt; = TransformManager.CONTENT_CLASS /** * 是否支持增量 * 如果支持增量执行, 则变化输入内容可能包含 修改/删除/添加 文件的列表 */ override fun isIncremental(): Boolean = false /** * 指定作用范围 */ override fun getScopes(): MutableSet&lt;in QualifiedContent.Scope&gt; = TransformManager.SCOPE_FULL_PROJECT /** * transform的执行主函数 */ override fun transform(transformInvocation: TransformInvocation?) &#123; transformInvocation?.inputs?.forEach &#123; // 输入源为文件夹类型 it.directoryInputs.forEach &#123;directoryInput-&gt; with(directoryInput)&#123; // TODO 针对文件夹进行字节码操作 val dest = transformInvocation.outputProvider.getContentLocation( name, contentTypes, scopes, Format.DIRECTORY ) file.copyTo(dest) &#125; &#125; // 输入源为jar包类型 it.jarInputs.forEach &#123; jarInput-&gt; with(jarInput)&#123; // TODO 针对Jar文件进行相关处理 val dest = transformInvocation.outputProvider.getContentLocation( name, contentTypes, scopes, Format.JAR ) file.copyTo(dest) &#125; &#125; &#125; &#125;&#125; 每一个Transform都声明它的作用域, 作用对象以及具体的操作以及操作后输出的内容. 作用域通过Transform#getScopes方法我们可以声明自定义的transform的作用域, 指定作用域包括如下几种 QualifiedContent.Scope EXTERNAL_LIBRARIES 只包含外部库 PROJECT 只作用于project本身内容 PROVIDED_ONLY 支持compileOnly的远程依赖 SUB_PROJECTS 子模块内容 TESTED_CODE 当前变体测试的代码以及包括测试的依赖项 作用对象通过Transform#getInputTypes我们可以声明其的作用对象, 我们可以指定的作用对象只包括两种 QualifiedContent.ContentType CLASSES Java代码编译后的内容, 包括文件夹以及Jar包内的编译后的类文件 RESOURCES 基于资源获取到的内容 TransformManager整合了部分常用的Scope以及Content集合,如果是application注册的transform, 通常情况下, 我们一般指定TransformManager.SCOPE_FULL_PROJECT;如果是library注册的transform, 我们只能指定TransformManager.PROJECT_ONLY , 我们可以在LibraryTaskManager#createTasksForVariantScope中看到相关的限制报错代码1234567891011121314Sets.SetView&lt;? super Scope&gt; difference = Sets.difference(transform.getScopes(), TransformManager.PROJECT_ONLY);if (!difference.isEmpty()) &#123; String scopes = difference.toString(); globalScope .getAndroidBuilder() .getIssueReporter() .reportError( Type.GENERIC, new EvalIssueException( String.format( "Transforms with scopes '%s' cannot be applied to library projects.", scopes)));&#125; 而作用对象我们主要常用到的是TransformManager.CONTENT_CLASS TransformInvocation我们通过实现Transform#transform方法来处理我们的中间转换过程, 而中间相关信息都是通过TransformInvocation对象来传递1234567891011121314151617181920212223242526272829303132333435public interface TransformInvocation &#123; /** * transform的上下文 */ @NonNull Context getContext(); /** * 返回transform的输入源 */ @NonNull Collection&lt;TransformInput&gt; getInputs(); /** * 返回引用型输入源 */ @NonNull Collection&lt;TransformInput&gt; getReferencedInputs(); /** * 额外输入源 */ @NonNull Collection&lt;SecondaryInput&gt; getSecondaryInputs(); /** * 输出源 */ @Nullable TransformOutputProvider getOutputProvider(); /** * 是否增量 */ boolean isIncremental();&#125; 关于输入源, 我们可以大致分为消费型和引用型和额外的输入源 消费型就是我们需要进行transform操作的, 这类对象在处理后我们必须指定输出传给下一级,我们主要通过getInputs()获取进行消费的输入源, 而在进行变换后, 我们也必须通过设置getInputTypes()和getScopes()来指定输出源传输给下个transform. 引用型输入源是指我们不进行transform操作, 但可能存在查看时候使用, 所以这类我们也不需要输出给下一级, 在通过覆写getReferencedScopes()指定我们的引用型输入源的作用域后, 我们可以通过TransformInvocation#getReferencedInputs()获取引用型输入源 另外我们还可以额外定义另外的输入源供下一级使用, 正常开发中我们很少用到, 不过像是ProGuardTransform中, 就会指定创建mapping.txt传给下一级; 同样像是DexMergerTransform, 如果打开了multiDex功能, 则会将maindexlist.txt文件传给下一级 Transform的原理Transform的执行链我们已经大致了解它是如何使用的, 现在看下他的原理(本篇源码基于gradle插件3.3.2版本)在去年AppPlugin源码解析中, 我们粗略了解了android的com.android.application以及com.android.library两个插件都继承于BasePlugin, 而他们的主要执行顺序可以分为三个步骤 project的配置 extension的配置 task的创建 在BaseExtension内部维护了一个transforms集合对象,android.registerTransform(theTransform)实际上就是将我们自定义的transform实例新增到这个列表对象中.在3.3.2的源码中, 也可以这样理解. 在BasePlugin#createAndroidTasks中, 我们通过VariantManager#createAndroidTasks创建各个变体的相关编译任务, 最终通过TaskManager#createTasksForVariantScope(application插件最终实现方法在TaskManager#createPostCompilationTasks中, 而library插件最终实现方法在LibraryTaskManager#createTasksForVariantScope中)方法中获取BaseExtension中维护的transforms对象, 通过TransformManager#addTransform将对应的transform对象转换为task, 注册在TaskFactory中.这里关于一系列Transform Task的执行流程, 我们可以选择看下application内的相关transform流程, 由于篇幅原因, 可以自行去看相关源码, 这里的transform task流程分别是从Desugar-&gt;MergeJavaRes-&gt;自定义的transform-&gt;MergeClasses-&gt;Shrinker(包括ResourcesShrinker和DexSplitter和Proguard)-&gt;MultiDex-&gt;BundleMultiDex-&gt;Dex-&gt;ResourcesShrinker-&gt;DexSplitter, 由此调用链, 我们也可以看出在处理类文件的时候, 是不需要去考虑混淆的处理的. TransformManagerTransformManager管理了项目对应变体的所有Transform对象, 它的内部维护了一个TransformStream集合对象streams, 每当新增一个transform, 对应的transform会消费掉对应的流, 而后将处理后的流添加会streams内123public class TransformManager extends FilterableStreamCollection&#123; private final List&lt;TransformStream&gt; streams = Lists.newArrayList();&#125; 我们可以看下它的核心方法addTransform12345678910111213141516171819202122232425262728293031323334353637383940414243444546@NonNull public &lt;T extends Transform&gt; Optional&lt;TaskProvider&lt;TransformTask&gt;&gt; addTransform( @NonNull TaskFactory taskFactory, @NonNull TransformVariantScope scope, @NonNull T transform, @Nullable PreConfigAction preConfigAction, @Nullable TaskConfigAction&lt;TransformTask&gt; configAction, @Nullable TaskProviderCallback&lt;TransformTask&gt; providerCallback) &#123; ... List&lt;TransformStream&gt; inputStreams = Lists.newArrayList(); // transform task的命名规则定义 String taskName = scope.getTaskName(getTaskNamePrefix(transform)); // 获取引用型流 List&lt;TransformStream&gt; referencedStreams = grabReferencedStreams(transform); // 找到输入流, 并计算通过transform的输出流 IntermediateStream outputStream = findTransformStreams( transform, scope, inputStreams, taskName, scope.getGlobalScope().getBuildDir()); // 省略代码是用来校验输入流和引用流是否为空, 理论上不可能为空, 如果为空, 则说明中间有个transform的转换处理有问题 ... transforms.add(transform); // transform task的创建 return Optional.of( taskFactory.register( new TransformTask.CreationAction&lt;&gt;( scope.getFullVariantName(), taskName, transform, inputStreams, referencedStreams, outputStream, recorder), preConfigAction, configAction, providerCallback)); &#125; 在TransformManager中添加一个Transform管理, 流程可分为以下几步 定义transform task名1234567891011121314151617181920static String getTaskNamePrefix(@NonNull Transform transform) &#123; StringBuilder sb = new StringBuilder(100); sb.append("transform"); sb.append( transform .getInputTypes() .stream() .map( inputType -&gt; CaseFormat.UPPER_UNDERSCORE.to( CaseFormat.UPPER_CAMEL, inputType.name())) .sorted() // Keep the order stable. .collect(Collectors.joining("And"))); sb.append("With"); StringHelper.appendCapitalized(sb, transform.getName()); sb.append("For"); return sb.toString(); &#125; 从上面代码, 我们可以看到新建的transform task的命名规则可以理解为transform${inputType1.name}And${inputType2.name}With${transform.name}For${variantName}, 对应的我们也可以通过已生成的transform task来验证 通过transform内部定义的引用型输入的作用域(SCOPE)和作用类型(InputTypes), 通过求取与streams作用域和作用类型的交集来获取对应的流, 将其定义为我们需要的引用型流 12345678910111213141516171819202122private List&lt;TransformStream&gt; grabReferencedStreams(@NonNull Transform transform) &#123; Set&lt;? super Scope&gt; requestedScopes = transform.getReferencedScopes(); ... List&lt;TransformStream&gt; streamMatches = Lists.newArrayListWithExpectedSize(streams.size()); Set&lt;ContentType&gt; requestedTypes = transform.getInputTypes(); for (TransformStream stream : streams) &#123; Set&lt;ContentType&gt; availableTypes = stream.getContentTypes(); Set&lt;? super Scope&gt; availableScopes = stream.getScopes(); Set&lt;ContentType&gt; commonTypes = Sets.intersection(requestedTypes, availableTypes); Set&lt;? super Scope&gt; commonScopes = Sets.intersection(requestedScopes, availableScopes); if (!commonTypes.isEmpty() &amp;&amp; !commonScopes.isEmpty()) &#123; streamMatches.add(stream); &#125; &#125; return streamMatches; &#125; 根据transform内定义的SCOPE和INPUT_TYPE, 获取对应的消费型输入流, 在streams内移除掉这一部分消费性的输入流, 保留无法匹配SCOPE和INPUT_TYPE的流; 构建新的输出流, 并加到streams中做管理 1234567891011121314151617181920212223242526272829303132333435363738394041private IntermediateStream findTransformStreams( @NonNull Transform transform, @NonNull TransformVariantScope scope, @NonNull List&lt;TransformStream&gt; inputStreams, @NonNull String taskName, @NonNull File buildDir) &#123; Set&lt;? super Scope&gt; requestedScopes = transform.getScopes(); ... Set&lt;ContentType&gt; requestedTypes = transform.getInputTypes(); // 获取消费型输入流 // 并将streams中移除对应的消费型输入流 consumeStreams(requestedScopes, requestedTypes, inputStreams); // 创建输出流 Set&lt;ContentType&gt; outputTypes = transform.getOutputTypes(); // 创建输出流转换的文件相关路径 File outRootFolder = FileUtils.join( buildDir, StringHelper.toStrings( AndroidProject.FD_INTERMEDIATES, FD_TRANSFORMS, transform.getName(), scope.getDirectorySegments())); // 输出流的创建 IntermediateStream outputStream = IntermediateStream.builder( project, transform.getName() + "-" + scope.getFullVariantName(), taskName) .addContentTypes(outputTypes) .addScopes(requestedScopes) .setRootLocation(outRootFolder) .build(); streams.add(outputStream); return outputStream; &#125; 最后, 创建TransformTask, 注册到TaskManager中 TransformTask如何触发到我们实现的Transform#transform方法, 就在TransformTask对应的TaskAction中执行 1234567891011121314151617181920212223242526272829303132333435363738394041void transform(final IncrementalTaskInputs incrementalTaskInputs) throws IOException, TransformException, InterruptedException &#123; final ReferenceHolder&lt;List&lt;TransformInput&gt;&gt; consumedInputs = ReferenceHolder.empty(); final ReferenceHolder&lt;List&lt;TransformInput&gt;&gt; referencedInputs = ReferenceHolder.empty(); final ReferenceHolder&lt;Boolean&gt; isIncremental = ReferenceHolder.empty(); final ReferenceHolder&lt;Collection&lt;SecondaryInput&gt;&gt; changedSecondaryInputs = ReferenceHolder.empty(); isIncremental.setValue(transform.isIncremental() &amp;&amp; incrementalTaskInputs.isIncremental()); GradleTransformExecution preExecutionInfo = GradleTransformExecution.newBuilder() .setType(AnalyticsUtil.getTransformType(transform.getClass()).getNumber()) .setIsIncremental(isIncremental.getValue()) .build(); // 一些增量模式下的处理, 包括在增量模式下, 判断输入流(引用型和消费型)的变化 ... GradleTransformExecution executionInfo = preExecutionInfo.toBuilder().setIsIncremental(isIncremental.getValue()).build(); ... transform.transform( new TransformInvocationBuilder(TransformTask.this) .addInputs(consumedInputs.getValue()) .addReferencedInputs(referencedInputs.getValue()) .addSecondaryInputs(changedSecondaryInputs.getValue()) .addOutputProvider( outputStream != null ? outputStream.asOutput( isIncremental.getValue()) : null) .setIncrementalMode(isIncremental.getValue()) .build()); if (outputStream != null) &#123; outputStream.save(); &#125; &#125; 通过上文的介绍, 我们现在应该知道了自定义的Transform执行的时序, 位置, 以及相关原理. 那么, 我们现在已经拿到了编译后的所有字节码, 我们要怎么去处理呢? 我们可以了解下ASM ASM的使用想要处理字节码, 常见的框架有AspectJ, Javasist, ASM. 关于框架的选型网上相关的文章还是比较多的, 从处理速度以及内存占用率上, ASM明显优于其他两个框架.本篇主要着眼于ASM的使用. 什么是ASMASM是一个通用的Java字节码操作和分析框架。它可以用于修改现有类或直接以二进制形式动态生成类. ASM提供了一些常见的字节码转换和分析算法，可以从中构建自定义复杂转换和代码分析工具.ASM库提供了两个用于生成和转换编译类的API：Core API提供基于事件的类表示，而Tree API提供基于对象的表示。由于基于事件的API(Core API)不需要在内存中存储一个表示该类的对象数, 所以从执行速度和内存占用上来说, 它比基于对象的API(Tree API)更优.然后从使用场景上来说, 基于事件的API使用会比基于对象的API使用更为困难, 譬如当我们需要针对某个对象进行调整的时候.由于一个类只能被一种API管理, 所以我们应该要区分场景选取使用对应的API ASM插件ASM的使用需要一定的学习成本, 我们可以通过使用ASM Bytecode Outline插件辅助了解, 对应插件在AS中的插件浏览器就可以找到, 唯一的遗憾在于它无法转换kotlin文件为通过ASM创建的类文件然后我们就可以通过打开一份java未编译文件, 通过右键选择Show Bytecode Outline转为对应的字节码, 并可以看到对应的通过ASM创建的类格式譬如我们新建了一个类, 可以通过asm插件得到通过core api生成的对应方法.1234@RouteModulepublic class ASMTest &#123;&#125; Transform API在应用工程方面的摸索使用组件通信中的作用Transform API在组件化工程中有很多应用方向, 目前我们项目中在自开发的路由框架中, 通过其去做了模块的自动化静态注册, 同时考虑到路由通过协议文档维护的不确定性(页面路由地址的维护不及时导致对应开发无法及时更新对应代码), 我们做了路由的常量管理, 首先通过扫描整个工程项目代码收集路由信息, 建立符合一定规则的路由原始基础信息文件, 通过variant#registerJavaGeneratingTask注册 通过对应原始信息文件生成对应常量Java文件下沉在基础通用组件中的task, 这样上层依赖于这个基础组件的项目都可以通过直接调用常量来使用路由.在各组件代码隔离的情况下, 可以通过由组件aar传递原始信息文件, 仍然走上面的步骤生成对应的常量表, 而存在的类重复的问题, 通过自定义Transform处理合并 业务监控中的作用在应用工程中, 我们通常有关于网络监控,应用性能检测(包括页面加载时间, 甚至包括各个方法调用所耗时间, 可能存在超过阈值需要警告)的需求, 这些需求我们都不可能嵌入在业务代码中, 都是可以基于Transform API进行处理. 而针对于埋点, 我们也可以通过Transform实现自动化埋点的功能, 通过ASM Core和ASM Tree将尽可能多的字段信息形成记录传递, 这里有些我们项目中已经实现了, 有一些则是我们需要去优化或者去实现的. 其他关于结合Transform+ASM的使用, 我写了个一个小Demo, 包括了如何处理支持增量功能时的转换, 如何使用ASM Core Api和ASM Tree Api, 做了一定的封装, 可以参阅 相关参考 ASM用户指南 一起玩转Android项目中的字节码 AOP 的利器：ASM 3.0 介绍 ASM官网]]></content>
      <categories>
        <category>源码解析</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>transform</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RxJava源码解析(三)-背压]]></title>
    <url>%2F2019%2F03%2F05%2FRxJava%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%89)-%E8%83%8C%E5%8E%8B%2F</url>
    <content type="text"><![CDATA[什么是背压(Backpressure)?我们来看下RxJava自身对其的解释 When the dataflow runs through asynchronous steps, each step may perform different things with different speed. To avoid overwhelming such steps, which usually would manifest itself as increased memory usage due to temporary buffering or the need for skipping/dropping data, a so-called backpressure is applied, which is a form of flow control where the steps can express how many items are they ready to process. This allows constraining the memory usage of the dataflows in situations where there is generally no way for a step to know how many items the upstream will send to it. 来祭出google翻译, 当数据流通过异步步骤时，每个步骤可以以不同的速度执行不同的操作。为了避免压倒这些步骤，这些步骤通常表现为由于临时缓冲或需要跳过/丢弃数据而增加的内存使用量，所以应用所谓的背压，这是流量控制的一种形式，其中步骤可以表达多少物品准备好了。这允许在通常无法知道上游将向其发送多少项的步骤的情况下约束数据流的存储器使用。 简而言之, 当异步情况下, 上流(被观察者)发送数据过快, 而下流(消费者)无法及时处理数据, 导致缓存内存增大, 最终导致OOM, 这个时候, 背压就是为了处理这种情况. Observable / Observer我们都知道RxJava2主要是增加了使用背压机制下调用的api, 而原来的Observable / Observer组合是不支持背压的, 那么我们先回顾下原来的Observable / Observer组合使用的订阅流程1234567891011121314151617Observable // 新建 ObservableCreate .create(ObservableOnSubscribe&lt;Int&gt; &#123; var i = 0 while (true)&#123; it.onNext(i ++) &#125; &#125;) // 新建 ObservableSubscribeOn .subscribeOn(Schedulers.io()) // 新建 ObservableObserveOn .observeOn(Schedulers.newThread()) // 返回 LambdaObserver .subscribe&#123; Thread.sleep(5000) Log.d("rxjava", it.toString()) &#125; Observable / Observer组合的订阅消费流程和线程切换原理在去年都曾经写过, 这里就不再赘述, 我们主要看下, 上游的缓冲池(buffer)的做法, 相关代码在ObserveOnObserver#onNext12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970static final class ObserveOnObserver&lt;T&gt; extends BasicIntQueueDisposable&lt;T&gt; implements Observer&lt;T&gt;, Runnable &#123; ... @Override public void onSubscribe(Disposable d) &#123; if (DisposableHelper.validate(this.upstream, d)) &#123; this.upstream = d; ... queue = new SpscLinkedArrayQueue&lt;T&gt;(bufferSize); downstream.onSubscribe(this); &#125; &#125; @Override public void onNext(T t) &#123; if (done) &#123; return; &#125; if (sourceMode != QueueDisposable.ASYNC) &#123; queue.offer(t); &#125; schedule(); &#125; ... &#125;public final class SpscLinkedArrayQueue&lt;T&gt; implements SimplePlainQueue&lt;T&gt; &#123; public SpscLinkedArrayQueue(final int bufferSize) &#123; int p2capacity = Pow2.roundToPowerOfTwo(Math.max(8, bufferSize)); int mask = p2capacity - 1; AtomicReferenceArray&lt;Object&gt; buffer = new AtomicReferenceArray&lt;Object&gt;(p2capacity + 1); producerBuffer = buffer; producerMask = mask; adjustLookAheadStep(p2capacity); consumerBuffer = buffer; consumerMask = mask; producerLookAhead = mask - 1; // we know it's all empty to start with soProducerIndex(0L); &#125; @Override public boolean offer(final T e) &#123; if (null == e) &#123; throw new NullPointerException("Null is not a valid element"); &#125; // local load of field to avoid repeated loads after volatile reads final AtomicReferenceArray&lt;Object&gt; buffer = producerBuffer; final long index = lpProducerIndex(); final int mask = producerMask; final int offset = calcWrappedOffset(index, mask); if (index &lt; producerLookAhead) &#123; return writeToQueue(buffer, e, index, offset); &#125; else &#123; final int lookAheadStep = producerLookAheadStep; // go around the buffer or resize if full (unless we hit max capacity) int lookAheadElementOffset = calcWrappedOffset(index + lookAheadStep, mask); if (null == lvElement(buffer, lookAheadElementOffset)) &#123; // LoadLoad producerLookAhead = index + lookAheadStep - 1; // joy, there's plenty of room return writeToQueue(buffer, e, index, offset); &#125; else if (null == lvElement(buffer, calcWrappedOffset(index + 1, mask))) &#123; // buffer is not full return writeToQueue(buffer, e, index, offset); &#125; else &#123; resize(buffer, index, offset, e, mask); // add a buffer and link old to new return true; &#125; &#125; &#125;&#125; 省略掉大部分不相关代码, 这里大致做的是, 当被观察者被订阅的时候, 会初始化一个SpscLinkedArrayQueue类对象, 他的内部实际维护了一个AtomicReferenceArray对象, 这个就是我们的缓冲队列, 他的初始默认容量是128, 当我们调用到onNext方法的时候, 会首先判断buffer是否已满, 若未满, 则进行插入; 若已满, 则会进行扩容处理, 在异步情况下, 我们的下游无法消费掉buffer内的缓存, 导致内存占用越来越大, 最终导致OOM Flowable / Subscriber好, 快速过完无背压机制下的订阅流程后, 我们来看下RxJava2是怎么通过Flowable / Subscriber来处理背压的 订阅响应流程首先, 我们来跟着基础Demo来看下Flowable的订阅流程12345678910111213141516171819202122232425262728293031323334Flowable// 创建 FlowableCreate 对象.create(FlowableOnSubscribe&lt;Int&gt; &#123;for(i in 0..150)&#123;it.onNext(i)Log.d("send", i.toString())&#125;&#125;, BackpressureStrategy.LATEST)// 创建 FlowableSubscribeOn 对象.subscribeOn(Schedulers.io())// 创建 FlowableObserveOn 对象.observeOn(AndroidSchedulers.mainThread()).subscribe (object : FlowableSubscriber&lt;Int&gt; &#123;lateinit var s: Subscriptionvar i = 1override fun onComplete() &#123;Log.d("rxjava", "complete")&#125;override fun onSubscribe(s: Subscription) &#123;this.s = ss.request(130)&#125;override fun onNext(t: Int?) &#123;Log.e("rxjava receive", "$&#123;i++&#125; $t")&#125;override fun onError(t: Throwable?) &#123;t?.printStackTrace()&#125;&#125;)Thread.sleep(5000) create操作符用来初始化一个FlowableCreate对象, 并返回 12345public static &lt;T&gt; Flowable&lt;T&gt; create(FlowableOnSubscribe&lt;T&gt; source, BackpressureStrategy mode) &#123; ObjectHelper.requireNonNull(source, "source is null"); ObjectHelper.requireNonNull(mode, "mode is null"); return RxJavaPlugins.onAssembly(new FlowableCreate&lt;T&gt;(source, mode)); &#125; subscribeOn操作符 将FlowableCreate进行包装, 以FlowableSubscribeOn对象返回 12345678public final Flowable&lt;T&gt; subscribeOn(@NonNull Scheduler scheduler) &#123; ObjectHelper.requireNonNull(scheduler, "scheduler is null"); return subscribeOn(scheduler, !(this instanceof FlowableCreate)); &#125;public final Flowable&lt;T&gt; subscribeOn(@NonNull Scheduler scheduler, boolean requestOn) &#123; ObjectHelper.requireNonNull(scheduler, "scheduler is null"); return RxJavaPlugins.onAssembly(new FlowableSubscribeOn&lt;T&gt;(this, scheduler, requestOn)); &#125; observeOn操作符 将FlowableSubscribeOn进行包装, 并以FlowableObserveOn对象返回 12345678public final Flowable&lt;T&gt; observeOn(Scheduler scheduler) &#123; return observeOn(scheduler, false, bufferSize()); &#125;public final Flowable&lt;T&gt; observeOn(Scheduler scheduler, boolean delayError, int bufferSize) &#123; ObjectHelper.requireNonNull(scheduler, "scheduler is null"); ObjectHelper.verifyPositive(bufferSize, "bufferSize"); return RxJavaPlugins.onAssembly(new FlowableObserveOn&lt;T&gt;(this, scheduler, delayError, bufferSize)); &#125; 注意这里传入的butterSize()方法, 他的详细代码如下1234567static final int BUFFER_SIZE; static &#123; BUFFER_SIZE = Math.max(1, Integer.getInteger("rx2.buffer-size", 128)); &#125;public static int bufferSize() &#123; return BUFFER_SIZE; &#125; 在FlowableObserveOn类里, prefetch表示的是初始的缓存池大小, 可以看出, 如果不指定buffer大小, 那么我们默认大小就是128123456789101112131415public final class FlowableObserveOn&lt;T&gt; extends AbstractFlowableWithUpstream&lt;T, T&gt; &#123; ... public FlowableObserveOn( Flowable&lt;T&gt; source, Scheduler scheduler, boolean delayError, int prefetch) &#123; super(source); this.scheduler = scheduler; this.delayError = delayError; // 预约的缓存池初始化大小 this.prefetch = prefetch; &#125; ...&#125; subscribe操作符, 以当前Demo为例, 我们这里生成了一个LambdaSubscriber, 而后调用到的是我们上个操作符流程返回的Flowable#subscribe123public final Disposable subscribe(Consumer&lt;? super T&gt; onNext, Consumer&lt;? super Throwable&gt; onError) &#123; return subscribe(onNext, onError, Functions.EMPTY_ACTION, FlowableInternalHelper.RequestMax.INSTANCE); &#125; 12345678910public final Disposable subscribe(Consumer&lt;? super T&gt; onNext, Consumer&lt;? super Throwable&gt; onError, Action onComplete, Consumer&lt;? super Subscription&gt; onSubscribe) &#123; ... LambdaSubscriber&lt;T&gt; ls = new LambdaSubscriber&lt;T&gt;(onNext, onError, onComplete, onSubscribe); subscribe(ls); return ls; &#125; 123456789101112131415161718192021public final void subscribe(FlowableSubscriber&lt;? super T&gt; s) &#123; ObjectHelper.requireNonNull(s, "s is null"); try &#123; Subscriber&lt;? super T&gt; z = RxJavaPlugins.onSubscribe(this, s); ... subscribeActual(z); &#125; catch (NullPointerException e) &#123; // NOPMD throw e; &#125; catch (Throwable e) &#123; Exceptions.throwIfFatal(e); // can't call onError because no way to know if a Subscription has been set or not // can't call onSubscribe because the call might have set a Subscription already RxJavaPlugins.onError(e); NullPointerException npe = new NullPointerException("Actually not, but can't throw other exceptions due to RS"); npe.initCause(e); throw npe; &#125; &#125; 最终走到Flowable#subscribeActual(Subscriber&lt;? super T&gt; s)方法, 它是个抽象方法, 由调用方FlowableObserveOn对象实现123456789101112131415public final class FlowableObserveOn&lt;T&gt; extends AbstractFlowableWithUpstream&lt;T, T&gt; &#123; ... @Override public void subscribeActual(Subscriber&lt;? super T&gt; s) &#123; Worker worker = scheduler.createWorker(); if (s instanceof ConditionalSubscriber) &#123; source.subscribe(new ObserveOnConditionalSubscriber&lt;T&gt;( (ConditionalSubscriber&lt;? super T&gt;) s, worker, delayError, prefetch)); &#125; else &#123; source.subscribe(new ObserveOnSubscriber&lt;T&gt;(s, worker, delayError, prefetch)); &#125; &#125; ...&#125; 这里source对象是我们前面被包装的FlowableSubscribeOn对象, 是不是很熟悉?FlowableSubscribeOn类继承于Flowable, 而Flowable#subscribe(FlowableSubscriber&lt;? super T&gt; s)方法最终走到 Flowable#subscribeActual(Subscriber&lt;? super T&gt; s),上文已知这是个抽象方法, 最终执行到FlowableSubscribeOn#subscribeActual, 并将LambdaSubscriber包装成ObserveOnSubscriber作为参数传递进去 12345678910111213public final class FlowableSubscribeOn&lt;T&gt; extends AbstractFlowableWithUpstream&lt;T , T&gt; &#123; ... @Override public void subscribeActual(final Subscriber&lt;? super T&gt; s) &#123; Scheduler.Worker w = scheduler.createWorker(); final SubscribeOnSubscriber&lt;T&gt; sos = new SubscribeOnSubscriber&lt;T&gt;(s, w, source, nonScheduledRequests); // s 为 ObserveOnSubscriber 对象 s.onSubscribe(sos); w.schedule(sos); &#125; ...&#125; 我们先来看下s.onSubscribe(sos);执行代码1234567891011121314151617181920212223242526272829303132333435363738394041424344static final class ObserveOnSubscriber&lt;T&gt; extends BaseObserveOnSubscriber&lt;T&gt; implements FlowableSubscriber&lt;T&gt; &#123; ... @Override public void onSubscribe(Subscription s) &#123; if (SubscriptionHelper.validate(this.upstream, s)) &#123; this.upstream = s; if (s instanceof QueueSubscription) &#123; @SuppressWarnings("unchecked") QueueSubscription&lt;T&gt; f = (QueueSubscription&lt;T&gt;) s; int m = f.requestFusion(ANY | BOUNDARY); if (m == SYNC) &#123; sourceMode = SYNC; queue = f; done = true; downstream.onSubscribe(this); return; &#125; else if (m == ASYNC) &#123; sourceMode = ASYNC; queue = f; downstream.onSubscribe(this); s.request(prefetch); return; &#125; &#125; // 初始化缓存队列 // prefetch 默认大小为128 queue = new SpscArrayQueue&lt;T&gt;(prefetch); // 下流订阅执行 downstream.onSubscribe(this); // 上流的subscription request 执行 s.request(prefetch); &#125; &#125; ... &#125; 可以看到, 在这个时候, 就会执行到消费者的onSubscribe方法, 然后会执行到SubscribeOnSubscriber#request123456789101112131415161718192021static final class SubscribeOnSubscriber&lt;T&gt; extends AtomicReference&lt;Thread&gt; implements FlowableSubscriber&lt;T&gt;, Subscription, Runnable &#123; @Override public void request(final long n) &#123; if (SubscriptionHelper.validate(n)) &#123; Subscription s = this.upstream.get(); if (s != null) &#123; requestUpstream(n, s); &#125; else &#123; BackpressureHelper.add(requested, n); s = this.upstream.get(); if (s != null) &#123; long r = requested.getAndSet(0L); if (r != 0L) &#123; requestUpstream(r, s); &#125; &#125; &#125; &#125; &#125; &#125; SubscribeOnSubscriber实现了Subscription的接口, request方法主要用来处理内部缓存最大值123456789101112131415161718public interface Subscription &#123; /** * No events will be sent by a &#123;@link Publisher&#125; until demand is signaled via this method. * &lt;p&gt; * It can be called however often and whenever needed—but the outstanding cumulative demand must never exceed Long.MAX_VALUE. * An outstanding cumulative demand of Long.MAX_VALUE may be treated by the &#123;@link Publisher&#125; as "effectively unbounded". * &lt;p&gt; * Whatever has been requested can be sent by the &#123;@link Publisher&#125; so only signal demand for what can be safely handled. * &lt;p&gt; * A &#123;@link Publisher&#125; can send less than is requested if the stream ends but * then must emit either &#123;@link Subscriber#onError(Throwable)&#125; or &#123;@link Subscriber#onComplete()&#125;. * * @param n the strictly positive number of elements to requests to the upstream &#123;@link Publisher&#125; */ public void request(long n); public void cancel();&#125; 这里, 和原来的线程切换原理相同, 根据scheduler.createWorker根据工厂模式的帮助, 创建新的Worker对象, 它的内部的工作原理都是通过线程池来执行对应的Runnable, 而我们包装后所得的SubscribeOnSubscriber对象正是继承于Runnable, 我们可以看他内部实现的run方法123456789101112131415161718192021static final class SubscribeOnSubscriber&lt;T&gt; extends AtomicReference&lt;Thread&gt; implements FlowableSubscriber&lt;T&gt;, Subscription, Runnable &#123; ... SubscribeOnSubscriber(Subscriber&lt;? super T&gt; actual, Scheduler.Worker worker, Publisher&lt;T&gt; source, boolean requestOn) &#123; this.downstream = actual; this.worker = worker; this.source = source; this.upstream = new AtomicReference&lt;Subscription&gt;(); this.requested = new AtomicLong(); this.nonScheduledRequests = !requestOn; &#125; @Override public void run() &#123; lazySet(Thread.currentThread()); Publisher&lt;T&gt; src = source; source = null; src.subscribe(this); &#125; ... &#125; 这里的source是在FlowableSubscribeOn初始化的时候, 通过构造函数传入的, 而我们知道, 他的内部是FlowableCreate12345public FlowableSubscribeOn(Flowable&lt;T&gt; source, Scheduler scheduler, boolean nonScheduledRequests) &#123; super(source); this.scheduler = scheduler; this.nonScheduledRequests = nonScheduledRequests; &#125; 根据前面的套路, 我们直接去看FlowableCreate下的subscribeActual实现方法123456789101112131415161718192021222324252627282930313233343536@Override public void subscribeActual(Subscriber&lt;? super T&gt; t) &#123; BaseEmitter&lt;T&gt; emitter; switch (backpressure) &#123; case MISSING: &#123; emitter = new MissingEmitter&lt;T&gt;(t); break; &#125; case ERROR: &#123; emitter = new ErrorAsyncEmitter&lt;T&gt;(t); break; &#125; case DROP: &#123; emitter = new DropAsyncEmitter&lt;T&gt;(t); break; &#125; case LATEST: &#123; emitter = new LatestAsyncEmitter&lt;T&gt;(t); break; &#125; default: &#123; emitter = new BufferAsyncEmitter&lt;T&gt;(t, bufferSize()); break; &#125; &#125; // SubscribeOnSubscriber.onSubscribe t.onSubscribe(emitter); try &#123; // 执行被观察者发送事件 source.subscribe(emitter); &#125; catch (Throwable ex) &#123; Exceptions.throwIfFatal(ex); emitter.onError(ex); &#125; &#125; 可以看到, 根据我们选择的背压策略, 新建不同类型继承于BaseEmitter类对象. 而这时候, 首先执行的是SubscribeOnSubscriber#onSubscribe12345678910111213141516171819@Overridepublic void onSubscribe(Subscription s) &#123; if (SubscriptionHelper.setOnce(this.upstream, s)) &#123; // 初始128 long r = requested.getAndSet(0L); if (r != 0L) &#123; requestUpstream(r, s); &#125; &#125;&#125;// 切换线程到正确的目标线程上// 最终执行 Subscription#request(n)void requestUpstream(final long n, final Subscription s) &#123; if (nonScheduledRequests || Thread.currentThread() == get()) &#123; s.request(n); &#125; else &#123; worker.schedule(new Request(s, n)); &#125;&#125; 这里的Subscription是前面BaseEmitter对象, 将其内部的缓存容量大小设为默认的128大小.123456789101112131415abstract static class BaseEmitter&lt;T&gt; extends AtomicLong implements FlowableEmitter&lt;T&gt;, Subscription &#123; @Override public final void request(long n) &#123; if (SubscriptionHelper.validate(n)) &#123; BackpressureHelper.add(this, n); onRequested(); &#125; &#125; void onRequested() &#123; // default is no-op &#125; &#125; 到这里我们的订阅整个流程已经完成, 然后我们通过实现的被观察者的发送事件, 通过emitter来循环发送自增整型i 我们来看下排除掉背压控制后的响应流程, 关于几个背压策略我们后文细讲, 这里我们需要知道MissingEmitter是不会处理背压, 所以我们从他的onNext看起123456789101112131415161718192021static final class MissingEmitter&lt;T&gt; extends BaseEmitter&lt;T&gt; &#123; MissingEmitter(Subscriber&lt;? super T&gt; downstream) &#123; super(downstream); &#125; @Override public void onNext(T t) &#123; if (isCancelled()) &#123; return; &#125; if (t != null) &#123; downstream.onNext(t); &#125; else &#123; onError(new NullPointerException("onNext called with null. Null values are generally not allowed in 2.x operators and sources.")); return; &#125; ... &#125; &#125; 直接执行下流的onNext方法, 而它的下流是SubscribeOnSubscriber 1234567static final class SubscribeOnSubscriber&lt;T&gt; extends AtomicReference&lt;Thread&gt; implements FlowableSubscriber&lt;T&gt;, Subscription, Runnable &#123; @Override public void onNext(T t) &#123; downstream.onNext(t); &#125; &#125; SubscribeOnSubscriber的下流是ObserveOnSubscriber, 他的onNext方法在父类BaseObserveOnSubscriber中1234567891011121314151617181920212223242526272829303132333435363738abstract static class BaseObserveOnSubscriber&lt;T&gt; extends BasicIntQueueSubscription&lt;T&gt; implements FlowableSubscriber&lt;T&gt;, Runnable &#123; @Override public final void onNext(T t) &#123; if (done) &#123; return; &#125; if (sourceMode == ASYNC) &#123; trySchedule(); return; &#125; if (!queue.offer(t)) &#123; upstream.cancel(); error = new MissingBackpressureException("Queue is full?!"); done = true; &#125; trySchedule(); &#125; final void trySchedule() &#123; if (getAndIncrement() != 0) &#123; return; &#125; worker.schedule(this); &#125; @Override public final void run() &#123; if (outputFused) &#123; runBackfused(); &#125; else if (sourceMode == SYNC) &#123; runSync(); &#125; else &#123; runAsync(); &#125; &#125; &#125; ObserveOnSubscriber内部维护的queue是SpscArrayQueue, 当维护的队列满了以后, 直接返回false, 而不会再做扩容操作, 当检测到内部缓存队列已满的时候, 会设置done为true, 异常为MissingBackpressureException123456789101112131415161718192021@Override public boolean offer(E e) &#123; if (null == e) &#123; throw new NullPointerException("Null is not a valid element"); &#125; // local load of field to avoid repeated loads after volatile reads final int mask = this.mask; final long index = producerIndex.get(); final int offset = calcElementOffset(index, mask); if (index &gt;= producerLookAhead) &#123; int step = lookAheadStep; if (null == lvElement(calcElementOffset(index + step, mask))) &#123; // LoadLoad producerLookAhead = index + step; &#125; else if (null != lvElement(offset)) &#123; return false; &#125; &#125; soElement(offset, e); // StoreStore soProducerIndex(index + 1); // ordered store -&gt; atomic and ordered for size() return true; &#125; 来看下他的异步处理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869@Overridevoid runAsync() &#123; int missed = 1; final Subscriber&lt;? super T&gt; a = downstream; final SimpleQueue&lt;T&gt; q = queue; long e = produced; for (;;) &#123; long r = requested.get(); while (e != r) &#123; boolean d = done; T v; try &#123; v = q.poll(); &#125; catch (Throwable ex) &#123; Exceptions.throwIfFatal(ex); cancelled = true; upstream.cancel(); q.clear(); a.onError(ex); worker.dispose(); return; &#125; boolean empty = v == null; if (checkTerminated(d, empty, a)) &#123; return; &#125; if (empty) &#123; break; &#125; a.onNext(v); e++; if (e == limit) &#123; if (r != Long.MAX_VALUE) &#123; r = requested.addAndGet(-e); &#125; upstream.request(e); e = 0L; &#125; &#125; if (e == r &amp;&amp; checkTerminated(done, q.isEmpty(), a)) &#123; return; &#125; int w = get(); if (missed == w) &#123; produced = e; missed = addAndGet(-missed); if (missed == 0) &#123; break; &#125; &#125; else &#123; missed = w; &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738final boolean checkTerminated(boolean d, boolean empty, Subscriber&lt;?&gt; a) &#123; if (cancelled) &#123; clear(); return true; &#125; if (d) &#123; if (delayError) &#123; if (empty) &#123; cancelled = true; Throwable e = error; if (e != null) &#123; a.onError(e); &#125; else &#123; a.onComplete(); &#125; worker.dispose(); return true; &#125; &#125; else &#123; Throwable e = error; if (e != null) &#123; cancelled = true; clear(); a.onError(e); worker.dispose(); return true; &#125; else if (empty) &#123; cancelled = true; a.onComplete(); worker.dispose(); return true; &#125; &#125; &#125; return false;&#125; 执行流程基本与ObservableObserveOn相同, 这里不再赘述.可以注意到, 当done为true并且error不为空的时候, 会调用到下流的onError, 最终是抛出MissingBackpressureException异常大概的流程图可参考下图 背压策略Emitter的类图如下 BaseEmitter我们首先看下BaseEmitter, 它是一个抽象类, 由于继承AtomicLong, 所以本身可维护下流缓存阈值, 而他内部维护的downsteam表示的是下流的Subscriber, 在本文的demo中, 它就是SubscribeOnSubscriber对象, 他的内部还实现了request(long n)方法, 这个方法主要是设置内部的缓存允许阈值, 详细代码我们再上文有带到. NoOverflowBaseAsyncEmitterNoOverflowBaseAsyncEmitter继承于BaseEmitter, 并覆写了onNext, 这里的代码也比较容易理解, 在缓存大小允许范围内发送数据, 则直接发送, 并计数-1, 否则调用onOverflow抽象方法, 可以看出onOverflow就是出现背压情况时候的实际处理策略1234567891011121314151617181920abstract static class NoOverflowBaseAsyncEmitter&lt;T&gt; extends BaseEmitter&lt;T&gt; &#123; @Override public final void onNext(T t) &#123; if (isCancelled()) &#123; return; &#125; ... if (get() != 0) &#123; downstream.onNext(t); // 阈值-1 BackpressureHelper.produced(this, 1); &#125; else &#123; onOverflow(); &#125; &#125; // 超出阈值情况处理 abstract void onOverflow(); &#125; ErrorAsyncEmitterErrorAsyncEmitter继承于NoOverflowBaseAsyncEmitter, 当出现背压情况的时候, 则直接调用onError, 抛出MissingBackpressureException异常12345678static final class ErrorAsyncEmitter&lt;T&gt; extends NoOverflowBaseAsyncEmitter&lt;T&gt; &#123; ... @Override void onOverflow() &#123; onError(new MissingBackpressureException("create: could not emit value due to lack of requests")); &#125; &#125; DropAsyncEmitterDropAsyncEmitter继承于NoOverflowBaseAsyncEmitter, 背压策略不做任务处理, 则当超出缓存允许大小的时候, 对应的发送数据就不会再调用到下流的响应事件, 相当于drop123456789static final class DropAsyncEmitter&lt;T&gt; extends NoOverflowBaseAsyncEmitter&lt;T&gt; &#123; ... @Override void onOverflow() &#123; // nothing to do &#125; &#125; LatestAsyncEmitter它的内部维护了一个AtomicReference的queue, 可以理解为其自身的缓存池, 而这个池只有一个内存大小, 它在调用到onNext方法的时候, 将发送的数据存入queue, 并调用drain, 我们主要看下drain方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869void drain() &#123; // 省略保证线程安全相关代码 ... final Subscriber&lt;? super T&gt; a = downstream; final AtomicReference&lt;T&gt; q = queue; for (;;) &#123; long r = get(); long e = 0L; while (e != r) &#123; if (isCancelled()) &#123; q.lazySet(null); return; &#125; boolean d = done; T o = q.getAndSet(null); boolean empty = o == null; if (d &amp;&amp; empty) &#123; Throwable ex = error; if (ex != null) &#123; error(ex); &#125; else &#123; complete(); &#125; return; &#125; if (empty) &#123; break; &#125; a.onNext(o); e++; &#125; if (e == r) &#123; if (isCancelled()) &#123; q.lazySet(null); return; &#125; boolean d = done; boolean empty = q.get() == null; if (d &amp;&amp; empty) &#123; Throwable ex = error; if (ex != null) &#123; error(ex); &#125; else &#123; complete(); &#125; return; &#125; &#125; if (e != 0) &#123; BackpressureHelper.produced(this, e); &#125; ... &#125; &#125; 我们可以看到, 它在内部缓存阈值允许范围内, 会遍历读取queue的数据, 并将其发送给下流,当然这里queue的缓存大小也只有一个, 所以才会出现消费的最后一个数据会是上流发送的最后一个数据 BufferAsyncEmitterBufferAsyncEmitter内部维护了一个128大小的SpscLinkedArrayQueue缓存队列, SpscLinkedArrayQueue我们在ObserveOnObserver中见过, 他在存入数据的时候, 当达到队列最大长度的时候, 会进行扩容处理, 而通过BufferAsyncEmitter每次发送数据的时候, 首先会存入到queue中, 然后调用drain, 这里的代码与LatestAsyncEmitter也很相似, 区别只在于缓冲区的区别, 而当缓存区一再扩容的时候, 有可能出现OOM的现象, 他的逻辑其实与ObserveOnObserver内的消费逻辑是一样的1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768void drain() &#123; ... final Subscriber&lt;? super T&gt; a = downstream; final SpscLinkedArrayQueue&lt;T&gt; q = queue; for (;;) &#123; long r = get(); long e = 0L; while (e != r) &#123; if (isCancelled()) &#123; q.clear(); return; &#125; boolean d = done; T o = q.poll(); boolean empty = o == null; if (d &amp;&amp; empty) &#123; Throwable ex = error; if (ex != null) &#123; error(ex); &#125; else &#123; complete(); &#125; return; &#125; if (empty) &#123; break; &#125; a.onNext(o); e++; &#125; if (e == r) &#123; if (isCancelled()) &#123; q.clear(); return; &#125; boolean d = done; boolean empty = q.isEmpty(); if (d &amp;&amp; empty) &#123; Throwable ex = error; if (ex != null) &#123; error(ex); &#125; else &#123; complete(); &#125; return; &#125; &#125; if (e != 0) &#123; BackpressureHelper.produced(this, e); &#125; ... &#125; &#125; 背压总结我们再回头看下, 几种背压策略的效果 策略 效果 MISSING 无任何背压策略执行, 除非调用onBackpressureXXX ERROR 抛出异常 BUFFER 内部维护可扩容的缓存池, 效果与Observer一样, 可能导致OOM DROP 如果下流无法跟上上流发射速度, 则会丢弃这块数据 LATEST 当下流无法跟上上流的发射速度的时候, 则只保存最近生产的数据]]></content>
      <categories>
        <category>源码解析</category>
      </categories>
      <tags>
        <tag>源码解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android基础-Handler源码]]></title>
    <url>%2F2018%2F12%2F12%2FAndroid%E5%9F%BA%E7%A1%80-Handler%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[最近深感对基础知识不够扎实, 所以回头看一下Handler的源码. 首先, 我们先从他的使用作为入口来 Handler的使用先看下, 几种通过Handler发送消息的用法, 一共有四种, 当然最终调用的还是Handler#sendMessageDelayed(Message msg, long delayMillis), 这个我们放在后面去解析.123456789101112131415161718private fun sendHandler()&#123; // 1 MyHandler().obtainMessage(1).sendToTarget() // 2 val msg = Message() msg.what = 2 MyHandler().sendMessage(msg) // 3 MyHandler().post &#123; Log.e(MainActivity::class.java.canonicalName, "3") &#125; // 4 val callback = Handler.Callback &#123; Log.e(MainActivity::class.java.canonicalName, it.what.toString()) true &#125; val msg2 = Message() msg2.what=4 MyHandler(callback).sendMessage(msg2) &#125; 然后是他通用的消息接收处理12345678910// kotlin内部类默认为静态类private class MyHandler: Handler &#123; constructor() constructor(callback: Callback) override fun handleMessage(msg: Message?) &#123; super.handleMessage(msg) Log.e(MainActivity::class.java.canonicalName, msg?.what.toString()) &#125; &#125; Handler构造要了解Handler, 我们首先看他的构造函数, Handler的构造, 实际分为两种, 一种是传入Looper, 一种是直接使用当前线程的Looper, 可以看到, 主要就是通过默认当前线程Looper或者是提供的Looper获取messageQueue对象.123456789101112131415161718192021222324252627282930public Handler(Callback callback, boolean async) &#123; if (FIND_POTENTIAL_LEAKS) &#123; final Class&lt;? extends Handler&gt; klass = getClass(); if ((klass.isAnonymousClass() || klass.isMemberClass() || klass.isLocalClass()) &amp;&amp; (klass.getModifiers() &amp; Modifier.STATIC) == 0) &#123; Log.w(TAG, "The following Handler class should be static or leaks might occur: " + klass.getCanonicalName()); &#125; &#125; // 使用当前线程的Looper对象 mLooper = Looper.myLooper(); if (mLooper == null) &#123; throw new RuntimeException( "Can't create handler inside thread that has not called Looper.prepare()"); &#125; // 获取looper持有的messageQueue mQueue = mLooper.mQueue; mCallback = callback; mAsynchronous = async; &#125;// 使用提供的Looper对象public Handler(Looper looper, Callback callback, boolean async) &#123; mLooper = looper; mQueue = looper.mQueue; mCallback = callback; mAsynchronous = async;&#125; 当我们在子线程内直接发送消息, 会抛出异常, 具体我们可以从Looper#myLooper()开始看1234567/** * Return the Looper object associated with the current thread. Returns * null if the calling thread is not associated with a Looper. */public static @Nullable Looper myLooper() &#123; return sThreadLocal.get(); &#125; ThreadLocal这里不细说, 反正知道他是每个线程独有的存储空间就行了.可以看到, looper是每个线程不共享的内存对象, 它存储在ThreadLocal内, 而在Looper#prepare会进行Looper的实例化, 和存储在threadLocal内12345678910private static void prepare(boolean quitAllowed) &#123; if (sThreadLocal.get() != null) &#123; throw new RuntimeException("Only one Looper may be created per thread"); &#125; sThreadLocal.set(new Looper(quitAllowed)); &#125;private Looper(boolean quitAllowed) &#123; mQueue = new MessageQueue(quitAllowed); mThread = Thread.currentThread();&#125; 发送消息Handler发送消息最终都会走到Handler#sendMessageDelayed方法, 会发现他最终调用的是MessageQueue#enqueueMessage(Message msg, long when)1234567891011121314151617181920212223242526public final boolean sendMessageDelayed(Message msg, long delayMillis) &#123; if (delayMillis &lt; 0) &#123; delayMillis = 0; &#125; return sendMessageAtTime(msg, SystemClock.uptimeMillis() + delayMillis); &#125;public boolean sendMessageAtTime(Message msg, long uptimeMillis) &#123; MessageQueue queue = mQueue; if (queue == null) &#123; RuntimeException e = new RuntimeException( this + " sendMessageAtTime() called with no mQueue"); Log.w("Looper", e.getMessage(), e); return false; &#125; return enqueueMessage(queue, msg, uptimeMillis); &#125;private boolean enqueueMessage(MessageQueue queue, Message msg, long uptimeMillis) &#123; msg.target = this; if (mAsynchronous) &#123; msg.setAsynchronous(true); &#125; return queue.enqueueMessage(msg, uptimeMillis); &#125; MessageQueue虽然说是消息队列, 但是实际实现队列机制是依靠的Message的数据结构,每一个Message都会通过它内部的next字段指向另外一个Message, 最终实现了单向列表的数据结构, 而MessageQueue内部的mMessages就是队列头的消息对象, 具体可以看下, 插入消息时候的方法体123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960boolean enqueueMessage(Message msg, long when) &#123; if (msg.target == null) &#123; throw new IllegalArgumentException("Message must have a target."); &#125; if (msg.isInUse()) &#123; throw new IllegalStateException(msg + " This message is already in use."); &#125; synchronized (this) &#123; if (mQuittying) &#123; IllegalStateException e = new IllegalStateException( msg.target + " sending message to a Handler on a dead thread"); Log.w(TAG, e.getMessage(), e); msg.recycle(); return false; &#125; msg.markInUse(); // 延迟时间 msg.when = when; // 队列中上一条消息 Message p = mMessages; boolean needWake; // 无延迟 或者 是第一条消息// 或者需要比上一条消息早发送 if (p == null || when == 0 || when &lt; p.when) &#123; // New head, wake up the event queue if blocked. // 将当前消息置于列表顶 // 当前消息的下一条消息指向之前的mMessages msg.next = p; mMessages = msg; needWake = mBlocked; &#125; else &#123; // Inserted within the middle of the queue. Usually we don't have to wake // up the event queue unless there is a barrier at the head of the queue // and the message is the earliest asynchronous message in the queue. // 中间插入当前的消息对象 needWake = mBlocked &amp;&amp; p.target == null &amp;&amp; msg.isAsynchronous(); Message prev; for (;;) &#123; prev = p; p = p.next; if (p == null || when &lt; p.when) &#123; break; &#125; if (needWake &amp;&amp; p.isAsynchronous()) &#123; needWake = false; &#125; &#125; msg.next = p; // invariant: p == prev.next prev.next = msg; &#125; // We can assume mPtr != 0 because mQuitting is false. // 线程唤醒 if (needWake) &#123; nativeWake(mPtr); &#125; &#125; return true; &#125; 消息处理关于消息的处理, 我们又要回头去看Looper, 关于MessageQueue它主要做了两个事情, 从Handler那边接收Message做队列托管, 然后将符合条件的Message返回给Looper, 具体我们可以看下Looper#loop()1234567891011121314151617181920212223242526272829public static void loop() &#123; final Looper me = myLooper(); if (me == null) &#123; throw new RuntimeException("No Looper; Looper.prepare() wasn't called on this thread."); &#125; final MessageQueue queue = me.mQueue; // Make sure the identity of this thread is that of the local process, // and keep track of what that identity token actually is. // 校验当前线程在当前进程内 Binder.clearCallingIdentity(); final long ident = Binder.clearCallingIdentity(); for (;;) &#123; // 1. 获取message Message msg = queue.next(); // might block if (msg == null) &#123; // No message indicates that the message queue is quitting. return; &#125; // 2. handler的分发处理 msg.target.dispatchMessage(msg); ... // 3. 消息的回收 msg.recycleUnchecked(); &#125; &#125; 删除了一些无关的代码, 我们看下核心流程, Looper#loop就一直不断循环的在做三件事: 拿取MessageQueue中的Message 调用Message持有的handler的分发处理事件 回收已处理掉的Message 我们来看下MessageQueue给到Looper怎么样的Message123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122Message next() &#123; // Return here if the message loop has already quit and been disposed. // This can happen if the application tries to restart a looper after quit // which is not supported. final long ptr = mPtr; if (ptr == 0) &#123; return null; &#125; int pendingIdleHandlerCount = -1; // -1 only during first iteration int nextPollTimeoutMillis = 0; for (;;) &#123; if (nextPollTimeoutMillis != 0) &#123; Binder.flushPendingCommands(); &#125; nativePollOnce(ptr, nextPollTimeoutMillis); synchronized (this) &#123; // Try to retrieve the next message. Return if found. // 获取当前启动时间 final long now = SystemClock.uptimeMillis(); Message prevMsg = null; Message msg = mMessages; // 当头部消息的target(携带handler)为空的情况下 if (msg != null &amp;&amp; msg.target == null) &#123; // Stalled by a barrier. Find the next asynchronous message in the queue. // 遍历队列, 直到获取到的消息不为空并且是同步信息 do &#123; prevMsg = msg; msg = msg.next; &#125; while (msg != null &amp;&amp; !msg.isAsynchronous()); &#125; if (msg != null) &#123; // 延迟消息 if (now &lt; msg.when) &#123; // Next message is not ready. Set a timeout to wake up when it is ready. nextPollTimeoutMillis = (int) Math.min(msg.when - now, Integer.MAX_VALUE); &#125; else &#123; // Got a message. // 指向下一条message // 该条消息需要被执行的时候 mBlocked = false; if (prevMsg != null) &#123; prevMsg.next = msg.next; &#125; else &#123; mMessages = msg.next; &#125; msg.next = null; if (DEBUG) Log.v(TAG, "Returning message: " + msg); msg.markInUse(); // 返回当前的message return msg; &#125; &#125; else &#123; // No more messages. // 如果当前队列头部没有消息, 则说明队列为空 nextPollTimeoutMillis = -1; &#125; // Process the quit message now that all pending messages have been handled. if (mQuitting) &#123; dispose(); return null; &#125; // If first time idle, then get the number of idlers to run. // Idle handles only run if the queue is empty or if the first message // in the queue (possibly a barrier) is due to be handled in the future. // 当队列空闲(头部消息为空或者头部消息还未到时候执行), 并且没有闲置handler的时候 if (pendingIdleHandlerCount &lt; 0 &amp;&amp; (mMessages == null || now &lt; mMessages.when)) &#123; pendingIdleHandlerCount = mIdleHandlers.size(); &#125; if (pendingIdleHandlerCount &lt;= 0) &#123; // No idle handlers to run. Loop and wait some more. // 当没有闲置handler需要执行的时候 mBlocked = true; continue; &#125; // 如果闲置handlers数组为空 if (mPendingIdleHandlers == null) &#123; // 初始化, 闲置的handlers最大数为4 mPendingIdleHandlers = new IdleHandler[Math.max(pendingIdleHandlerCount, 4)]; &#125; mPendingIdleHandlers = mIdleHandlers.toArray(mPendingIdleHandlers); &#125; // Run the idle handlers. // We only ever reach this code block during the first iteration. for (int i = 0; i &lt; pendingIdleHandlerCount; i++) &#123; final IdleHandler idler = mPendingIdleHandlers[i]; // 引用释放, 则这个循环只会执行mPendingIdleHandlers集合的第一个handler元素 mPendingIdleHandlers[i] = null; // release the reference to the handler boolean keep = false; try &#123; // 执行空闲回调处理 keep = idler.queueIdle(); &#125; catch (Throwable t) &#123; Log.wtf(TAG, "IdleHandler threw exception", t); &#125; // 假设空闲回调处理不保留这个闲置处理, 则移除对应的idleHandler if (!keep) &#123; synchronized (this) &#123; mIdleHandlers.remove(idler); &#125; &#125; &#125; // Reset the idle handler count to 0 so we do not run them again. // 重置 pendingIdleHandlerCount = 0; // While calling an idle handler, a new message could have been delivered // so go back and look again for a pending message without waiting. // 重置 nextPollTimeoutMillis = 0; &#125; &#125; 相关的代码注释差不多都在上面了, 我们主要整理下, 这里在做的事情 获取队列头部消息, 如果头部消息存在, 并且当前消息持有handler为空的情况下, 则去取下一个非空的同步消息 当该条消息是当前正需要执行的时候(具体看Message#when的时间戳), 则返回这条消息, 否则继续查找下一条消息 如果当前没有消息, 或者当前时间没有需要执行的消息, 则触发idleHandler的处理. 然后在下个时间戳继续找消息 回头看Handler#dispatchMessage(Message msg), 可以了解到handler处理事件的优先级123456789101112131415public void dispatchMessage(Message msg) &#123; // msg.callback通过handler.post传入的runnable if (msg.callback != null) &#123; handleCallback(msg); &#125; else &#123; if (mCallback != null) &#123; // mCallback是通过Handler的构造函数传入 if (mCallback.handleMessage(msg)) &#123; return; &#125; &#125; // 最后才是Message传入的处理, 一般是继承Handler, 重写handleMessage方法 handleMessage(msg); &#125; &#125; 关于Message的重复利用主流程基本分析完毕, 我们现在再回头看使用API, 一般的业务场景, 我们用到比较多的可能是自己新建包装一个Message, 通过Handler来发送. 那么Handler#obtainMessage()做了什么呢, 为什么通过这个自己可以不用再新建一个Message了. 我们看API调取, 会发现他内部调用到了Message#obtain(), 而最终message对象是从这里获取到.12345678910111213public static Message obtain() &#123; synchronized (sPoolSync) &#123; if (sPool != null) &#123; Message m = sPool; sPool = m.next; m.next = null; m.flags = 0; // clear in-use flag sPoolSize--; return m; &#125; &#125; return new Message(); &#125; 可以看到, 当sPool对象不为空的时候, 是复用了这个对象的内存空间.那么sPool又是什么时候被赋值的呢123456789101112131415161718192021222324void recycleUnchecked() &#123; // Mark the message as in use while it remains in the recycled object pool. // Clear out all other details. flags = FLAG_IN_USE; what = 0; arg1 = 0; arg2 = 0; obj = null; replyTo = null; sendingUid = -1; when = 0; target = null; callback = null; data = null; synchronized (sPoolSync) &#123; // MAX_POOL_SIZE == 50 if (sPoolSize &lt; MAX_POOL_SIZE) &#123; next = sPool; sPool = this; sPoolSize++; &#125; &#125; &#125; 这个方法是不是有点眼熟, 就是前面分析Looper#loop()时候, 当消息处理完以后, 消息回收调用到的, 可以看到sPool作为需要被回收的对象, 当消息处理完后, 当前消息进入当前回收队列中, 这样可以达到Message的复用作用]]></content>
      <categories>
        <category>源码解析</category>
      </categories>
      <tags>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeakCanary简易解析]]></title>
    <url>%2F2018%2F12%2F03%2FLeakCanary%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言本篇基于1.6.1版本源码阅读, 本篇内容就是搞懂LeakCanary如何做到内存泄漏定位的主要流程, 不抠具体细节. 正文老样子, 我们直接从从LeakCanary.install(this)作为入口开始看12345678910111213141516171819202122public static RefWatcher install(Application application) &#123; return refWatcher(application).listenerServiceClass(DisplayLeakService.class) .excludedRefs(AndroidExcludedRefs.createAppDefaults().build()) .buildAndInstall(); &#125; public RefWatcher buildAndInstall() &#123; if (LeakCanaryInternals.installedRefWatcher != null) &#123; throw new UnsupportedOperationException("buildAndInstall() should only be called once."); &#125; RefWatcher refWatcher = build(); if (refWatcher != DISABLED) &#123; if (watchActivities) &#123; ActivityRefWatcher.install(context, refWatcher); &#125; if (watchFragments) &#123; FragmentRefWatcher.Helper.install(context, refWatcher); &#125; &#125; LeakCanaryInternals.installedRefWatcher = refWatcher; return refWatcher; &#125; 通过AndroidRefWatcherBuilder对象进行一系列相关对象的初始化, 包括ServiceHeapDumpListener, ExcludedRefs,以及最重要的RefWatcher. ServiceHeapDumpListener:堆解析监听, 主要负责启动解析Heap服务以及负责处理引用路径的解析服务的连接 ExcludedRefs: 内存泄漏分析的白名单 RefWatcher: 观测引用是否弱可达, 通过它来观测是否该回收的内存未被回收导致内存泄漏, 如果存在这种情况, 会触发HeapDumper的记录 我们通过ActivityRefWatcher.install(context, refWatcher)查看Actvitiy的内存泄漏的分析流程12345678910111213public static void install(Context context, RefWatcher refWatcher) &#123; Application application = (Application) context.getApplicationContext(); ActivityRefWatcher activityRefWatcher = new ActivityRefWatcher(application, refWatcher); application.registerActivityLifecycleCallbacks(activityRefWatcher.lifecycleCallbacks); &#125; private final Application.ActivityLifecycleCallbacks lifecycleCallbacks = new ActivityLifecycleCallbacksAdapter() &#123; @Override public void onActivityDestroyed(Activity activity) &#123; refWatcher.watch(activity); &#125; &#125;; 可以看到注册了一个ActivityLifecycleCallbacks, 在页面生命周期走到onDestroy的时候, 会触发refWatcher.watch(activity)12345678910111213141516171819202122232425public void watch(Object watchedReference) &#123; watch(watchedReference, ""); &#125; /** * Watches the provided references and checks if it can be GCed. This method is non blocking, * the check is done on the &#123;@link WatchExecutor&#125; this &#123;@link RefWatcher&#125; has been constructed * with. * * @param referenceName An logical identifier for the watched object. */ public void watch(Object watchedReference, String referenceName) &#123; if (this == DISABLED) &#123; return; &#125; checkNotNull(watchedReference, "watchedReference"); checkNotNull(referenceName, "referenceName"); final long watchStartNanoTime = System.nanoTime(); String key = UUID.randomUUID().toString(); retainedKeys.add(key); final KeyedWeakReference reference = new KeyedWeakReference(watchedReference, key, referenceName, queue); ensureGoneAsync(watchStartNanoTime, reference); &#125; 申明弱引用, 放入activity对象, 注册关联queue引用队列1234567private void ensureGoneAsync(final long watchStartNanoTime, final KeyedWeakReference reference) &#123; watchExecutor.execute(new Retryable() &#123; @Override public Retryable.Result run() &#123; return ensureGone(reference, watchStartNanoTime); &#125; &#125;); &#125; 在AndroidRefWatcherBuilder可以通过watchDelay(long delay, TimeUnit unit)设置是否延迟观测, 如果有设置, 则会在保证在主线程内延迟进行分析内存泄漏; 否则直接执行分析处理123456789101112131415161718192021222324252627282930313233343536373839Retryable.Result ensureGone(final KeyedWeakReference reference, final long watchStartNanoTime) &#123; long gcStartNanoTime = System.nanoTime(); long watchDurationMs = NANOSECONDS.toMillis(gcStartNanoTime - watchStartNanoTime); removeWeaklyReachableReferences(); if (debuggerControl.isDebuggerAttached()) &#123; // The debugger can create false leaks. return RETRY; &#125; // 不存在内存泄漏的对象 if (gone(reference)) &#123; return DONE; &#125; // 重新执行gc gcTrigger.runGc(); removeWeaklyReachableReferences(); if (!gone(reference)) &#123; long startDumpHeap = System.nanoTime(); long gcDurationMs = NANOSECONDS.toMillis(startDumpHeap - gcStartNanoTime); File heapDumpFile = heapDumper.dumpHeap(); if (heapDumpFile == RETRY_LATER) &#123; // Could not dump the heap. return RETRY; &#125; long heapDumpDurationMs = NANOSECONDS.toMillis(System.nanoTime() - startDumpHeap); HeapDump heapDump = heapDumpBuilder.heapDumpFile(heapDumpFile).referenceKey(reference.key) .referenceName(reference.name) .watchDurationMs(watchDurationMs) .gcDurationMs(gcDurationMs) .heapDumpDurationMs(heapDumpDurationMs) .build(); heapdumpListener.analyze(heapDump); &#125; return DONE; &#125; 12345678private void removeWeaklyReachableReferences() &#123; // WeakReferences are enqueued as soon as the object to which they point to becomes weakly // reachable. This is before finalization or garbage collection has actually happened. KeyedWeakReference ref; while ((ref = (KeyedWeakReference) queue.poll()) != null) &#123; retainedKeys.remove(ref.key); &#125; &#125; 每个activity申明弱引用的时候都会有个ID, ID保存在retainedKeys集合中, 首先遍历移除被gc回收的对象, 如果这个时候retainedKeys集合为空, 则表示不存在内存泄漏的情况. 否则手动执行GC, 再次判断移除, 这个时候如果retainedKeys内仍存在ID, 则说明有内存泄漏的情况存在. 在存在内存泄漏的情况下, 通过heapDumper.dumpHeap()获取堆内存快照, 通过heapdumpListener.analyze去进行解析.1234public void analyze(HeapDump heapDump) &#123; checkNotNull(heapDump, "heapDump"); HeapAnalyzerService.runAnalysis(context, heapDump, listenerServiceClass); &#125; 123456789public static void runAnalysis(Context context, HeapDump heapDump, Class&lt;? extends AbstractAnalysisResultService&gt; listenerServiceClass) &#123; setEnabledBlocking(context, HeapAnalyzerService.class, true); setEnabledBlocking(context, listenerServiceClass, true); Intent intent = new Intent(context, HeapAnalyzerService.class); intent.putExtra(LISTENER_CLASS_EXTRA, listenerServiceClass.getName()); intent.putExtra(HEAPDUMP_EXTRA, heapDump); ContextCompat.startForegroundService(context, intent); &#125; 这里启动了HeapAnalyzerServiceIntentService, 这个服务主要做的就是去解析我们的.hprof文件, 主要的工作内容在onHandleIntentInForeground方法内123456789101112131415@Override protected void onHandleIntentInForeground(@Nullable Intent intent) &#123; if (intent == null) &#123; CanaryLog.d("HeapAnalyzerService received a null intent, ignoring."); return; &#125; String listenerClassName = intent.getStringExtra(LISTENER_CLASS_EXTRA); HeapDump heapDump = (HeapDump) intent.getSerializableExtra(HEAPDUMP_EXTRA); HeapAnalyzer heapAnalyzer = new HeapAnalyzer(heapDump.excludedRefs, this, heapDump.reachabilityInspectorClasses); AnalysisResult result = heapAnalyzer.checkForLeak(heapDump.heapDumpFile, heapDump.referenceKey, heapDump.computeRetainedHeapSize); AbstractAnalysisResultService.sendResultToListener(this, listenerClassName, heapDump, result); &#125; 然后通过haha库, 将.hprof文件解析结果AnalysisResult对象, 通过AbstractAnalysisResultService.sendResultToListener传递启动DisplayLeakService服务.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@Override protected final void onHeapAnalyzed(HeapDump heapDump, AnalysisResult result) &#123; String leakInfo = leakInfo(this, heapDump, result, true); CanaryLog.d("%s", leakInfo); boolean resultSaved = false; boolean shouldSaveResult = result.leakFound || result.failure != null; if (shouldSaveResult) &#123; heapDump = renameHeapdump(heapDump); resultSaved = saveResult(heapDump, result); &#125; PendingIntent pendingIntent; String contentTitle; String contentText; if (!shouldSaveResult) &#123; contentTitle = getString(R.string.leak_canary_no_leak_title); contentText = getString(R.string.leak_canary_no_leak_text); pendingIntent = null; &#125; else if (resultSaved) &#123; pendingIntent = DisplayLeakActivity.createPendingIntent(this, heapDump.referenceKey); if (result.failure == null) &#123; if (result.retainedHeapSize == AnalysisResult.RETAINED_HEAP_SKIPPED) &#123; String className = classSimpleName(result.className); if (result.excludedLeak) &#123; contentTitle = getString(R.string.leak_canary_leak_excluded, className); &#125; else &#123; contentTitle = getString(R.string.leak_canary_class_has_leaked, className); &#125; &#125; else &#123; String size = formatShortFileSize(this, result.retainedHeapSize); String className = classSimpleName(result.className); if (result.excludedLeak) &#123; contentTitle = getString(R.string.leak_canary_leak_excluded_retaining, className, size); &#125; else &#123; contentTitle = getString(R.string.leak_canary_class_has_leaked_retaining, className, size); &#125; &#125; &#125; else &#123; contentTitle = getString(R.string.leak_canary_analysis_failed); &#125; contentText = getString(R.string.leak_canary_notification_message); &#125; else &#123; contentTitle = getString(R.string.leak_canary_could_not_save_title); contentText = getString(R.string.leak_canary_could_not_save_text); pendingIntent = null; &#125; // New notification id every second. int notificationId = (int) (SystemClock.uptimeMillis() / 1000); showNotification(this, contentTitle, contentText, pendingIntent, notificationId); afterDefaultHandling(heapDump, result, leakInfo); &#125; 将对应的.hprof文件重命名, 对应泄漏的内存对象关联key, 传递到DisplayLeakActivity做显示, 另外进行通知显示. 总结通过上文的简易解析, 我们可以得出LeakCanary的一个大概的原理流程.通过application注册ActivityLifecycleCallbacks的回调, 在每个activity销毁的时候, 将activity的弱引用包装绑定在ReferenceQueue上, 当GC的时候, 可以通过queue移除已被回收的activity对象key, 获得始终未被回收的对象, 判断为是内存泄漏, 根据haha库解析heap dumps,获取引用路径最终在DisplayLeakActivity上显示我们熟悉的内存泄漏的列表内容.]]></content>
      <categories>
        <category>源码解析</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>源码解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于适配Replugin插件化框架的使用]]></title>
    <url>%2F2018%2F11%2F14%2F%E5%85%B3%E4%BA%8E%E9%80%82%E9%85%8DReplugin%E6%8F%92%E4%BB%B6%E5%8C%96%E6%A1%86%E6%9E%B6%E4%BD%BF%E7%94%A8%E7%9A%84%E8%B7%AF%E7%94%B1%E6%A1%86%E6%9E%B6%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[前言公司有内部开发的路由框架, 为了可适配Replugin插件化框架, 当前的路由框架肯定是不能使用的, 由于项目闭源, 这里主要讲下改造的思路 原路由设计思路以及主要问题以ARouter为例, 他的设计仅服务于组件化架构项目, 各模块通过APT收集路由信息,APP壳(应用壳)通过反射或者通过TranslateAPI + ASM技术进行动态注册路由映射表, (具体可参考之前的ARouter源码解析) 我们内部的路由大体的设计原理也差不多如上. 显而易见, 当要接入Replugin的时候, 会出现以下几个问题: Replugin当跨插件调用组件的时候(譬如Activity跳转), 携带的Intent需要设置ComponentName(参见Replugin Wiki 组件的调用), 那么我们在匹配到对应路由的进行页面跳转的时候, 启动方式需要一定的变动. 插件调用插件的组件, 有三种方法 123456789101112131415// 插件调用插件的组件// 方法1（最“单品”）Intent intent = new Intent();intent.setComponent(new ComponentName("demo2", "com.qihoo360.replugin.sample.demo2.databinding.DataBindingActivity"));context.startActivity(intent);// 方法2（快速创建Intent）Intent intent = RePlugin.createIntent("demo2", "com.qihoo360.replugin.sample.demo2.databinding.DataBindingActivity");context.startActivity(intent);// 方法3（一行搞定）RePlugin.startActivity(v.getContext(), new Intent(), "demo2", "com.qihoo360.replugin.sample.demo2.databinding.DataBindingActivity"); 宿主调用插件的组件, 必须使用Replugin的startActvityAPI12RePlugin.startActivity(MainActivity.this, RePlugin.createIntent("demo1", "com.qihoo360.replugin.sample.demo1.MainActivity")); 由于Replugin宿主和插件使用不同的ClassLoader, 变相导致插件和宿主的代码级隔离, 所以常用的通过反射or使用ASM获取路由映射表动态注册的方式就无法解决. 一版改造设计思路原来参考网上的资料, 是考量各插件维护自身的路由映射表, 当宿主动态加载插件的时候, 主动启动插件, 路由框架提供远程服务通过AIDL通信实现各插件的路由可以共享, 而关于组件的跳转, 将其抽象有外部业务项目初始化时进行实现. 具体思路流程可看下图但是这样又有两个问题出现了: 通过AIDL传输路由, 存在一定的性能消耗 另外很重要的一个问题是, 目前内部路由存在路由协议无法与对应页面所在插件匹配的情况下, 那么, 当宿主或者插件需要根据对应的路由跳转到对应的插件下组件的时候, 从路由信息上是无法获取需要启动哪个插件 基于此, 我们走了另外一个方向 当前适配插件化路由设计思路由于上文的问题, 最终决定不沿用参考文中的动态路由加载的方案, 而改为将路由表都由宿主来统一管理. 那么这样也可以排除掉了当路由无法找到的时候, 需要去判断是目标插件未启动or未down的情况(针对内置插件的情况).主要思路如下: 插件在编译期通过APT收集路由信息, 生成JSON文件, 放在assets中 针对内置插件, 插件放入宿主的assets/plugins文件夹后, 参考Replugin的宿主gradle plugin的做法, 解析插件获取插件资源内的路由表, copy到宿主的assets中, 由宿主进行维护; 而针对外置插件, 需要插件上传时配合上传路由表, 宿主在初始化的时候可以请求服务端获取到外置插件的路由(关于外置插件路由获取方案目前只是设想, 由于当前的需求环境, 所以并未去实现) 宿主在初始化的时候, 获取路由json, 解析保存在内存中. 那么按以上流程, 路由需要做的工作, 主要就存在于原来annotation处理的逻辑修改和plugin的修改上, 相对来说, 改动点不大. 参考 Router: 教你如何进行任意插件化环境下的路由适配]]></content>
      <categories>
        <category>日常开发踩坑记录</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>路由</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[okHttp3源码解析(三)-CallServerInterceptor]]></title>
    <url>%2F2018%2F08%2F29%2FOkHttp%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%89)-CallServerInterceptor%2F</url>
    <content type="text"><![CDATA[前言本篇主要看下CallServerInterceptor, 关于他在整个请求中起到的作用, okHttp已经告诉我们, 可以看出它作为责任链中的最后一个环节, 承担了对服务端进行请求的工作. This is the last interceptor in the chain. It makes a network call to the server. 正文okHttp对于对服务钱的请求与相应, 底层都是通过okio对socket进行操作.老样子, 我们直接上代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123@Override public Response intercept(Chain chain) throws IOException &#123; RealInterceptorChain realChain = (RealInterceptorChain) chain; // 在 ConnectInterceptor创建 HttpCodec httpCodec = realChain.httpStream(); // 在 RetryAndFollowUpInterceptor创建 StreamAllocation streamAllocation = realChain.streamAllocation(); // 在 ConnectInterceptor获取 RealConnection connection = (RealConnection) realChain.connection(); Request request = realChain.request(); // 发送请求时间戳为当前时间戳 long sentRequestMillis = System.currentTimeMillis(); realChain.eventListener().requestHeadersStart(realChain.call()); // 发送请求头, 通过Okio httpCodec.writeRequestHeaders(request); realChain.eventListener().requestHeadersEnd(realChain.call(), request); Response.Builder responseBuilder = null; // GET or HEAD 不需要 if (HttpMethod.permitsRequestBody(request.method()) &amp;&amp; request.body() != null) &#123; // If there's a "Expect: 100-continue" header on the request, wait for a "HTTP/1.1 100 // Continue" response before transmitting the request body. If we don't get that, return // what we did get (such as a 4xx response) without ever transmitting the request body. if ("100-continue".equalsIgnoreCase(request.header("Expect"))) &#123; // 请求刷新, okio处理 httpCodec.flushRequest(); realChain.eventListener().responseHeadersStart(realChain.call()); // 构建Response.Builder, 当response状态为100, 则返回null responseBuilder = httpCodec.readResponseHeaders(true); &#125; if (responseBuilder == null) &#123; // head成功响应的情况下 // Write the request body if the "Expect: 100-continue" expectation was met. realChain.eventListener().requestBodyStart(realChain.call()); long contentLength = request.body().contentLength(); // 请求体的输出流 CountingSink requestBodyOut = new CountingSink(httpCodec.createRequestBody(request, contentLength)); BufferedSink bufferedRequestBody = Okio.buffer(requestBodyOut); // 发送请求体 request.body().writeTo(bufferedRequestBody); bufferedRequestBody.close(); realChain.eventListener() .requestBodyEnd(realChain.call(), requestBodyOut.successfulCount); &#125; else if (!connection.isMultiplexed()) &#123; // HTTP/1请求协议, 而且初次握手失败 // If the "Expect: 100-continue" expectation wasn't met, prevent the HTTP/1 connection // from being reused. Otherwise we're still obligated to transmit the request body to // leave the connection in a consistent state. // 禁止同主机请求新流的分配 streamAllocation.noNewStreams(); &#125; &#125; // flush httpCodec.finishRequest(); // 如果是GET请求, 或者需要'100- continue'握手成功的情况下 if (responseBuilder == null) &#123; realChain.eventListener().responseHeadersStart(realChain.call()); // 构建responseBuilder responseBuilder = httpCodec.readResponseHeaders(false); &#125; // 获取响应 Response response = responseBuilder // 原请求 .request(request) // 握手情况 .handshake(streamAllocation.connection().handshake()) // 请求时间 .sentRequestAtMillis(sentRequestMillis) // 响应时间 .receivedResponseAtMillis(System.currentTimeMillis()) .build(); int code = response.code(); if (code == 100) &#123; // server sent a 100-continue even though we did not request one. // try again to read the actual response // 即使我们没有请求, 服务端也会发送一个100-continue // 重新读取真正的响应 responseBuilder = httpCodec.readResponseHeaders(false); // 构建response response = responseBuilder .request(request) .handshake(streamAllocation.connection().handshake()) .sentRequestAtMillis(sentRequestMillis) .receivedResponseAtMillis(System.currentTimeMillis()) .build(); code = response.code(); &#125; realChain.eventListener() .responseHeadersEnd(realChain.call(), response); if (forWebSocket &amp;&amp; code == 101) &#123; // Connection is upgrading, but we need to ensure interceptors see a non-null response body. // 我们需要确保不会反悔一个空的响应体 response = response.newBuilder() .body(Util.EMPTY_RESPONSE) .build(); &#125; else &#123; response = response.newBuilder() .body(httpCodec.openResponseBody(response)) .build(); &#125; // 如果请求关闭连接, 则关闭 if ("close".equalsIgnoreCase(response.request().header("Connection")) || "close".equalsIgnoreCase(response.header("Connection"))) &#123; streamAllocation.noNewStreams(); &#125; // 抛出协议异常 // 204: No Content // 205: Reset Content if ((code == 204 || code == 205) &amp;&amp; response.body().contentLength() &gt; 0) &#123; throw new ProtocolException( "HTTP " + code + " had non-zero Content-Length: " + response.body().contentLength()); &#125; return response; &#125; 请求我们来一步步看下代码12345678RealInterceptorChain realChain = (RealInterceptorChain) chain; // 在 ConnectInterceptor创建 HttpCodec httpCodec = realChain.httpStream(); // 在 RetryAndFollowUpInterceptor创建 StreamAllocation streamAllocation = realChain.streamAllocation(); // 在 ConnectInterceptor获取 RealConnection connection = (RealConnection) realChain.connection(); Request request = realChain.request(); 在CallServerInterceptor在, 核心工具类就是HttpCodec, 他的初始化我们在上篇ConnectInterceptor解析中可以看到.这里的步骤其实就是工具的准备.1httpCodec.writeRequestHeaders(request); 我们以HTTP/1.1协议来看, 那么具体要看Http1Codec中的实现1234567891011121314151617181920@Override public void writeRequestHeaders(Request request) throws IOException &#123; // requestLine 就是我们请求报文内容的首行, 譬如 "GET / HTTP/1.1" String requestLine = RequestLine.get( request, streamAllocation.connection().route().proxy().type()); writeRequest(request.headers(), requestLine); &#125; final BufferedSink sink; public void writeRequest(Headers headers, String requestLine) throws IOException &#123; if (state != STATE_IDLE) throw new IllegalStateException("state: " + state); sink.writeUtf8(requestLine).writeUtf8("\r\n"); for (int i = 0, size = headers.size(); i &lt; size; i++) &#123; sink.writeUtf8(headers.name(i)) .writeUtf8(": ") .writeUtf8(headers.value(i)) .writeUtf8("\r\n"); &#125; sink.writeUtf8("\r\n"); state = STATE_OPEN_REQUEST_BODY; &#125; 可以看到在writeRequest中的方法, 就是针对BufferedSink对象的写操作, 在上篇ConnectInterceptor中进行三次握手连接的时候, 会进行初始化的工作, 我们会发现他是针对Socket的包装, 可以看做是Socket的输出流, 所以这里相当于是Socket的写入动作, 可以看出来, 这里会请求发送header.1234567891011121314151617181920212223242526272829if (HttpMethod.permitsRequestBody(request.method()) &amp;&amp; request.body() != null) &#123; if ("100-continue".equalsIgnoreCase(request.header("Expect"))) &#123; // 请求刷新, okio处理 httpCodec.flushRequest(); realChain.eventListener().responseHeadersStart(realChain.call()); // 构建Response.Builder, 当response状态为100, 则返回null responseBuilder = httpCodec.readResponseHeaders(true); &#125; if (responseBuilder == null) &#123; // head成功响应的情况下 // Write the request body if the "Expect: 100-continue" expectation was met. realChain.eventListener().requestBodyStart(realChain.call()); long contentLength = request.body().contentLength(); // 请求体的输出流 CountingSink requestBodyOut = new CountingSink(httpCodec.createRequestBody(request, contentLength)); BufferedSink bufferedRequestBody = Okio.buffer(requestBodyOut); // 发送请求体 request.body().writeTo(bufferedRequestBody); bufferedRequestBody.close(); realChain.eventListener() .requestBodyEnd(realChain.call(), requestBodyOut.successfulCount); &#125; else if (!connection.isMultiplexed()) &#123; // HTTP/1请求协议, 而且初次握手失败 // 禁止同主机请求新流的分配 streamAllocation.noNewStreams(); &#125; &#125; 当请求首部字段包含Expect:100-continue, 一般在请求上传大容量body或者是需要验证的时候, 这样避免大文件传送失败带来的带宽浪费。所以需要判断请求体不为空的情况下, 并且请求首部包含该字段的情况下, 刷新请求, 构建responseBuilder对象, 如果这个时候服务端响应成功, 则responseBuilder对象为null, 并进行body的请求;而如果第一次请求头响应失败的情况下, 那么如果是HTTP/1的请求协议下, 就会禁止同host的请求新流的分配. 响应以上就是请求的过程, 然后看响应12345678910111213141516// 如果是GET请求, 或者需要'100- continue'握手成功的情况下 if (responseBuilder == null) &#123; // 构建responseBuilder responseBuilder = httpCodec.readResponseHeaders(false); &#125; // 获取响应 Response response = responseBuilder // 原请求 .request(request) // 握手情况 .handshake(streamAllocation.connection().handshake()) // 请求时间 .sentRequestAtMillis(sentRequestMillis) // 响应时间 .receivedResponseAtMillis(System.currentTimeMillis()) .build(); 在请求成功的情况下, 会重新构建responseBuilder对象, 通过它来构建响应报文.123456789101112131415int code = response.code(); if (code == 100) &#123; // 即使我们没有请求, 服务端也会发送一个100-continue // 重新读取真正的响应 responseBuilder = httpCodec.readResponseHeaders(false); // 构建response response = responseBuilder .request(request) .handshake(streamAllocation.connection().handshake()) .sentRequestAtMillis(sentRequestMillis) .receivedResponseAtMillis(System.currentTimeMillis()) .build(); code = response.code(); &#125; 如果客户端响应100状态码, 这个时候, 我们就需要重新读取获取真正的内容响应. 剩下的代码就是一些异常的处理, 这里就不做分析了.]]></content>
      <categories>
        <category>源码解析</category>
      </categories>
      <tags>
        <tag>源码解析</tag>
        <tag>okHttp3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[okHttp3源码解析(二)-ConnectInterceptor]]></title>
    <url>%2F2018%2F08%2F24%2FokHttp%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%BA%8C)-ConnectInterceptor%2F</url>
    <content type="text"><![CDATA[前言上文简单概括了下okHttp3请求的整体流程, 本篇主要看下ConnectInterceptor的主要工作内容 正文已知拦截器链都是从各拦截器的intercept方法开始调用, 那么我们从ConnectInterceptor的intercept代码开始看起1234567891011121314@Override public Response intercept(Chain chain) throws IOException &#123; RealInterceptorChain realChain = (RealInterceptorChain) chain; Request request = realChain.request(); // 从RetryAndFollowUpInterceptor获取 StreamAllocation streamAllocation = realChain.streamAllocation(); // 判断请求是不是GET方法, 不是的情况下,需要进行有效监测 boolean doExtensiveHealthChecks = !request.method().equals("GET"); // 新建HttpCodec HttpCodec httpCodec = streamAllocation.newStream(client, chain, doExtensiveHealthChecks); RealConnection connection = streamAllocation.connection(); return realChain.proceed(request, streamAllocation, httpCodec, connection); &#125; 我们可以看到, 获取连接的拦截器内, 主要只有三个步骤: 初始化HttpCodec 通过streamAllocation获取连接 将httpCodec和connection作为参数带到下个拦截器的调用方法中 这里HttpCodec我们可以大概了解下, 它是个抽象类, 有Http1Codec和Http2Codec实现它, 分别根据Http/1.1,和Http/2做针对请求响应不同的编解码处理. 而StreamAllocation对象是在RetryAndFollowUpInterceptor中新建获取到的, 它做了Streams, Connections, Calls的关系管理.这里要注意的是Streams表示的是逻辑层面的连接(流), 每个连接(Connection)都定义了可以并发请求的连接(Streams), HTTP/1.x每次只能携带一次, HTTP/2可以携带多次. 回头我们看下streamAllocation.newStream做了什么1234567891011121314151617181920212223public HttpCodec newStream( OkHttpClient client, Interceptor.Chain chain, boolean doExtensiveHealthChecks) &#123; int connectTimeout = chain.connectTimeoutMillis(); int readTimeout = chain.readTimeoutMillis(); int writeTimeout = chain.writeTimeoutMillis(); int pingIntervalMillis = client.pingIntervalMillis(); boolean connectionRetryEnabled = client.retryOnConnectionFailure(); try &#123; // 遍历查找健康可用的连接 RealConnection resultConnection = findHealthyConnection(connectTimeout, readTimeout, writeTimeout, pingIntervalMillis, connectionRetryEnabled, doExtensiveHealthChecks); // HttpCodec初始化 HttpCodec resultCodec = resultConnection.newCodec(client, chain, this); synchronized (connectionPool) &#123; codec = resultCodec; return resultCodec; &#125; &#125; catch (IOException e) &#123; throw new RouteException(e); &#125; &#125; 可以看到它这里也就做了三个动作 配置连接超时, 读取超时, 写超时的时间. 查找健康可用的连接 根据可用连接初始化HttpCodec 继续往下看:12345678910111213141516171819202122232425262728private RealConnection findHealthyConnection(int connectTimeout, int readTimeout, int writeTimeout, int pingIntervalMillis, boolean connectionRetryEnabled, boolean doExtensiveHealthChecks) throws IOException &#123; while (true) &#123; // 查找连接, 更加倾向连接池内已存在的连接, 否则会重新构建 RealConnection candidate = findConnection(connectTimeout, readTimeout, writeTimeout, pingIntervalMillis, connectionRetryEnabled); // If this is a brand new connection, we can skip the extensive health checks. // 如果是全新的连接, 则跳过可用检查, 直接返回 synchronized (connectionPool) &#123; if (candidate.successCount == 0) &#123; return candidate; &#125; &#125; // Do a (potentially slow) check to confirm that the pooled connection is still good. If it // isn't, take it out of the pool and start again. // 判断是否是可用连接 if (!candidate.isHealthy(doExtensiveHealthChecks)) &#123; // 禁止新流创建 noNewStreams(); continue; &#125; return candidate; &#125; &#125; 循环查找连接 如果是全新的连接, 则跳过检查, 直接返回 判断是否可用连接, 如果不是, 则禁止新流创建 继续看findConnection方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150/** * Returns a connection to host a new stream. This prefers the existing connection if it exists, * then the pool, finally building a new connection. */ private RealConnection findConnection(int connectTimeout, int readTimeout, int writeTimeout, int pingIntervalMillis, boolean connectionRetryEnabled) throws IOException &#123; // 从连接池中找到连接 boolean foundPooledConnection = false; // 实际需要返回的连接 RealConnection result = null; // 对应找到的路由 Route selectedRoute = null; // 对应可释放的连接 Connection releasedConnection; // 需要关闭的socket Socket toClose; synchronized (connectionPool) &#123; // 异常判断 // 判断是否连接已经被释放, codec是否为空, 请求是否被取消 if (released) throw new IllegalStateException("released"); if (codec != null) throw new IllegalStateException("codec != null"); if (canceled) throw new IOException("Canceled"); // 尝试寻找已经存在的连接来使用. // 但是需要注意的是, 已存在的连接可能已经无法再创建新的流 // Attempt to use an already-allocated connection. We need to be careful here because our // already-allocated connection may have been restricted from creating new streams. releasedConnection = this.connection; // toClose如果无法创建流, 需要关闭的socket toClose = releaseIfNoNewStreams(); if (this.connection != null) &#123; // We had an already-allocated connection and it's good. // 如果当前连接不为空, 就说明这个连接是可以用的 result = this.connection; releasedConnection = null; &#125; if (!reportedAcquired) &#123; // If the connection was never reported acquired, don't report it as released! releasedConnection = null; &#125; // 如果没有现成的连接 if (result == null) &#123; // Attempt to get a connection from the pool. // 尝试从连接池中获取 Internal.instance.get(connectionPool, address, this, null); // 如果有复用的连接 if (connection != null) &#123; // 表示找到连接池可复用的连接 foundPooledConnection = true; result = connection; &#125; else &#123; selectedRoute = route; &#125; &#125; &#125; // 关闭socket closeQuietly(toClose); if (releasedConnection != null) &#123; eventListener.connectionReleased(call, releasedConnection); &#125; if (foundPooledConnection) &#123; eventListener.connectionAcquired(call, result); &#125; if (result != null) &#123; // If we found an already-allocated or pooled connection, we're done. // 如果有存在已分配的连接或者是连接池内可复用的连接, 则直接返回该连接对象 return result; &#125; // If we need a route selection, make one. This is a blocking operation. boolean newRouteSelection = false; if (selectedRoute == null &amp;&amp; (routeSelection == null || !routeSelection.hasNext())) &#123; newRouteSelection = true; // 切换路由 routeSelection = routeSelector.next(); &#125; synchronized (connectionPool) &#123; if (canceled) throw new IOException("Canceled"); if (newRouteSelection) &#123; // Now that we have a set of IP addresses, make another attempt at getting a connection from // the pool. This could match due to connection coalescing. List&lt;Route&gt; routes = routeSelection.getAll(); for (int i = 0, size = routes.size(); i &lt; size; i++) &#123; Route route = routes.get(i); // 获取可复用的连接 Internal.instance.get(connectionPool, address, this, route); // 如果存在可复用连接 if (connection != null) &#123; foundPooledConnection = true; result = connection; this.route = route; break; &#125; &#125; &#125; // 如果没有找到可复用的连接 if (!foundPooledConnection) &#123; // 如果当前路由为空 if (selectedRoute == null) &#123; selectedRoute = routeSelection.next(); &#125; // Create a connection and assign it to this allocation immediately. This makes it possible // for an asynchronous cancel() to interrupt the handshake we're about to do. route = selectedRoute; refusedStreamCount = 0; // 创建新的连接 result = new RealConnection(connectionPool, selectedRoute); acquire(result, false); &#125; &#125; // If we found a pooled connection on the 2nd time around, we're done. // 如果第二次有找到, 则返回复用的连接 if (foundPooledConnection) &#123; eventListener.connectionAcquired(call, result); return result; &#125; // Do TCP + TLS handshakes. This is a blocking operation. // 做三次握手 result.connect(connectTimeout, readTimeout, writeTimeout, pingIntervalMillis, connectionRetryEnabled, call, eventListener); // 将该路由从错误缓存记录中移除 routeDatabase().connected(result.route()); Socket socket = null; synchronized (connectionPool) &#123; reportedAcquired = true; // Pool the connection. // 在连接池中添加该连接 Internal.instance.put(connectionPool, result); // If another multiplexed connection to the same address was created concurrently, then // release this connection and acquire that one. // 如果有其他复数连接到相同地址, 则删除重复连接 if (result.isMultiplexed()) &#123; socket = Internal.instance.deduplicate(connectionPool, address, this); result = connection; &#125; &#125; closeQuietly(socket); eventListener.connectionAcquired(call, result); return result; &#125; 其实看方法注释, 我们大概可以知道这里做的就是返回一个连接, 首先会从连接池中来, 如果连接池中没有对应连接, 则再重新新建一个连接. 具体的注释都在代码里了, 我们再看下其中几个调用方法.首先我们将即将要释放的连接指向当前的连接, 通过调用releaseIfNoNewStreams方法, 返回需要关闭的socket我们来看下releaseIfNoNewStreams方法的代码123456789101112131415/** * 如果当前连接无法新建流, 释放当前连接, 并且返回需要关闭的socket * 由于http2复数请求会使用同一个连接, 所以可能存在当前连接限制后续的请求 */ private Socket releaseIfNoNewStreams() &#123; // 断言锁持有 assert (Thread.holdsLock(connectionPool)); RealConnection allocatedConnection = this.connection; // 当当前连接不为空, 而且没有新的流被创建 if (allocatedConnection != null &amp;&amp; allocatedConnection.noNewStreams) &#123; return deallocate(false, false, true); &#125; // 正常情况, 没有需要被关闭的socket返回 return null; &#125; 可以看到只有当当前连接存在, 而且不允许有新的流产生的时候, 才会返回执行deallocate(false, false, true)后的结果, 正常的情况下, 没有需要被关闭的socket返回关于deallocate方法, 可以看下面的代码1234567891011121314151617181920212223242526272829303132333435363738394041424344private Socket deallocate(boolean noNewStreams, boolean released, boolean streamFinished) &#123; assert (Thread.holdsLock(connectionPool)); if (streamFinished) &#123; this.codec = null; &#125; if (released) &#123; this.released = true; &#125; Socket socket = null; if (connection != null) &#123; if (noNewStreams) &#123; connection.noNewStreams = true; &#125; if (this.codec == null &amp;&amp; (this.released || connection.noNewStreams)) &#123; // 释放连接 release(connection); // 如果这个连接的当前的流为空 if (connection.allocations.isEmpty()) &#123; // 当连接的流为0时候的记录时间戳 connection.idleAtNanos = System.nanoTime(); // 判断连接是否闲置 if (Internal.instance.connectionBecameIdle(connectionPool, connection)) &#123; // 如果闲置, 则返回需要关闭的socket socket = connection.socket(); &#125; &#125; // 回收 connection = null; &#125; &#125; return socket; &#125; private void release(RealConnection connection) &#123; for (int i = 0, size = connection.allocations.size(); i &lt; size; i++) &#123; Reference&lt;StreamAllocation&gt; reference = connection.allocations.get(i); if (reference.get() == this) &#123; connection.allocations.remove(i); return; &#125; &#125; throw new IllegalStateException(); &#125; 可以看到这里具体做的就是, 编解码类对象codec赋值为null, 调用release释放连接, 当这个connection没有连接流的时候, 一并判断连接是否闲置, 如果闲置, 则返回对应的socket, 并将当前的connection赋值为null.而这里的release方法主要做的就是移除连接对应流引用的移除. 我们回头去看findConnection方法内下一步123456if (this.connection != null) &#123; // We had an already-allocated connection and it's good. // 如果当前连接不为空, 就说明这个连接是可以用的 result = this.connection; releasedConnection = null; &#125; 我们知道前面调用releaseIfNoNewStreams的时候, 如果有返回socket, 那么connection也会被置为null, 所以这里connection不为空, 说明就是现在的连接是可以用的, 那么需要释放连接的对象就为null, 没必要被释放.1234567891011121314// 如果没有现成的连接 if (result == null) &#123; // Attempt to get a connection from the pool. // 尝试从连接池中获取 Internal.instance.get(connectionPool, address, this, null); // 如果有复用的连接 if (connection != null) &#123; // 表示找到连接池可复用的连接 foundPooledConnection = true; result = connection; &#125; else &#123; selectedRoute = route; &#125; &#125; 而如果没有可用的连接, 那么就会从连接池中尝试获取12345678910111213141516171819202122232425/** * 返回一个可重用的连接, 如果没有对应连接存在, 则返回null */@Nullable RealConnection get(Address address, StreamAllocation streamAllocation, Route route) &#123; // 断言锁的持有 assert (Thread.holdsLock(this)); // 遍历 for (RealConnection connection : connections) &#123; // 判断连接是否可复用 if (connection.isEligible(address, route)) &#123; streamAllocation.acquire(connection, true); return connection; &#125; &#125; return null;&#125;public void acquire(RealConnection connection, boolean reportedAcquired) &#123; assert (Thread.holdsLock(connectionPool)); if (this.connection != null) throw new IllegalStateException(); this.connection = connection; this.reportedAcquired = reportedAcquired; // 添加一个流的引用 connection.allocations.add(new StreamAllocationReference(this, callStackTrace));&#125; 可以看到, 如果当前连接池中有连接可复用, 则会将新的流引用添加在connection.allocations中.1234567891011121314// 关闭socket closeQuietly(toClose); if (releasedConnection != null) &#123; eventListener.connectionReleased(call, releasedConnection); &#125; if (foundPooledConnection) &#123; eventListener.connectionAcquired(call, result); &#125; if (result != null) &#123; // If we found an already-allocated or pooled connection, we're done. // 如果有存在已分配的连接或者是连接池内可复用的连接, 则直接返回该连接对象 return result; &#125; 再回到主方法内, 不论是否有找到可用的连接, 都会关闭socket, 然后根据是否存在需要释放的连接, 回调eventListener.connectionReleased, 并根据是否找到连接池内可用连接, 回调eventListener.connectionAcquired.当有实际可用的连接的时候, 那么直接返回该连接对象.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849boolean newRouteSelection = false; if (selectedRoute == null &amp;&amp; (routeSelection == null || !routeSelection.hasNext())) &#123; newRouteSelection = true; // 切换路由 routeSelection = routeSelector.next(); &#125; synchronized (connectionPool) &#123; if (canceled) throw new IOException("Canceled"); if (newRouteSelection) &#123; // Now that we have a set of IP addresses, make another attempt at getting a connection from // the pool. This could match due to connection coalescing. List&lt;Route&gt; routes = routeSelection.getAll(); for (int i = 0, size = routes.size(); i &lt; size; i++) &#123; Route route = routes.get(i); // 获取可复用的连接 Internal.instance.get(connectionPool, address, this, route); // 如果存在可复用连接 if (connection != null) &#123; foundPooledConnection = true; result = connection; this.route = route; break; &#125; &#125; &#125; // 如果没有找到可复用的连接 if (!foundPooledConnection) &#123; // 如果当前路由为空 if (selectedRoute == null) &#123; selectedRoute = routeSelection.next(); &#125; // Create a connection and assign it to this allocation immediately. This makes it possible // for an asynchronous cancel() to interrupt the handshake we're about to do. route = selectedRoute; refusedStreamCount = 0; // 创建新的连接 result = new RealConnection(connectionPool, selectedRoute); acquire(result, false); &#125; &#125; // If we found a pooled connection on the 2nd time around, we're done. // 如果第二次有找到, 则返回复用的连接 if (foundPooledConnection) &#123; eventListener.connectionAcquired(call, result); return result; &#125; 当仍然没有找到连接的时候, 那么就会切换路由, 再次从连接池内找对应路由可复用的连接, 如果有找到, 则返回这次复用的连接对象. 123456789101112131415161718192021222324252627// Do TCP + TLS handshakes. This is a blocking operation. // 做三次握手 result.connect(connectTimeout, readTimeout, writeTimeout, pingIntervalMillis, connectionRetryEnabled, call, eventListener); // 将该路由从错误缓存记录中移除 routeDatabase().connected(result.route()); Socket socket = null; synchronized (connectionPool) &#123; reportedAcquired = true; // Pool the connection. // 在连接池中添加该连接 Internal.instance.put(connectionPool, result); // If another multiplexed connection to the same address was created concurrently, then // release this connection and acquire that one. // 如果有其他复数连接到相同地址, 则删除重复连接 if (result.isMultiplexed()) &#123; socket = Internal.instance.deduplicate(connectionPool, address, this); result = connection; &#125; &#125; closeQuietly(socket); eventListener.connectionAcquired(call, result); return result; 但如果这次仍然没有找到对应可用的连接, 则只好新建连接, 并将流引用加到对应的conection对象中, 然后做三次握手, 并将对应的路由从错误缓存中移除.最后还做了重复连接的去重的工作, 然后再返回这个新建的连接对象. 截止至此, 寻找可用连接的代码分析就完成了. 回头再看下HttpCodec的初始化1234567891011public HttpCodec newCodec(OkHttpClient client, Interceptor.Chain chain, StreamAllocation streamAllocation) throws SocketException &#123; if (http2Connection != null) &#123; return new Http2Codec(client, chain, streamAllocation, http2Connection); &#125; else &#123; socket.setSoTimeout(chain.readTimeoutMillis()); source.timeout().timeout(chain.readTimeoutMillis(), MILLISECONDS); sink.timeout().timeout(chain.writeTimeoutMillis(), MILLISECONDS); return new Http1Codec(client, streamAllocation, source, sink); &#125; &#125; 主要就是根据判断是Http1还是Http2来判断新建哪个编解码类. 总结可以看出, ConnectionInterceptor拦截器, 主要做的是, 获取当前连接(connection), 如果不可用, 则从连接池中获取可复用连接, 如果仍然获取不到, 则新建连接 通过连接, 生成HttpCodec对象]]></content>
      <categories>
        <category>源码解析</category>
      </categories>
      <tags>
        <tag>源码解析</tag>
        <tag>okHttp3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[okHttp3源码解析(一)]]></title>
    <url>%2F2018%2F08%2F20%2FokHttp%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[源码基于3.11.0版本 okHttp的请求分为两种, 同步和异步的.本篇主要了解下两种请求的请求流程, 差异. 同步请求我们先看下同步请求api的使用12345678val okHttpClient by lazy &#123; OkHttpClient() &#125;private fun synchronousRun(url: String): String?&#123; val request = Request.Builder() .url(url) .build() val response = okHttpClient.newCall(request).execute() return response?.body()?.string() &#125; RequestRequest的代码就不看了, 可以看出是使用建造者模式, 根据具体配置去build.要注意的是, 这里传入的url, 如果是websocket协议的url, 会替换成http, 最后url会包装成一个HttpUrl对象123456789101112public Builder url(String url) &#123; if (url == null) throw new NullPointerException("url == null"); // Silently replace web socket URLs with HTTP URLs. if (url.regionMatches(true, 0, "ws:", 0, 3)) &#123; url = "http:" + url.substring(3); &#125; else if (url.regionMatches(true, 0, "wss:", 0, 4)) &#123; url = "https:" + url.substring(4); &#125; return url(HttpUrl.get(url)); &#125; 另外关于GET的请求, 在Request构造器初始的时候, 就会默认为GET请求, 所以如果是POST请求的时候, 需要调用Request.Build().post(body)方法1234567public Builder() &#123; this.method = "GET"; this.headers = new Headers.Builder(); &#125;public Builder post(RequestBody body) &#123; return method("POST", body);&#125; 我们可以看下Request可配置项, 分别包含一个Url, 一个请求的方法, header列表, 请求体和tags(关于tags我们后续再讲) Call请求需要准备一个Call对象, 他表示在未来的时间点内可以随时执行准备好的请求. 我们可以看到实际执行的时候, 其实使用的是RealCall对象, 具体看下请求执行的过程123@Override public Call newCall(Request request) &#123; return RealCall.newRealCall(this, request, false /* for web socket */); &#125; execute123456789101112131415161718192021222324@Override public Response execute() throws IOException &#123; synchronized (this) &#123; if (executed) throw new IllegalStateException("Already Executed"); executed = true; &#125; // 创建一个跟踪当前执行方法的堆栈, 赋值在失败重试的拦截器中 captureCallStackTrace(); // 监听 eventListener.callStart(this); try &#123; // 通过dispatcher做管理, 将call加入同步请求队列中 client.dispatcher().executed(this); // 获取返回的结果, 并执行一系列拦截器处理 Response result = getResponseWithInterceptorChain(); if (result == null) throw new IOException("Canceled"); return result; &#125; catch (IOException e) &#123; eventListener.callFailed(this, e); throw e; &#125; finally &#123; // 通过dispatcher通知结束 client.dispatcher().finished(this); &#125; &#125; executed表示对应的call是否已经执行, 这里同步锁可以避免了竞态条件的出现, 可以看出一个call实例只能被执行一次, 是一个”消耗品”关于Dispatcher我们可以看下在同步请求下他具体的执行和结束的代码123456789101112131415161718192021222324// 执行方法synchronized void executed(RealCall call) &#123; runningSyncCalls.add(call); &#125;// 通知结束void finished(RealCall call) &#123; finished(runningSyncCalls, call, false); &#125; private &lt;T&gt; void finished(Deque&lt;T&gt; calls, T call, boolean promoteCalls) &#123; int runningCallsCount; Runnable idleCallback; synchronized (this) &#123; // 移除call if (!calls.remove(call)) throw new AssertionError("Call wasn't in-flight!"); if (promoteCalls) promoteCalls(); runningCallsCount = runningCallsCount(); idleCallback = this.idleCallback; &#125; // 判断当前异步请求和同步请求数总和是否为0, 如果为0 则调用闲置时候的回调 if (runningCallsCount == 0 &amp;&amp; idleCallback != null) &#123; idleCallback.run(); &#125; &#125; 可以看到在同步请求的时候, dispatcher的执行和完成通知, 实际是针对于runningSyncCalls对象的管理.1234567891011121314151617181920212223242526Response getResponseWithInterceptorChain() throws IOException &#123; // Build a full stack of interceptors. List&lt;Interceptor&gt; interceptors = new ArrayList&lt;&gt;(); // 自定义拦截器 interceptors.addAll(client.interceptors()); // 失败重试或者重定向的拦截器 interceptors.add(retryAndFollowUpInterceptor); // 请求和响应的转换处理拦截器 interceptors.add(new BridgeInterceptor(client.cookieJar())); // 缓存拦截器, 从缓存中请求并将响应写入缓存 interceptors.add(new CacheInterceptor(client.internalCache())); // 建立连接拦截器, 并继续下一个拦截器 interceptors.add(new ConnectInterceptor(client)); if (!forWebSocket) &#123; // 用户自定义的拦截器 interceptors.addAll(client.networkInterceptors()); &#125; // 最后一个拦截器, 处理网络调用服务器 interceptors.add(new CallServerInterceptor(forWebSocket)); Interceptor.Chain chain = new RealInterceptorChain(interceptors, null, null, null, 0, originalRequest, this, eventListener, client.connectTimeoutMillis(), client.readTimeoutMillis(), client.writeTimeoutMillis()); return chain.proceed(originalRequest); &#125; 我们可以看到, 实际执行是RealInterceptorChain.proceed123456789101112131415161718192021222324252627282930313233343536373839404142434445public Response proceed(Request request, StreamAllocation streamAllocation, HttpCodec httpCodec, RealConnection connection) throws IOException &#123; if (index &gt;= interceptors.size()) throw new AssertionError(); calls++; // If we already have a stream, confirm that the incoming request will use it. if (this.httpCodec != null &amp;&amp; !this.connection.supportsUrl(request.url())) &#123; throw new IllegalStateException("network interceptor " + interceptors.get(index - 1) + " must retain the same host and port"); &#125; // If we already have a stream, confirm that this is the only call to chain.proceed(). if (this.httpCodec != null &amp;&amp; calls &gt; 1) &#123; throw new IllegalStateException("network interceptor " + interceptors.get(index - 1) + " must call proceed() exactly once"); &#125; // 请求下一个责任链 RealInterceptorChain next = new RealInterceptorChain(interceptors, streamAllocation, httpCodec, connection, index + 1, request, call, eventListener, connectTimeout, readTimeout, writeTimeout); // 获取当前的拦截器 Interceptor interceptor = interceptors.get(index); // 执行, 返回响应 Response response = interceptor.intercept(next); // 保证下一个拦截器会调用到chain.proceed(). if (httpCodec != null &amp;&amp; index + 1 &lt; interceptors.size() &amp;&amp; next.calls != 1) &#123; throw new IllegalStateException("network interceptor " + interceptor + " must call proceed() exactly once"); &#125; // 保证拦截器返回的响应不为空 if (response == null) &#123; throw new NullPointerException("interceptor " + interceptor + " returned null"); &#125; // 保证响应的body不为空 if (response.body() == null) &#123; throw new IllegalStateException( "interceptor " + interceptor + " returned a response with no body"); &#125; return response; &#125; 这里可以把拦截器理解成工厂模式, 包装Request, 递归执行拦截器抽象的intercept方法, 然后将返回的Response再传回上一个拦截器内做处理.再返回看前面的getResponseWithInterceptorChain方法, 可以看出真正请求执行的就在这一块, 根据责任链的设计思想, 将操作分开进行处理.具体流程可看下图 异步请求现在我们再回头看下异步请求时, 与同步请求有什么区别.123456789@Override public void enqueue(Callback responseCallback) &#123; synchronized (this) &#123; if (executed) throw new IllegalStateException("Already Executed"); executed = true; &#125; captureCallStackTrace(); eventListener.callStart(this); client.dispatcher().enqueue(new AsyncCall(responseCallback)); &#125; 在执行异步调用的时候, okHttp包装了一个AsyncCall对象通过dispatcher进行执行.AsyncCall继承NamedRunnable, 实现了Runnable接口.123456789synchronized void enqueue(AsyncCall call) &#123; // 判断当前异步请求数是否小于最大请求数 以及 同主机的请求数是否小于每个主机的最大请求数 if (runningAsyncCalls.size() &lt; maxRequests &amp;&amp; runningCallsForHost(call) &lt; maxRequestsPerHost) &#123; runningAsyncCalls.add(call); executorService().execute(call); &#125; else &#123; readyAsyncCalls.add(call); &#125; &#125; 可以看到异步请求, 在dispatcher内部会维护两个集合以及一个线程池: runningAsyncCalls表示当前执行的异步请求队列, readyAsyncCalls表示等待执行的异步请求队列.执行内容我们可以看AsyncCall.execute, 他在判断请求是否取消后, 会调用getResponseWithInterceptorChain方法, 后面的请求走到的步骤就与同步相同了.然后通过dispatcher关闭管理.12345678910111213141516171819202122232425@Override protected void execute() &#123; boolean signalledCallback = false; try &#123; // 责任链执行 Response response = getResponseWithInterceptorChain(); if (retryAndFollowUpInterceptor.isCanceled()) &#123; signalledCallback = true; responseCallback.onFailure(RealCall.this, new IOException("Canceled")); &#125; else &#123; signalledCallback = true; responseCallback.onResponse(RealCall.this, response); &#125; &#125; catch (IOException e) &#123; if (signalledCallback) &#123; // Do not signal the callback twice! Platform.get().log(INFO, "Callback failure for " + toLoggableString(), e); &#125; else &#123; eventListener.callFailed(RealCall.this, e); responseCallback.onFailure(RealCall.this, e); &#125; &#125; finally &#123; client.dispatcher().finished(this); &#125; &#125; &#125; 12345678910111213141516private void promoteCalls() &#123; if (runningAsyncCalls.size() &gt;= maxRequests) return; // Already running max capacity. if (readyAsyncCalls.isEmpty()) return; // No ready calls to promote. for (Iterator&lt;AsyncCall&gt; i = readyAsyncCalls.iterator(); i.hasNext(); ) &#123; AsyncCall call = i.next(); if (runningCallsForHost(call) &lt; maxRequestsPerHost) &#123; i.remove(); runningAsyncCalls.add(call); executorService().execute(call); &#125; if (runningAsyncCalls.size() &gt;= maxRequests) return; // Reached max capacity. &#125; &#125; 这里唯一的区别是, 异步请求调到Dispatcher.finished的时候, 会调到promoteCalls方法, 他用来判断调度当前异步请求数是否超过最大请求, 如果没有, 则会从异步请求等待队列中获取出来再进行请求执行.由此, Dispatch才做到了内部针对于异步请求的线程管理, 实现了对应策略下同时请求的最大化. 总结本篇主要了解同步请求和异步请求的主干流程, 可以看出异步请求和同步请求的区别, 就在于, 异步请求真正执行是通过Dispatcher进行管理与执行, 虽然同步请求也用到了Dispatcher, 但它主要是用来做同步请求队列的管理.两类请求真正的请求网络的处理, 都是通过调用getResponseWithInterceptorChain方法进行处理.整体流程可以参照拆轮子系列：拆 OkHttp里的下图]]></content>
      <categories>
        <category>源码解析</category>
      </categories>
      <tags>
        <tag>源码解析</tag>
        <tag>okHttp3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AppPlugin源码解析]]></title>
    <url>%2F2018%2F07%2F06%2FAppPlugin%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[之前为了优化内部的Route, 去看了下TransformAPI, 然后就顺便看了下AppPlugin的源码.本篇源码基于android gradle 3.0.1的版本. 总入口我们直接从入口apply开始看, 他调到了父类BasePlugin的apply方法.1234567891011121314151617181920212223242526272829303132333435protected void apply(@NonNull Project project) &#123; // 一些基础path和插件版本的校验 // 以及一些流程记录的初始化 ... // 真正执行的是configureProject方法 // 项目配置 threadRecorder.record( ExecutionType.BASE_PLUGIN_PROJECT_CONFIGURE, project.getPath(), null, this::configureProject); threadRecorder.record( ExecutionType.BASE_PLUGIN_PROJECT_BASE_EXTENSION_CREATION, project.getPath(), null, this::configureExtension); threadRecorder.record( ExecutionType.BASE_PLUGIN_PROJECT_TASKS_CREATION, project.getPath(), null, this::createTasks); &#125;public interface Recorder &#123; ... // record方法用来执行block, 然后将执行结果记录 void record( @NonNull ExecutionType executionType, @NonNull String projectPath, @Nullable String variant, @NonNull VoidBlock block); &#125; apply入口的代码非常简洁, 主要执行就三个方法, configureProject, configureExtension和createTasks, 看方法名可以猜到, 他们的作用应该是配置Project, 配置插件的Extensions, 并且创建任务(task). configureProject123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111private void configureProject() &#123; extraModelInfo = new ExtraModelInfo(projectOptions, project.getLogger()); checkGradleVersion(); sdkHandler = new SdkHandler(project, getLogger()); // sdk, dependence的下载 if (!project.getGradle().getStartParameter().isOffline() &amp;&amp; projectOptions.get(BooleanOption.ENABLE_SDK_DOWNLOAD) &amp;&amp; !projectOptions.get(BooleanOption.IDE_INVOKED_FROM_IDE)) &#123; SdkLibData sdkLibData = SdkLibData.download(getDownloader(), getSettingsController()); sdkHandler.setSdkLibData(sdkLibData); &#125; // 构建androidBuilder androidBuilder = new AndroidBuilder( project == project.getRootProject() ? project.getName() : project.getPath(), creator, new GradleProcessExecutor(project), new GradleJavaProcessExecutor(project), extraModelInfo, getLogger(), isVerbose()); dataBindingBuilder = new DataBindingBuilder(); dataBindingBuilder.setPrintMachineReadableOutput( extraModelInfo.getErrorFormatMode() == ExtraModelInfo.ErrorFormatMode.MACHINE_PARSABLE); // Apply the Java and Jacoco plugins. // JavaBasePlugin, 用于编译java代码成class, 并组装成一个jar文件 project.getPlugins().apply(JavaBasePlugin.class); project.getPlugins().apply(JacocoPlugin.class); // 设置assmble task的描述 project.getTasks() .getByName("assemble") .setDescription( "Assembles all variants of all applications and secondary packages."); // 注册编译监听 // 会在每个project build结束后调用到, 而不单是当前的project project.getGradle() .addBuildListener( new BuildListener() &#123; @Override public void buildStarted(Gradle gradle) &#123; TaskInputHelper.enableBypass(); &#125; @Override public void settingsEvaluated(Settings settings) &#123;&#125; @Override public void projectsLoaded(Gradle gradle) &#123;&#125; @Override public void projectsEvaluated(Gradle gradle) &#123;&#125; @Override public void buildFinished(BuildResult buildResult) &#123; // 复合构建时不会多次重复清除 if (buildResult.getGradle().getParent() != null) &#123; return; &#125; // 清除dex缓存 ExecutorSingleton.shutdown(); sdkHandler.unload(); threadRecorder.record( ExecutionType.BASE_PLUGIN_BUILD_FINISHED, project.getPath(), null, () -&gt; &#123; PreDexCache.getCache() .clear( FileUtils.join( project.getRootProject() .getBuildDir(), FD_INTERMEDIATES, "dex-cache", "cache.xml"), getLogger()); Main.clearInternTables(); &#125;); &#125; &#125;); // 注册taskGraph构建完成时的回调 project.getGradle() .getTaskGraph() .addTaskExecutionGraphListener( taskGraph -&gt; &#123; TaskInputHelper.disableBypass(); // 遍历所有task, 如果是dexTransform, 则读取对应的dexTransform的缓存 for (Task task : taskGraph.getAllTasks()) &#123; if (task instanceof TransformTask) &#123; Transform transform = ((TransformTask) task).getTransform(); if (transform instanceof DexTransform) &#123; PreDexCache.getCache() .load( FileUtils.join( project.getRootProject() .getBuildDir(), FD_INTERMEDIATES, "dex-cache", "cache.xml")); break; &#125; &#125; &#125; &#125;); &#125; 看代码我们可以梳理configureProject流程如下 校验gradle版本 下载dependence 构建androidBuilder 如果有设置dataBinding, 则会构建dataBindingBuilder(这个不在本篇重点) 分别引用JavaBasePlugin和JacocoPlugin插件, 分别用于编译java代码成class和用于检查测试用例的覆盖率 注册taskGraph构建准备时的回调, 在准备完成时读取DexTransform的dex-cache缓存 注册编译完成时的回调, 进行dex缓存的清除工作configureExtension 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111private void configureExtension() &#123; // 分别创建buildType, ProductFlavor, SigningConfig, BaseVariantOutput对应存储的集合对象, 设置默认的Extensions final NamedDomainObjectContainer&lt;BuildType&gt; buildTypeContainer = project.container( BuildType.class, new BuildTypeFactory(instantiator, project, extraModelInfo)); final NamedDomainObjectContainer&lt;ProductFlavor&gt; productFlavorContainer = project.container( ProductFlavor.class, new ProductFlavorFactory( instantiator, project, project.getLogger(), extraModelInfo)); final NamedDomainObjectContainer&lt;SigningConfig&gt; signingConfigContainer = project.container(SigningConfig.class, new SigningConfigFactory(instantiator)); final NamedDomainObjectContainer&lt;BaseVariantOutput&gt; buildOutputs = project.container(BaseVariantOutput.class); // 设置project的buildOutputs属性的扩展为buildOutputs project.getExtensions().add("buildOutputs", buildOutputs); // 在appPlugin中实现, 创建android扩展属性 extension = createExtension( project, projectOptions, instantiator, androidBuilder, sdkHandler, buildTypeContainer, productFlavorContainer, signingConfigContainer, buildOutputs, extraModelInfo); // ndk处理器实例化 ndkHandler = new NdkHandler( project.getRootDir(), null, /* compileSkdVersion, this will be set in afterEvaluate */ "gcc", "" /*toolchainVersion*/, false /* useUnifiedHeaders */); @Nullable FileCache buildCache = BuildCacheUtils.createBuildCacheIfEnabled(project, projectOptions); GlobalScope globalScope = new GlobalScope( project, projectOptions, androidBuilder, extension, sdkHandler, ndkHandler, registry, buildCache); // ApplicationVariantFactory variantFactory = createVariantFactory(globalScope, instantiator, androidBuilder, extension); // ApplicationTaskManager, 管理application的任务创建 taskManager = createTaskManager( globalScope, project, projectOptions, androidBuilder, dataBindingBuilder, extension, sdkHandler, ndkHandler, registry, threadRecorder); // 变体的创建和管理的管理器 variantManager = new VariantManager( globalScope, project, projectOptions, androidBuilder, extension, variantFactory, taskManager, threadRecorder); // 注册自定义工具模型, 和native工具模型 registerModels(registry, globalScope, variantManager, extension, extraModelInfo); // map the whenObjectAdded callbacks on the containers. signingConfigContainer.whenObjectAdded(variantManager::addSigningConfig); buildTypeContainer.whenObjectAdded( buildType -&gt; &#123; SigningConfig signingConfig = signingConfigContainer.findByName(BuilderConstants.DEBUG); buildType.init(signingConfig); variantManager.addBuildType(buildType); &#125;); productFlavorContainer.whenObjectAdded(variantManager::addProductFlavor); // map whenObjectRemoved on the containers to throw an exception. signingConfigContainer.whenObjectRemoved( new UnsupportedAction("Removing signingConfigs is not supported.")); buildTypeContainer.whenObjectRemoved( new UnsupportedAction("Removing build types is not supported.")); productFlavorContainer.whenObjectRemoved( new UnsupportedAction("Removing product flavors is not supported.")); // create default Objects, signingConfig first as its used by the BuildTypes. variantFactory.createDefaultComponents( buildTypeContainer, productFlavorContainer, signingConfigContainer); &#125; configureExtension主要处理了extension 分别创建buildType, ProductFlavor, SigningConfig, BaseVariantOutput对应存储的集合对象 创建android Extension, createExtension是个抽象方法, 具体实现代码可以看AppPlugin里, 在我们的工程配置gradle文件里, 就是我们熟悉的android闭包里的配置 1234567891011121314151617181920212223242526protected BaseExtension createExtension( @NonNull Project project, @NonNull ProjectOptions projectOptions, @NonNull Instantiator instantiator, @NonNull AndroidBuilder androidBuilder, @NonNull SdkHandler sdkHandler, @NonNull NamedDomainObjectContainer&lt;BuildType&gt; buildTypeContainer, @NonNull NamedDomainObjectContainer&lt;ProductFlavor&gt; productFlavorContainer, @NonNull NamedDomainObjectContainer&lt;SigningConfig&gt; signingConfigContainer, @NonNull NamedDomainObjectContainer&lt;BaseVariantOutput&gt; buildOutputs, @NonNull ExtraModelInfo extraModelInfo) &#123; return project.getExtensions() .create( "android", AppExtension.class, project, projectOptions, instantiator, androidBuilder, sdkHandler, buildTypeContainer, productFlavorContainer, signingConfigContainer, buildOutputs, extraModelInfo); &#125; 分别创建taskManager和variantManager, 看名字就可以知道他负责的分别是task和variant 针对签名配置signingConfig, buildType, productFlavor 注册新增时候的监听, 对应添加到variantManager中做管理. 同时, 他们是不支持删除的. 创建默认的variant createTasks123456789101112131415161718private void createTasks() &#123; threadRecorder.record( ExecutionType.TASK_MANAGER_CREATE_TASKS, project.getPath(), null, // 在before evaluate新增部分tasks () -&gt; taskManager.createTasksBeforeEvaluate( new TaskContainerAdaptor(project.getTasks()))); project.afterEvaluate( project -&gt; threadRecorder.record( ExecutionType.BASE_PLUGIN_CREATE_ANDROID_TASKS, project.getPath(), null, () -&gt; createAndroidTasks(false))); &#125; 在createTask阶段, 首先会在配置收集之前(即在apply plugin)阶段会创建一些task, 这里TaskContainerAdaptor可以理解为对task的又一层管理封装. 在配置收集获取所有task之后, 我们会调用到createAndroidTasks在执行真正的创建tasks之前, 主要是对extension内一些配置进行校验, 譬如针对buildToolsVersion, compileSdkVersion是否指定, 是否另外引用了JavaPlugin等等, 这里的代码可以自行看源码了解1234567891011121314151617181920212223final void createAndroidTasks(boolean force) &#123; ... threadRecorder.record( ExecutionType.VARIANT_MANAGER_CREATE_ANDROID_TASKS, project.getPath(), null, // 根据variant创建tasks () -&gt; &#123; variantManager.createAndroidTasks(); ApiObjectFactory apiObjectFactory = new ApiObjectFactory( androidBuilder, extension, variantFactory, instantiator, project.getObjects()); for (VariantScope variantScope : variantManager.getVariantScopes()) &#123; BaseVariantData variantData = variantScope.getVariantData(); apiObjectFactory.create(variantData); &#125; &#125;); ... &#125; 这里我们可以主要看下variantManager.createAndroidTasks()方法内容, 这里根据variant创建对应的tasks可以看到具体流程如下: 校验是否引用apt插件(这在3.0里使用annotationProcessor来声明注解处理器) 填充收集所以variant 根据variant创建对应的tasks 12345678910111213141516171819202122232425262728293031323334public void createAndroidTasks() &#123; variantFactory.validateModel(this); // 校验是否引用apt插件, 如果有, 抛出异常 variantFactory.preVariantWork(project); final TaskFactory tasks = new TaskContainerAdaptor(project.getTasks()); if (variantScopes.isEmpty()) &#123; recorder.record( ExecutionType.VARIANT_MANAGER_CREATE_VARIANTS, project.getPath(), null /*variantName*/, // 填充所有variant this::populateVariantDataList); &#125; // Create top level test tasks. recorder.record( ExecutionType.VARIANT_MANAGER_CREATE_TESTS_TASKS, project.getPath(), null /*variantName*/, // 创建测试tasks () -&gt; taskManager.createTopLevelTestTasks(tasks, !productFlavors.isEmpty())); for (final VariantScope variantScope : variantScopes) &#123; recorder.record( ExecutionType.VARIANT_MANAGER_CREATE_TASKS_FOR_VARIANT, project.getPath(), variantScope.getFullVariantName(), // 根据variant创建不同的tasks, 创建assemble任务也在这里 () -&gt; createTasksForVariantData(tasks, variantScope)); &#125; taskManager.createReportTasks(tasks, variantScopes); &#125; 总结最后我们总结下, appPlugin apply的整体流程(当然, 因为他执行的是父类的apply, 所以流程适用于libraryPlugin) project的配置 检验gradle版本 下载dependence 构建androidBuilder 引用JavaBasePlugin和JacocoPlugin 定义编译过程的回调, 负责处理dex-cache的加载和清除工作 extension的配置 创建和配置extension 创建taskManager和variantManager 配置签名设置, buildType, productFlavor, 供后续task以及编译时使用 创建task(任务) 一些extension设置的检验 编译task的创建]]></content>
      <categories>
        <category>源码解析</category>
      </categories>
      <tags>
        <tag>源码解析</tag>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kotlin零散二三点]]></title>
    <url>%2F2018%2F05%2F25%2FKotlin%E9%9B%B6%E6%95%A3%E4%BA%8C%E4%B8%89%E7%82%B9%2F</url>
    <content type="text"><![CDATA[本篇主要谈些Kotlin开发过程比较常用到的技巧 空安全处理在Kotlin中, 最出名的特性莫过于就是它的空安全了, 毕竟NPE应该是大家最不想看到的错误信息.我们先回顾下Kotlin如何处理空安全 我们有四种方法来避免NPE 在条件中检查null 安全调用使用?. 使用Elvis 操作符 ?: 使用!!操作符 当然关于第四点使用!!操作符, 他的本质就回归到了当遇到null的时候仍然会抛出NPE. 所以在非必须的情况下, 我们应该尽量避免使用!! 为了避免NPE, 在kotlin的类型系统中, 它做到的就是强制开发者明确定义目标类型是否是可空类型(通过?区别), 如果一个变量是可空的, 我们需要这样写1var nullpossible: String? = null 而像下面这种, 是永远不会编译通过的1var nullpossible: String = null 当我们在定义一个变量的时候, 当能够确保他是非空类型的时候就必须要在构造器中初始化, 然而这在实际开发中是非常不方便的.1var a: String = ... 我们可以利用几种方式来解决 使用lateinit延迟初始化 使用委托Delegates.notNull() 12var test: String by Delegates.notNull()lateinit var testinit: String 不管我们使用哪种方式, 都可以让我们避免在初次定义类型的时候就必须初始化工作, 当然不论哪种方式, 在初始化前调用属性都是会抛出异常的. 而关于Delegates.notNull(), 通过源码我们可以看到他实际返回的是NotNullVar的委托.而通过NotNullVar中的getValue()返回直接定义为非空属性.1234567891011121314public object Delegates &#123; public fun &lt;T: Any&gt; notNull(): ReadWriteProperty&lt;Any?, T&gt; = NotNullVar()&#125;private class NotNullVar&lt;T: Any&gt;() : ReadWriteProperty&lt;Any?, T&gt; &#123; private var value: T? = null public override fun getValue(thisRef: Any?, property: KProperty&lt;*&gt;): T &#123; return value ?: throw IllegalStateException("Property $&#123;property.name&#125; should be initialized before get.") &#125; public override fun setValue(thisRef: Any?, property: KProperty&lt;*&gt;, value: T) &#123; this.value = value &#125;&#125; 还有一种方式是通过委托属性by lazy, 但是他只可以修饰val, 会在第一次调用对应属性的时候进行初始化, 默认是线程安全1val testlazy: String by lazy &#123; "fff"&#125; 另外他可以通过传入参数来选择不同的多线程处理12345678910111213141516@kotlin.jvm.JvmVersionpublic fun &lt;T&gt; lazy(mode: LazyThreadSafetyMode, initializer: () -&gt; T): Lazy&lt;T&gt; = when (mode) &#123; /* * 使用同步锁确保只有一条线程可以进行实例化 */ LazyThreadSafetyMode.SYNCHRONIZED -&gt; SynchronizedLazyImpl(initializer) /* * 同一时期多个线程可以初始化实例，但是只有最先返回的值会作为延迟初始化的实例，使用 AtomicReferenceFieldUpdater.compareAndSet() 方法实现。 **/ LazyThreadSafetyMode.PUBLICATION -&gt; SafePublicationLazyImpl(initializer) /** * 没有任何线程安全保证与开销 */ LazyThreadSafetyMode.NONE -&gt; UnsafeLazyImpl(initializer) &#125; 单例模式的实现Kotlin提供了object来很方便的支持了单例模式的实现12345678910object Singleton &#123; fun test()&#123; // ... &#125;&#125;// kotlin中调用Singleton.test()// java中调用Singleton.INSTANCE.test(); 我们看下他转为Java代码后是如何实现的.1234567891011public final class Singleton &#123; public static final Singleton INSTANCE; public final void test() &#123; &#125; static &#123; Singleton var0 = new Singleton(); INSTANCE = var0; &#125;&#125; 很好, 一个典型的饿汉式. 饿汉式的缺点我们简明讲下, 由于是类加载的第一时间就会新建实例, 所以当我们整个工程没有用到的时候, 就会导致内存空间的浪费.另外, 它无法自定义构造函数.如果我们不适用object呢, 应该如何实现单例模式? 我们来尝试用kotlin写一个DSL单例模式, 先看java的实现方法123456789101112131415161718public class SingletonDSL &#123; private static volatile SingletonDSL instance; private SingletonDSL()&#123; &#125; public static SingletonDSL getInstance() &#123; if(null == instance)&#123; synchronized (SingletonDSL.class)&#123; if(null == instance)&#123; instance = new SingletonDSL(); &#125; &#125; &#125; return instance; &#125;&#125; ok, 下面是翻译工作123456789class SingleDSLKotlin private constructor ()&#123; companion object &#123; @Volatile private var sInstance: SingleDSLKotlin? = null fun getInstance() = sInstance ?: synchronized(SingleDSLKotlin::class.java)&#123; sInstance ?: SingleDSLKotlin().also &#123; sInstance = it &#125; &#125; &#125;&#125; 根据上面lazy的延迟初始化的特性(通过查看源码我们可以发现他内部也是用双重锁机制来实现的), 我们还可以更加的简单实现12345class SingleDSLKotlin private constructor ()&#123; companion object &#123; val INSTANCE by lazy &#123; SingleDSLKotlin() &#125; &#125;&#125; 当然我们也可以通过静态内部类来实现单例模式123456789class SingletonStaticClass private constructor()&#123; fun getInstance() = INSTANCE.sInstance companion object INSTANCE&#123; private val sInstance = SingletonStaticClass() &#125;&#125; 这里关于构造函数的相关基础知识可参见官网 域函数的区别我们在前面写DSL单例的demo的时候, 用到了一个also.我们开发过程中会经常用到这几个作用域函数run, with, apply, with, also, let 要理解源码, 我们首先要搞明白inline内联函数是做什么用的. 在kotlin中, 函数也是作为一个对象存储在内存中.当我们调用一个函数的时候, VM首先去找你函数存储的位置, 然后执行函数, 最后再回到你调用函数的地方. 这会分别引入了内存空间的开销和虚拟调用运行的时间开销 而内联函数做的就是在编译期就将函数的调用替换成函数的定义. 然后我们再回头看这几个函数的作用 let我们最开始接触的作用域函数应该就是let了, 当我们处理一个可空对象的时候, 要获取它的内部某个属性的时候, 我们一般都是通过使用?.let{}来忽略掉空对象逻辑处理情况1234567@kotlin.internal.InlineOnlypublic inline fun &lt;T, R&gt; T.let(block: (T) -&gt; R): R &#123; contract &#123; callsInPlace(block, InvocationKind.EXACTLY_ONCE) &#125; return block(this)&#125; 可以看到他是将自身T作为参数传入调用函数中, 然后返回最后执行的结果.12345678private fun descriLet()&#123; val des = "showValue" val letResult = des.let &#123; Log.e("lettt", it) true &#125; Log.e("let result", letResult.toString()) &#125; 我们可以通过输出结果里验证 run123456789101112131415161718192021/** * Calls the specified function [block] and returns its result. */@kotlin.internal.InlineOnlypublic inline fun &lt;R&gt; run(block: () -&gt; R): R &#123; contract &#123; callsInPlace(block, InvocationKind.EXACTLY_ONCE) &#125; return block()&#125;/** * Calls the specified function [block] with `this` value as its receiver and returns its result. */@kotlin.internal.InlineOnlypublic inline fun &lt;T, R&gt; T.run(block: T.() -&gt; R): R &#123; contract &#123; callsInPlace(block, InvocationKind.EXACTLY_ONCE) &#125; return block()&#125; 可以看出当我们使用T.run的时候, 是作为T.()扩展函数的调用块, 最后返回闭包执行的结果12345678910111213private fun describeRun()&#123; val runResult = run&#123; true &#125; Log.e("run result", runResult.toString()) val runResult1 = "T.run".run &#123; Log.e("run", this) Log.e("length", length.toString()) // print "length: 5" 2 &#125; Log.e("run result2", runResult1.toString()) // print "run result2: 2" &#125; also123456789101112/** * Calls the specified function [block] with `this` value as its argument and returns `this` value. */@kotlin.internal.InlineOnly@SinceKotlin("1.1")public inline fun &lt;T&gt; T.also(block: (T) -&gt; Unit): T &#123; contract &#123; callsInPlace(block, InvocationKind.EXACTLY_ONCE) &#125; block(this) return this&#125; also和let有点像, 但是他返回的对象与闭包执行结果没有关系, 返回的是调用对象本身123456private fun describeAlso()&#123; val alsoResult = "also result".also &#123; it.reversed() &#125; Log.e("also result", alsoResult) // print "also result: also result" &#125; apply1234567891011/** * Calls the specified function [block] with `this` value as its receiver and returns `this` value. */@kotlin.internal.InlineOnlypublic inline fun &lt;T&gt; T.apply(block: T.() -&gt; Unit): T &#123; contract &#123; callsInPlace(block, InvocationKind.EXACTLY_ONCE) &#125; block() return this&#125; 作为T.()扩展函数调用块执行, 返回被调用对象本身1234567private fun describeApply()&#123; val applyResult = "apply".apply &#123; reversed() length &#125; Log.e("apply Result", applyResult) // print "apply Result: apply" &#125; with12345678910/** * Calls the specified function [block] with the given [receiver] as its receiver and returns its result. */@kotlin.internal.InlineOnlypublic inline fun &lt;T, R&gt; with(receiver: T, block: T.() -&gt; R): R &#123; contract &#123; callsInPlace(block, InvocationKind.EXACTLY_ONCE) &#125; return receiver.block()&#125; with需要我们传入一个参数receiver, 然后作为它的扩展函数执行闭包, 返回执行结果.123456private fun describeWith()&#123; val withResult = with("with")&#123; reversed() &#125; Log.e("with result", withResult) // print "with result: htiw" &#125; 关于他们在用处上的一些区别, 可以看这里]]></content>
      <categories>
        <category>kotlin</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>kotlin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ARouter源码解析]]></title>
    <url>%2F2018%2F05%2F18%2FARouter%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[如果应用项目要做模块化, 必然绕不开为了模块间跳转解耦而做的处理, 我们都知道一般都会采用路由模式, 本篇主要解析阿里的开源路由框架ARouter, 源码地址可见Github,本篇分析版本为api1.3.1 初始化感谢源码自带Demo, 我们直接从他的整个使用流程开始看起.忽略掉Log模式和Debug模式的开启, 首先我们需要初始化ARouter1ARouter.init(getApplication()); 它内部实际调用的是LogisticsCenter.init(Context context, ThreadPoolExecutor tpe)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public synchronized static void init(Context context, ThreadPoolExecutor tpe) throws HandlerException &#123; mContext = context; executor = tpe; try &#123; long startInit = System.currentTimeMillis(); //billy.qi modified at 2017-12-06 //load by plugin first loadRouterMap(); if (registerByPlugin) &#123; logger.info(TAG, "Load router map by arouter-auto-register plugin."); &#125; else &#123; Set&lt;String&gt; routerMap; // It will rebuild router map every times when debuggable. if (ARouter.debuggable() || PackageUtils.isNewVersion(context)) &#123; logger.info(TAG, "Run with debug mode or new install, rebuild router map."); // These class was generated by arouter-compiler. // 通过arouter-compiler生成 routerMap = ClassUtils.getFileNameByPackageName(mContext, ROUTE_ROOT_PAKCAGE); if (!routerMap.isEmpty()) &#123; context.getSharedPreferences(AROUTER_SP_CACHE_KEY, Context.MODE_PRIVATE).edit().putStringSet(AROUTER_SP_KEY_MAP, routerMap).apply(); &#125; // 当router map更新的时候保存新的版本号 PackageUtils.updateVersion(context); // Save new version name when router map update finishes. &#125; else &#123; logger.info(TAG, "Load router map from cache."); routerMap = new HashSet&lt;&gt;(context.getSharedPreferences(AROUTER_SP_CACHE_KEY, Context.MODE_PRIVATE).getStringSet(AROUTER_SP_KEY_MAP, new HashSet&lt;String&gt;())); &#125; logger.info(TAG, "Find router map finished, map size = " + routerMap.size() + ", cost " + (System.currentTimeMillis() - startInit) + " ms."); startInit = System.currentTimeMillis(); for (String className : routerMap) &#123; if (className.startsWith(ROUTE_ROOT_PAKCAGE + DOT + SDK_NAME + SEPARATOR + SUFFIX_ROOT)) &#123; // This one of root elements, load root. ((IRouteRoot) (Class.forName(className).getConstructor().newInstance())).loadInto(Warehouse.groupsIndex); &#125; else if (className.startsWith(ROUTE_ROOT_PAKCAGE + DOT + SDK_NAME + SEPARATOR + SUFFIX_INTERCEPTORS)) &#123; // Load interceptorMeta ((IInterceptorGroup) (Class.forName(className).getConstructor().newInstance())).loadInto(Warehouse.interceptorsIndex); &#125; else if (className.startsWith(ROUTE_ROOT_PAKCAGE + DOT + SDK_NAME + SEPARATOR + SUFFIX_PROVIDERS)) &#123; // Load providerIndex ((IProviderGroup) (Class.forName(className).getConstructor().newInstance())).loadInto(Warehouse.providersIndex); &#125; &#125; &#125; logger.info(TAG, "Load root element finished, cost " + (System.currentTimeMillis() - startInit) + " ms."); if (Warehouse.groupsIndex.size() == 0) &#123; logger.error(TAG, "No mapping files were found, check your configuration please!"); &#125; if (ARouter.debuggable()) &#123; logger.debug(TAG, String.format(Locale.getDefault(), "LogisticsCenter has already been loaded, GroupIndex[%d], InterceptorIndex[%d], ProviderIndex[%d]", Warehouse.groupsIndex.size(), Warehouse.interceptorsIndex.size(), Warehouse.providersIndex.size())); &#125; &#125; catch (Exception e) &#123; throw new HandlerException(TAG + "ARouter init logistics center exception! [" + e.getMessage() + "]"); &#125; &#125; 这里loadRouterMap()方法就是将是否通过插件注册的tag初始化为false, 我们主要看正常流程下的注册, 所以关注点在else的代码块中.对于routerMap从上下文我们可以看出, 他是APT自动生成的类名集合. 在Debug模式下, 当每次更新路由缓存的版本的时候, 都会从指定包名com.alibaba.android.arouter.routes收集所有的className, 如果不为空 则更新磁盘缓存. 而非Debug模式下, 不做收集, 直接获取磁盘缓存, 如果没有则new一个空集合. 然后通过反射新建对应类实例并调用load方法.我们可以看下debug模式下, APT生成类文件下的load函数具体执行了什么12345678910111213141516171819202122public class ARouter$$Group$$arouter implements IRouteGroup &#123; @Override public void loadInto(Map&lt;String, RouteMeta&gt; atlas) &#123; atlas.put("/arouter/service/autowired", RouteMeta.build(RouteType.PROVIDER, AutowiredServiceImpl.class, "/arouter/service/autowired", "arouter", null, -1, -2147483648)); atlas.put("/arouter/service/interceptor", RouteMeta.build(RouteType.PROVIDER, InterceptorServiceImpl.class, "/arouter/service/interceptor", "arouter", null, -1, -2147483648)); &#125;&#125;public class ARouter$$Providers$$arouterapi implements IProviderGroup &#123; @Override public void loadInto(Map&lt;String, RouteMeta&gt; providers) &#123; providers.put("com.alibaba.android.arouter.facade.service.AutowiredService", RouteMeta.build(RouteType.PROVIDER, AutowiredServiceImpl.class, "/arouter/service/autowired", "arouter", null, -1, -2147483648)); providers.put("com.alibaba.android.arouter.facade.service.InterceptorService", RouteMeta.build(RouteType.PROVIDER, InterceptorServiceImpl.class, "/arouter/service/interceptor", "arouter", null, -1, -2147483648)); &#125;&#125;public class ARouter$$Root$$arouterapi implements IRouteRoot &#123; @Override public void loadInto(Map&lt;String, Class&lt;? extends IRouteGroup&gt;&gt; routes) &#123; routes.put("arouter", ARouter$$Group$$arouter.class); &#125;&#125; 可以看出所有loadInto()方法执行的都是将注解的信息通过Map强引用做内存缓存管理.这里Warehouse.groupsIndex管理的是组的路由生成文件的内存, Warehouse.interceptorsIndex拦截器的索引管理, Warehouse.providersIndex服务(不是四大组件, 而是实现了继承IProvider接口的对象)索引管理. 跳转我们先看下对应的API123ARouter.getInstance() .build("/test/activity2") .navigation(); 首先需要build一个Postcard对象, 他包含了我们传递的跳转信息.123456789101112131415161718192021222324protected Postcard build(String path) &#123; if (TextUtils.isEmpty(path)) &#123; throw new HandlerException(Consts.TAG + "Parameter is invalid!"); &#125; else &#123; // 判断是否重写跳转URL, 没有就使用原来的path构建Postcard PathReplaceService pService = ARouter.getInstance().navigation(PathReplaceService.class); if (null != pService) &#123; path = pService.forString(path); &#125; return build(path, extractGroup(path)); &#125; &#125;protected Postcard build(String path, String group) &#123; if (TextUtils.isEmpty(path) || TextUtils.isEmpty(group)) &#123; throw new HandlerException(Consts.TAG + "Parameter is invalid!"); &#125; else &#123; PathReplaceService pService = ARouter.getInstance().navigation(PathReplaceService.class); if (null != pService) &#123; path = pService.forString(path); &#125; return new Postcard(path, group); &#125; &#125; 然后通过postcard.navigation()做跳转工作, 在这个方法内首先会针对我们记载路由信息的postcard通过调用LogisticsCenter.completion(postcard);进行信息补充完善1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798public synchronized static void completion(Postcard postcard) &#123; if (null == postcard) &#123; throw new NoRouteFoundException(TAG + "No postcard!"); &#125; // 通过path获取路由基础信息 RouteMeta routeMeta = Warehouse.routes.get(postcard.getPath()); // 如果没有获取到路由基础信息 if (null == routeMeta) &#123; // Maybe its does't exist, or didn't load. // 则重新通过反射进行加载 Class&lt;? extends IRouteGroup&gt; groupMeta = Warehouse.groupsIndex.get(postcard.getGroup()); // Load route meta. if (null == groupMeta) &#123; throw new NoRouteFoundException(TAG + "There is no route match the path [" + postcard.getPath() + "], in group [" + postcard.getGroup() + "]"); &#125; else &#123; // Load route and cache it into memory, then delete from metas. try &#123; if (ARouter.debuggable()) &#123; logger.debug(TAG, String.format(Locale.getDefault(), "The group [%s] starts loading, trigger by [%s]", postcard.getGroup(), postcard.getPath())); &#125; IRouteGroup iGroupInstance = groupMeta.getConstructor().newInstance(); iGroupInstance.loadInto(Warehouse.routes); Warehouse.groupsIndex.remove(postcard.getGroup()); if (ARouter.debuggable()) &#123; logger.debug(TAG, String.format(Locale.getDefault(), "The group [%s] has already been loaded, trigger by [%s]", postcard.getGroup(), postcard.getPath())); &#125; &#125; catch (Exception e) &#123; throw new HandlerException(TAG + "Fatal exception when loading group meta. [" + e.getMessage() + "]"); &#125; // 递归进行路由的完善工作 completion(postcard); // Reload &#125; &#125; else &#123; // 完善postcard信息 postcard.setDestination(routeMeta.getDestination()); postcard.setType(routeMeta.getType()); postcard.setPriority(routeMeta.getPriority()); postcard.setExtra(routeMeta.getExtra()); Uri rawUri = postcard.getUri(); if (null != rawUri) &#123; // Try to set params into bundle. Map&lt;String, String&gt; resultMap = TextUtils.splitQueryParameters(rawUri); Map&lt;String, Integer&gt; paramsType = routeMeta.getParamsType(); if (MapUtils.isNotEmpty(paramsType)) &#123; // Set value by its type, just for params which annotation by @Param for (Map.Entry&lt;String, Integer&gt; params : paramsType.entrySet()) &#123; setValue(postcard, params.getValue(), params.getKey(), resultMap.get(params.getKey())); &#125; // Save params name which need auto inject. postcard.getExtras().putStringArray(ARouter.AUTO_INJECT, paramsType.keySet().toArray(new String[]&#123;&#125;)); &#125; // Save raw uri postcard.withString(ARouter.RAW_URI, rawUri.toString()); &#125; switch (routeMeta.getType()) &#123; case PROVIDER: // if the route is provider, should find its instance // Its provider, so it must implement IProvider Class&lt;? extends IProvider&gt; providerMeta = (Class&lt;? extends IProvider&gt;) routeMeta.getDestination(); IProvider instance = Warehouse.providers.get(providerMeta); switch (routeMeta.getType()) &#123; case PROVIDER: // if the route is provider, should find its instance // Its provider, so it must implement IProvider // 如果路由目标是一个provider // 需要找到目标实例 Class&lt;? extends IProvider&gt; providerMeta = (Class&lt;? extends IProvider&gt;) routeMeta.getDestination(); IProvider instance = Warehouse.providers.get(providerMeta); if (null == instance) &#123; // There's no instance of this provider IProvider provider; try &#123; provider = providerMeta.getConstructor().newInstance(); provider.init(mContext); Warehouse.providers.put(providerMeta, provider); instance = provider; &#125; catch (Exception e) &#123; throw new HandlerException("Init provider failed! " + e.getMessage()); &#125; &#125; postcard.setProvider(instance); // provider不会触发拦截器 postcard.greenChannel(); // Provider should skip all of interceptors break; case FRAGMENT: // fragment不会触发拦截器 postcard.greenChannel(); // Fragment needn't interceptors default: break; &#125; &#125; &#125; 然后再回来看下路由跳转做的事情.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * Use router navigation. * * @param context * @param postcard 路由信息 * @param requestCode RequestCode, 默认为-1 * @param callback 申明的跳转回调 */protected Object navigation(final Context context, final Postcard postcard, final int requestCode, final NavigationCallback callback) &#123; try &#123; // postcard信息完善 LogisticsCenter.completion(postcard); &#125; catch (NoRouteFoundException ex) &#123; logger.warning(Consts.TAG, ex.getMessage()); if (debuggable()) &#123; // Show friendly tips for user. Toast.makeText(mContext, "There's no route matched!\n" + " Path = [" + postcard.getPath() + "]\n" + " Group = [" + postcard.getGroup() + "]", Toast.LENGTH_LONG).show(); &#125; // 没有找到对应路由信息的回调通知, 如果没有回调, 会通过DegradeService服务进行通知, 但是要根据他发出的进行处理, 需要我们实现DegradeService的接口 if (null != callback) &#123; callback.onLost(postcard); &#125; else &#123; // No callback for this invoke, then we use the global degrade service. DegradeService degradeService = ARouter.getInstance().navigation(DegradeService.class); if (null != degradeService) &#123; degradeService.onLost(context, postcard); &#125; &#125; return null; &#125; // 回调通知onFound if (null != callback) &#123; callback.onFound(postcard); &#125; // 当需要处理拦截器内容的时候 if (!postcard.isGreenChannel()) &#123; // It must be run in async thread, maybe interceptor cost too mush time made ANR. // 拦截器处理 interceptorService.doInterceptions(postcard, new InterceptorCallback() &#123; /** * Continue process * * @param postcard route meta */ @Override public void onContinue(Postcard postcard) &#123; // 继续跳转 _navigation(context, postcard, requestCode, callback); &#125; /** * Interrupt process, pipeline will be destory when this method called. * * @param exception Reson of interrupt. */ @Override public void onInterrupt(Throwable exception) &#123; if (null != callback) &#123; // 回调 callback.onInterrupt(postcard); &#125; logger.info(Consts.TAG, "Navigation failed, termination by interceptor : " + exception.getMessage()); &#125; &#125;); &#125; else &#123; return _navigation(context, postcard, requestCode, callback); &#125; return null; &#125; 拦截器的处理是通过interceptorService代理来实现, 我们可以往里面看123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122@Route(path = "/arouter/service/interceptor")public class InterceptorServiceImpl implements InterceptorService &#123; private static boolean interceptorHasInit; private static final Object interceptorInitLock = new Object(); @Override public void doInterceptions(final Postcard postcard, final InterceptorCallback callback) &#123; if (null != Warehouse.interceptors &amp;&amp; Warehouse.interceptors.size() &gt; 0) &#123; checkInterceptorsInitStatus(); if (!interceptorHasInit) &#123; callback.onInterrupt(new HandlerException("Interceptors initialization takes too much time.")); return; &#125; // 通过线程池进行异步管理执行 LogisticsCenter.executor.execute(new Runnable() &#123; @Override public void run() &#123; CancelableCountDownLatch interceptorCounter = new CancelableCountDownLatch(Warehouse.interceptors.size()); try &#123; // 通过interceptorCounter倒数计数器, 一个个执行拥有的拦截器 _excute(0, interceptorCounter, postcard); // 默认timeout时间是0.3s interceptorCounter.await(postcard.getTimeout(), TimeUnit.SECONDS); // 如果在postcard.getTimeout()时间内没有执行完 if (interceptorCounter.getCount() &gt; 0) &#123; // Cancel the navigation this time, if it hasn't return anythings. // 取消 callback.onInterrupt(new HandlerException("The interceptor processing timed out.")); &#125; else if (null != postcard.getTag()) &#123; // Maybe some exception in the tag. callback.onInterrupt(new HandlerException(postcard.getTag().toString())); &#125; else &#123; // 在没有超时和抛出异常的情况下, 则继续往后执行 callback.onContinue(postcard); &#125; &#125; catch (Exception e) &#123; callback.onInterrupt(e); &#125; &#125; &#125;); &#125; else &#123; callback.onContinue(postcard); &#125; &#125; /** * Excute interceptor * * @param index current interceptor index * @param counter interceptor counter * @param postcard routeMeta */ private static void _excute(final int index, final CancelableCountDownLatch counter, final Postcard postcard) &#123; if (index &lt; Warehouse.interceptors.size()) &#123; IInterceptor iInterceptor = Warehouse.interceptors.get(index); iInterceptor.process(postcard, new InterceptorCallback() &#123; @Override public void onContinue(Postcard postcard) &#123; // Last interceptor excute over with no exception. counter.countDown(); // 递归处理 _excute(index + 1, counter, postcard); // When counter is down, it will be execute continue ,but index bigger than interceptors size, then U know. &#125; @Override public void onInterrupt(Throwable exception) &#123; // Last interceptor excute over with fatal exception. postcard.setTag(null == exception ? new HandlerException("No message.") : exception.getMessage()); // save the exception message for backup. counter.cancel(); // Be attention, maybe the thread in callback has been changed, // then the catch block(L207) will be invalid. // The worst is the thread changed to main thread, then the app will be crash, if you throw this exception!// if (!Looper.getMainLooper().equals(Looper.myLooper())) &#123; // You shouldn't throw the exception if the thread is main thread.// throw new HandlerException(exception.getMessage());// &#125; &#125; &#125;); &#125; &#125; @Override public void init(final Context context) &#123; LogisticsCenter.executor.execute(new Runnable() &#123; @Override public void run() &#123; if (MapUtils.isNotEmpty(Warehouse.interceptorsIndex)) &#123; for (Map.Entry&lt;Integer, Class&lt;? extends IInterceptor&gt;&gt; entry : Warehouse.interceptorsIndex.entrySet()) &#123; Class&lt;? extends IInterceptor&gt; interceptorClass = entry.getValue(); try &#123; IInterceptor iInterceptor = interceptorClass.getConstructor().newInstance(); iInterceptor.init(context); Warehouse.interceptors.add(iInterceptor); &#125; catch (Exception ex) &#123; throw new HandlerException(TAG + "ARouter init interceptor error! name = [" + interceptorClass.getName() + "], reason = [" + ex.getMessage() + "]"); &#125; &#125; interceptorHasInit = true; logger.info(TAG, "ARouter interceptors init over."); synchronized (interceptorInitLock) &#123; interceptorInitLock.notifyAll(); &#125; &#125; &#125; &#125;); &#125; private static void checkInterceptorsInitStatus() &#123; synchronized (interceptorInitLock) &#123; while (!interceptorHasInit) &#123; try &#123; interceptorInitLock.wait(10 * 1000); &#125; catch (InterruptedException e) &#123; throw new HandlerException(TAG + "Interceptor init cost too much time error! reason = [" + e.getMessage() + "]"); &#125; &#125; &#125; &#125;&#125; ok, 在进行了拦截器处理(或者没有拦截器的情况下), 我们走到了_navigation(context, postcard, requestCode, callback), 到这里基本又是熟悉的配方了, 可以看到他最后通过startActivity来进行跳转.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364private Object _navigation(final Context context, final Postcard postcard, final int requestCode, final NavigationCallback callback) &#123; final Context currentContext = null == context ? mContext : context; switch (postcard.getType()) &#123; case ACTIVITY: // Build intent final Intent intent = new Intent(currentContext, postcard.getDestination()); intent.putExtras(postcard.getExtras()); // Set flags. int flags = postcard.getFlags(); if (-1 != flags) &#123; intent.setFlags(flags); &#125; else if (!(currentContext instanceof Activity)) &#123; // Non activity, need less one flag. intent.setFlags(Intent.FLAG_ACTIVITY_NEW_TASK); &#125; // Navigation in main looper. new Handler(Looper.getMainLooper()).post(new Runnable() &#123; @Override public void run() &#123; if (requestCode &gt; 0) &#123; // Need start for result ActivityCompat.startActivityForResult((Activity) currentContext, intent, requestCode, postcard.getOptionsBundle()); &#125; else &#123; ActivityCompat.startActivity(currentContext, intent, postcard.getOptionsBundle()); &#125; if ((-1 != postcard.getEnterAnim() &amp;&amp; -1 != postcard.getExitAnim()) &amp;&amp; currentContext instanceof Activity) &#123; // Old version. ((Activity) currentContext).overridePendingTransition(postcard.getEnterAnim(), postcard.getExitAnim()); &#125; if (null != callback) &#123; // Navigation over. callback.onArrival(postcard); &#125; &#125; &#125;); break; case PROVIDER: return postcard.getProvider(); case BOARDCAST: case CONTENT_PROVIDER: case FRAGMENT: Class fragmentMeta = postcard.getDestination(); try &#123; Object instance = fragmentMeta.getConstructor().newInstance(); if (instance instanceof Fragment) &#123; ((Fragment) instance).setArguments(postcard.getExtras()); &#125; else if (instance instanceof android.support.v4.app.Fragment) &#123; ((android.support.v4.app.Fragment) instance).setArguments(postcard.getExtras()); &#125; return instance; &#125; catch (Exception ex) &#123; logger.error(Consts.TAG, "Fetch fragment instance error, " + TextUtils.formatStackTrace(ex.getStackTrace())); &#125; case METHOD: case SERVICE: default: return null; &#125; return null; &#125;]]></content>
      <categories>
        <category>源码解析</category>
      </categories>
      <tags>
        <tag>源码解析</tag>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[androidAPT的使用]]></title>
    <url>%2F2018%2F05%2F17%2FandroidAPT%2F</url>
    <content type="text"><![CDATA[前言APT的概念大家应该不会陌生, 而且在很多第三方库中都有使用到, 最有名的应该就是ButterKnife了. 这里基础概念就略过了, 本篇主要是着重在怎么编写自己的注解处理器, 以及一些踩到的坑. 开始一般要实现编译器注解处理生成, 需要新建两个module, 分别存放自定义的Annotation和对应Annotation的处理器. 自定义注解我们先新建存在自定义注解的module, 注意, 这里建议新建java-library, 便于本地调试时给存放处理器的module依赖使用, 对应gradle配置如下12345678apply plugin: 'java-library'dependencies &#123; implementation fileTree(dir: 'libs', include: ['*.jar'])&#125;sourceCompatibility = "1.8"targetCompatibility = "1.8" 自定义一个新的注解12345@Retention(RetentionPolicy.CLASS)@Target(ElementType.TYPE)public @interface TestAnnotation &#123; String value();&#125; 这里Retention注解表示设置注解保留时机, 需要传递的是RetentionPolicy枚举类型, 值分别有: SOURCE: 编译器时就会抛弃注解 CLASS: 注解保留到编译器, 运行期会去除 RUNTIME: 注解保留到运行期, 编译器时也会存在 Target表示注解适用的上下文, 即他的目标修饰类型, 可以传数组,值应该为ElementType,枚举各个值的含义可以看官方文档, 我们主要用到比较多的应该是 TYPE: 类, 接口(包括注解类型)或者枚举的声明 METHOD: 方法声明 FIELD: 字段声明, 包括枚举常量 LOCAL_VARIABLE: 局部变量声明 CONSTRUCTOR: 构造函数的声明 注解处理器同样需要新建一个java-library, 对应gradle的配置如下1234567891011apply plugin: 'java-library'dependencies &#123; implementation fileTree(dir: 'libs', include: ['*.jar']) // 协助我们生成类文件 implementation 'com.squareup:javapoet:1.11.0' // 自定义注解的库 implementation project(':anno') // 协助自动注册META-INF implementation 'com.google.auto.service:auto-service:1.0-rc4'&#125; 然后开始编写处理器, 关于如何使用JavaPoet, 建议看下官方文档, 在这里不再细说.最后通过Filer来进行文件的写入.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// AutoService注解协助自动生成META-INF服务, 提供项目识别自定义的注解处理器@AutoService(Processor.class)public class TestProcessor extends AbstractProcessor &#123; private Filer mFiler; private Messager messager; /** * init()方法可以初始化拿到一些使用的工具，比如文件相关的辅助类 Filer;元素相关的辅助类Elements;日志相关的辅助类Messager; * @param processingEnv */ @Override public synchronized void init(ProcessingEnvironment processingEnv) &#123; super.init(processingEnv); mFiler = processingEnv.getFiler(); messager = processingEnv.getMessager(); &#125; /** * @return 返回Java版本 * 也可以通过@SupportedSourceVersion来指定, 如果没有设置默认返回的是JDK1.6版本 */ @Override public SourceVersion getSupportedSourceVersion() &#123; return SourceVersion.latest(); &#125; /** * * @return 支持的注解类型 * 即是这个处理器是需要注册在哪几个注解上的, 也可以通过@SupportedAnnotationTypes来指定 */ @Override public Set&lt;String&gt; getSupportedAnnotationTypes() &#123; LinkedHashSet&lt;String&gt; types = new LinkedHashSet&lt;&gt;(); types.add(TestAnnotation.class.getCanonicalName()); return types; &#125; /** * 一个Processor的main函数 * @param annotations 请求被处理的注解 * @param roundEnv 可以用来查询特定注解的被注解元素 * @return true 被当前处理器处理; false 可能被其他同样声明支持对应注解的处理器用来处理 */ @Override public boolean process(Set&lt;? extends TypeElement&gt; annotations, RoundEnvironment roundEnv) &#123; HashMap&lt;String, String&gt; nameMap = new HashMap&lt;&gt;(); Set&lt;? extends Element&gt; annotationElements = roundEnv.getElementsAnnotatedWith(TestAnnotation.class); for (Element element: annotationElements ) &#123; TestAnnotation annotation = element.getAnnotation(TestAnnotation.class); String name = annotation.value(); nameMap.put(name, element.getSimpleName().toString()); &#125; generateJavaFile(nameMap); return true; &#125; private void generateJavaFile(Map&lt;String, String&gt; nameMap)&#123; // 通过javaPoet生成java文件 &#125;&#125; 错误信息由于注解处理器是JVM在编译期进行运行, 所以普通的Log无法用来提示我们来打印一些日志或者用来提示错误信息.在Processor中, 当执行初始化的时候, 会传进来一个ProcessingEnvironment参数, 在上方代码注释内我也写了, 他会提供一些我们需要的参数, 比如Messager一个用来报告错误, 警报或者其他通知的工具, 它可以用来提醒第三方使用注解的开发者们来处理相关的错误.它有多个重载函数, 用于设置提醒到哪个地步, 具体可以自己尝试下.1234567891011121314151617181920public interface Messager &#123; void printMessage(Diagnostic.Kind kind, CharSequence msg); void printMessage(Diagnostic.Kind kind, CharSequence msg, Element e); void printMessage(Diagnostic.Kind kind, CharSequence msg, Element e, AnnotationMirror a); /** * @param kind 通知类型 * @param msg 内容 * @param e 注解元素 * @param a 包含注解的值得注解 * @param v 提示到注解的值使用位置 */ void printMessage(Diagnostic.Kind kind, CharSequence msg, Element e, AnnotationMirror a, AnnotationValue v);&#125; 使用自定义注解当我们需要使用的时候, 那么就跟常见的几个第三方库的使用(比如Dagger之类)是一样的.1234// 依赖管理自定义注解的库implementation project(':anno')// apt配置注解处理库annotationProcessor project(':aptlib') 值得注意的是如果你使用的是kotlin开发使用到对应的注解, 那么首先需要依赖kapt插件, 然后以kapt替换annotationProcessor添加注解处理库, 当项目里有Java文件使用到注解的时候, kapt也会兼顾到.12345678apply plugin: 'kotlin-kapt'dependencies &#123; implementation fileTree(include: ['*.jar'], dir: 'libs') implementation project(':anno') kapt project(':aptlib')&#125; Tips我们在开始的时候, 谈到注解的声明和处理器需要分别放在不同的module里, 原因是因为, 如果放在一个module里, 那么应用项目在依赖的时候, 就会变成12implementation project(':aptlib')annotationProcessor project(':aptlib') 而不论是我们使用的AbstractProcessor还是JavaPoet库, 都是依赖于JDK进行编译的, 当应用项目依赖于(implementation)这个库的时候, AS就会默认用SDK来进行编译, 导致编译器提示部分类无法加载, 所以我们才需要分成两个module, 保证到进行逻辑处理的处理器可以不会通过implementation被依赖进项目中.相关可以看看相关的issue的说明]]></content>
      <categories>
        <category>android学习记录</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>APT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一次Gradle的踩坑]]></title>
    <url>%2F2018%2F05%2F15%2F%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1Gradle%E7%9A%84%E8%B8%A9%E5%9D%91%2F</url>
    <content type="text"><![CDATA[前提背景来了新公司后第一个任务是给项目升级支持gradle插件3.0, 这个当初还是3.0.1的时候就做过, 所以并没有什么难度, 但是顺带要将内部的热更新插件同样升级碰到了个百思不得其解的问题. 问题我们先看下出现问题的伪代码, 当我在AS上需要编译运行项目的时候, 会提示dexTask为空的错误信息, 而在同事的PC上却可以顺利的运行.(gradle插件环境都是3.0.1, gradle使用的是4.1版本)12345678910afterEvaluate&#123; android.buildTypes.each&#123; type -&gt; def typeName = type.name if("release" == typeName)&#123; def dexTask = project.tasks.findByName("transformClassesWithDexForRelease") // 针对于dexTask的逻辑处理... &#125; &#125;&#125; 由于Gradle开发经验少的可怜, 所以此次我们一行行来看代码 Gradle的执行流程要解释afterEvaluate, 我们必须先了解Gradle的执行流程.它主要可分为三个步骤 初始化, 解析settings.gradle, 根据module生成对应project的实例 配置, 解析每个project, 获取对应的task 执行task 当然这一块流程, 我们可以从AS的Build上分析得出.然后我们再回头说到afterEvaluate, 它是在配置阶段后, 已经获取对应project的task后, 回调执行的.具体可以看官方文档的说明(这里放的是最新版本的API文档, 要看对应版本的文档, 可以看本地的gradle文件夹内的javadoc文档) 问题和解决ok, 那么关于afterEvaluate我们已经了解了, 再往下看,android.buildTypes.each就是对project的配置的buildType进行遍历, 然后当buildType为release的时候, 获取对应buildType的transformClassesWithDex.而在调试的过程中, 我发现走debug的时候transformClassesWithDexForDebug是有的, 可以看出配置阶段只会获取当前buildType的task.那么现在我们要做的就是改为判断当前buildType为release的时候, 再获取对应的task.12345678910android.applicationVariants.all&#123; variant -&gt; variant.outputs.each&#123; type -&gt; if("release" == type.name)&#123; def dexTask = project.tasks.findByName("transformClassesWithDexForRelease") // 针对于dexTask的逻辑处理... &#125; &#125;&#125; 然后这里还有个问题, 我们已知task的获取是要在配置结束后才能获得的, 这里不通过afterEvaluate是否可以获取到对应的task? 这块我们可以看下源码注释1234567891011121314151617181920212223242526/** * Returns a collection of &lt;a * href="https://developer.android.com/studio/build/build-variants.html"&gt;build variants&lt;/a&gt; that * the app project includes. * * &lt;p&gt;To process elements in this collection, you should use the &lt;a * href="https://docs.gradle.org/current/javadoc/org/gradle/api/DomainObjectCollection.html#all(org.gradle.api.Action)"&gt; * &lt;code&gt;all&lt;/code&gt;&lt;/a&gt; iterator. That's because the plugin populates this collection only after * the project is evaluated. Unlike the &lt;code&gt;each&lt;/code&gt; iterator, using &lt;code&gt;all&lt;/code&gt; * processes future elements as the plugin creates them. * * &lt;p&gt;The following sample iterates through all &lt;code&gt;applicationVariants&lt;/code&gt; elements to &lt;a * href="https://developer.android.com/studio/build/manifest-build-variables.html"&gt;inject a * build variable into the manifest&lt;/a&gt;: * * &lt;pre&gt; * android.applicationVariants.all &#123; variant -&amp;gt; * def mergedFlavor = variant.getMergedFlavor() * // Defines the value of a build variable you can use in the manifest. * mergedFlavor.manifestPlaceholders = [hostName:"www.example.com/$&#123;variant.versionName&#125;"] * &#125; * &lt;/pre&gt; */ public DomainObjectSet&lt;ApplicationVariant&gt; getApplicationVariants() &#123; return applicationVariantList; &#125; all与each不同, 他只会在configuration阶段后进行获取填充. 其他至于为什么同事的PC上可以运行, 我的不行, 后来排查下来, 应该是在AS3.1.2版本(同事的AS是3.0.1)在执行获取配置这块, 校验更为严格的原因. 但是具体的我并没有查询相关的文档. 总结其实本次问题并不难解决, 可能是前期因为同事可以运行, 本地环境却不能运行的状况给搞懵逼了. 但是后来还是顺利解决了.关于Gradle, 这次的踩坑经验是教了我去看官方API…虽然说Gradle的文档是真的好难定位]]></content>
      <categories>
        <category>日常开发踩坑记录</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>gradle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayList源码解析]]></title>
    <url>%2F2018%2F04%2F26%2FArrayList%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言每个ArrayList都有一个容量(capacity)的含义, 他接近于本身队列长度大小, 基本每个元素在新增的时候,都可以做到自动扩容.本篇主要是了解他的扩容机制.本篇源码以openjdk8为准 构造ArrayList实现了Serializable接口, 说明它是支持序列化的, 在它的内部有个elementData数组对象元素用来实现内存中的元素缓存, 它的长度相当于就是ArrayList的长度.这里有个关于transient关键字的知识点, 它保证了elementData不会被序列化, 使得它的生命周期保在调用者的内存中而不会被保存在磁盘中.1234public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123; transient Object[] elementData; &#125; 首先我们看下, 日常开发中我们最常用到的无参构造函数, 它主要做的就是将elementData引用指向默认静态的一个空数组.123public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; 还有其他的两个构造函数, 一个是可以初始定义队列的容量, 当传入的initialCapacity为负数的时候, 会抛出异常.要注意的是, 当定义的初始容量为0的时候, elementData指向的是另外一个空数组EMPTY_ELEMENTDATA, 具体为什么要区分两个静态空数组实例, 留在后面的扩容机制上说明.12345678910public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125; &#125; 最后一个构造函数式可以直接传集合进去, elementData引用指向传入的集合数组, 当集合长度为0的时候, 仍然会使它指向 EMPTY_ELEMENTDATA空数组.而当传入的集合有元素的情况下, 从注释上看是为了处理6260652的bug, 所以需要判断不是Object[]的情况下的时候, 使用Arrays内部实现的拷贝的方法copyOf进行元素的拷贝.1234567891011public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; 具体我们可以稍微看下Arrays.copyOf的源码, 后面会发现他是内部核心调用方法, 可以看出每次调用的时候, 实际是实例化了一个新的数组, 将原来的数组元素填充进去实现了copy的目的.123456789public static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) &#123; @SuppressWarnings("unchecked") T[] copy = ((Object)newType == (Object)Object[].class) ? (T[]) new Object[newLength] : (T[]) Array.newInstance(newType.getComponentType(), newLength); System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy; &#125; add我们首先看下几个add的方法, 其实内部实现的原理都不会错过扩容的操作, 所以我们具体看下扩容的原理.123456789101112131415161718192021public boolean add(E e) &#123; // size为arrayList的长度大小 ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; &#125;public void add(int index, E element) &#123; if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); // 容量确保 ensureCapacityInternal(size + 1); // Increments modCount!! // 空出index位, 进行拷贝 System.arraycopy(elementData, index, elementData, index + 1, size - index); // 根据索引获取数组index位进行赋值 elementData[index] = element; // 长度 + 1 size++;&#125; 首先, 每次都需要调用到ensureCapacityInternal, 进行容量的确定12345678910111213/** * 确保内部容量大小 * @param minCapacity */ private void ensureCapacityInternal(int minCapacity) &#123; // 当调用ArrayList()构造函数, 内部维护的数组是DEFAULTCAPACITY_EMPTY_ELEMENTDATA // 则minCapacity = 10 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; // minCapacity为10 或者为 size + 1 ensureExplicitCapacity(minCapacity); &#125; 这里可以看到, 当内部管理数组elementData指向内存地址与DEFAULTCAPACITY_EMPTY_ELEMENTDATA默认空数组实例相等的时候, 最小的容量会以传入的最小容量和默认容量(10)的最大值为准, 同时, 这里可以了解到, 区分两个空数组的实例, 就是为了扩容的时候确定容量的时候, 可以区分到调用无参构造函数的arrayList, 在第一次添加元素的时候, 可以保证他的容量首先是10(DEFAULT_CAPACITY)).然后再是调用到ensureExplicitCapacity方法.123456789private void ensureExplicitCapacity(int minCapacity) &#123; // 操作数记录 modCount++; // overflow-conscious code // 如果 当前数组的长度比添加元素后的长度要小则进行扩容 if (minCapacity - elementData.length &gt; 0) grow(minCapacity); &#125; 当内部当前管理的数组elementData的长度小于添加元素后的长度, 则需要进行真正的扩容方法grow 可以看到, 每次容量是根据原来容量的1.5倍来扩充的, 当扩充后的容量仍然没有加入新元素后的长度大的时候, 那么直接扩容到加入后的长度. 而实现扩容的真正机制, 其实还是调用了Arrays.copyOf方法, 声明了目标容量的数组, 进行元素拷贝. 这样的话, 其实每次ArrayList的内部元素变化的时候, 都会存在相对的内存开销.1234567891011121314151617181920212223242526272829303132/** * 将原来的数组, 拷贝到一个扩容后新长度的数组内 * Increases the capacity to ensure that it can hold at least the * number of elements specified by the minimum capacity argument. * * @param minCapacity the desired minimum capacity */ private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; // oldCapacity &gt;&gt; 1 相当于 oldCapacity / 2 // 新容量为老容量的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 如果扩容后容量比添加元素后的长度小 if (newCapacity - minCapacity &lt; 0) // 直接扩容到添加元素后的长度大小 newCapacity = minCapacity; // 新容量大小比 MAX_ARRAY_SIZE 大 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: // 构建newCapacity长度的新数组, elementData指向它 elementData = Arrays.copyOf(elementData, newCapacity); &#125;private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); // 如果是添加元素后的长度大于 MAX_ARRAY_SIZE, 则容量设为Integer的最大. 否则 -8 return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; remove搞懂扩容机制后, 我们可以对应看下其他我们常用的API, 首先看下remove相关, 可以看出在移除元素的时候, 其实实际上我们还是做了个拷贝的动作, 将除去移除目标元素的数组其他元素, 拷贝到新的数组中, 同时, 这个时候容量其实是没有变的.1234567891011121314151617181920212223242526272829303132333435363738394041public E remove(int index) &#123; if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); modCount++; E oldValue = (E) elementData[index]; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue; &#125;public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false; &#125;private void fastRemove(int index) &#123; // 操作数的新增 modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work&#125; 其他我们在看下get和contains是怎么实现的123456public E get(int index) &#123; if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); return (E) elementData[index]; &#125; 可以看到get的方法, 实际就是对于内部数组的索引查找12345678910111213141516public boolean contains(Object o) &#123; return indexOf(o) &gt;= 0; &#125;public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1;&#125; 而contains(Object o)方法其实做的就是对内部数组进行遍历查找. 总结考量到使用无参构造函数的时候, 当添加元素的时候, 初始容量为10, 以10为基准进行1.5倍的扩容, 通过源码的解读, 我们可以就可以进行一定的内存优化, 譬如在使用ArrayList的时候, 就应该避免使用无参构造函数, 尽量多的给它定义明确的初始容量, 一个是可以导致不会有过多的内存空间被浪费, 另外一个是可以减少调用到System.arraycopynative方法, 保证了一定的内存开销的节省.]]></content>
      <categories>
        <category>源码解析</category>
      </categories>
      <tags>
        <tag>源码解析</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EventBus源码解析]]></title>
    <url>%2F2018%2F03%2F30%2FEventBus%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言前期加班加点赶项目, 趁着刚上线空两天,赶紧看下EventBus做个”思维复健” 使用EventBus的使用非常简单, 如果使用默认的EventBus, 我们一般只会使用到以下三个API 绑定 1EventBus.getDefault().regisiter(this); 发送信息 1EventBus.getDefault().post(new Event()); 解绑 1EventBus.getDefault().unregisiter(this); EventBus.getDefault()EventBus内部维护了一个单例, 通过getDefault我们可以获取默认单例来进行绑定和发送动作, 但是当我们需要进行一些关于log, 是否未有订阅者情况的响应处理时, 我们可以通过EventBusBuilder通过构建者模式来进行配置处理,本篇解析仅分析默认情况下的流程代码 绑定老规矩, 我们先上代码1234567891011public void register(Object subscriber) &#123; Class&lt;?&gt; subscriberClass = subscriber.getClass(); // 获取对应subscriber类的订阅方法 List&lt;SubscriberMethod&gt; subscriberMethods = subscriberMethodFinder.findSubscriberMethods(subscriberClass); synchronized (this) &#123; // 遍历执行订阅 for (SubscriberMethod subscriberMethod : subscriberMethods) &#123; subscribe(subscriber, subscriberMethod); &#125; &#125; &#125; 我们根据传递的订阅者来获取相关的订阅方法, 然后遍历执行订阅的动作. 我们首先看下如果查找订阅者的所有订阅方法12345678910111213141516171819202122232425List&lt;SubscriberMethod&gt; findSubscriberMethods(Class&lt;?&gt; subscriberClass) &#123; // 从缓存中查找订阅方法 List&lt;SubscriberMethod&gt; subscriberMethods = METHOD_CACHE.get(subscriberClass); // 缓存中有, 直接返回 if (subscriberMethods != null) &#123; return subscriberMethods; &#125; // 查找注册方法, 默认false if (ignoreGeneratedIndex) &#123; // 使用反射查找 subscriberMethods = findUsingReflection(subscriberClass); &#125; else &#123; // 使用注解器生成的类查找 subscriberMethods = findUsingInfo(subscriberClass); &#125; // 如果没有订阅方法, 则抛出异常 if (subscriberMethods.isEmpty()) &#123; throw new EventBusException("Subscriber " + subscriberClass + " and its super classes have no public methods with the @Subscribe annotation"); &#125; else &#123; // 否则加入缓存中 METHOD_CACHE.put(subscriberClass, subscriberMethods); return subscriberMethods; &#125; &#125; 我们知道EventBus3.0版本后通过@Subscribe注解来标注对应的订阅方法, 可以看到通过findUsingInfo方法查询订阅方法, 如果没有订阅方法, 会抛出异常, 而如果找到了, 则会加入缓存METHOD_CACHE进行内部维护, 这个方法可以优化部分性能, 减少反射带来的性能问题.我们在往findUsingInfo里看, 会发现如果找不到相关订阅者信息的时候, 仍会通过反射来寻找.123456789101112131415161718192021private List&lt;SubscriberMethod&gt; findUsingInfo(Class&lt;?&gt; subscriberClass) &#123; FindState findState = prepareFindState(); findState.initForSubscriber(subscriberClass); while (findState.clazz != null) &#123; findState.subscriberInfo = getSubscriberInfo(findState); if (findState.subscriberInfo != null) &#123; SubscriberMethod[] array = findState.subscriberInfo.getSubscriberMethods(); // 遍历订阅者方法 for (SubscriberMethod subscriberMethod : array) &#123; if (findState.checkAdd(subscriberMethod.method, subscriberMethod.eventType)) &#123; findState.subscriberMethods.add(subscriberMethod); &#125; &#125; &#125; else &#123; // 没有订阅信息, 从反射来找 findUsingReflectionInSingleClass(findState); &#125; findState.moveToSuperclass(); &#125; return getMethodsAndRelease(findState); &#125; 我们回头去看subscribe订阅动作的执行代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 订阅动作 * @param subscriber 订阅者(类似订阅的Activity之类) * @param subscriberMethod 订阅事件方法, 比如加了@Subscribe注解的方法 */ private void subscribe(Object subscriber, SubscriberMethod subscriberMethod) &#123; // 订阅事件的类, 比如平常传递的自己写的EventLogin等等.. Class&lt;?&gt; eventType = subscriberMethod.eventType; Subscription newSubscription = new Subscription(subscriber, subscriberMethod); // 获取与eventType有关的订阅事件的队列 CopyOnWriteArrayList&lt;Subscription&gt; subscriptions = subscriptionsByEventType.get(eventType); // 如果为空 if (subscriptions == null) &#123; // 初始队列 subscriptions = new CopyOnWriteArrayList&lt;&gt;(); subscriptionsByEventType.put(eventType, subscriptions); &#125; else &#123; // 如果管理的订阅队列存在新的订阅事件, 则抛出已注册事件的异常 if (subscriptions.contains(newSubscription)) &#123; throw new EventBusException("Subscriber " + subscriber.getClass() + " already registered to event " + eventType); &#125; &#125; int size = subscriptions.size(); // 遍历订阅的事件 for (int i = 0; i &lt;= size; i++) &#123; // 根据优先级, 插入订阅事件 if (i == size || subscriberMethod.priority &gt; subscriptions.get(i).subscriberMethod.priority) &#123; subscriptions.add(i, newSubscription); break; &#125; &#125; // 以订阅者为key, value为订阅事件的类的队列 List&lt;Class&lt;?&gt;&gt; subscribedEvents = typesBySubscriber.get(subscriber); if (subscribedEvents == null) &#123; subscribedEvents = new ArrayList&lt;&gt;(); typesBySubscriber.put(subscriber, subscribedEvents); &#125; subscribedEvents.add(eventType); // 是否粘性事件 if (subscriberMethod.sticky) &#123; // 是否分发订阅了响应事件类父类事件的方法, 默认为true if (eventInheritance) &#123; // Existing sticky events of all subclasses of eventType have to be considered. // Note: Iterating over all events may be inefficient with lots of sticky events, // thus data structure should be changed to allow a more efficient lookup // (e.g. an additional map storing sub classes of super classes: Class -&gt; List&lt;Class&gt;). // stickyEvents 粘性事件集合, key为eventType的类, value是eventType对象 Set&lt;Map.Entry&lt;Class&lt;?&gt;, Object&gt;&gt; entries = stickyEvents.entrySet(); for (Map.Entry&lt;Class&lt;?&gt;, Object&gt; entry : entries) &#123; // 获取候选eventType Class&lt;?&gt; candidateEventType = entry.getKey(); // native方法, 应该是判断当前注册eventType与候选缓存的eventType是否匹配 if (eventType.isAssignableFrom(candidateEventType)) &#123; // 如果匹配, 校验并发送订阅 Object stickyEvent = entry.getValue(); checkPostStickyEventToSubscription(newSubscription, stickyEvent); &#125; &#125; &#125; else &#123; Object stickyEvent = stickyEvents.get(eventType); checkPostStickyEventToSubscription(newSubscription, stickyEvent); &#125; &#125; &#125; 相关注释都在代码里, 这块的流程我们可以梳理成以下步骤: 获取我们订阅时间传输的类EventType, 初始化内部维护的两个集合, 分别是subscriptionsByEventType和typesBySubscriber, 根据命名我们也可以理解, 一个是根据eventType区分的订阅者队列, 一个是根据subscriber(订阅者)区分的eventType队列, 分别向对应的集合内添加对应新的订阅者和订阅事件 根据是否粘性事件判断是否需要调用checkPostStickyEventToSubscription直接发送信息给订阅者 checkPostStickyEventToSubscription内部判断事件是否被中断来判断是否会调用到postToSubscription, 就是发送信息给订阅者 发送信息12345678910111213141516171819202122232425262728293031323334/** * 事件发送 */ /** Posts the given event to the event bus. */ public void post(Object event) &#123; // currentPostingThreadState 为ThreadLocal对象 // 获取当前线程的发送状态 PostingThreadState postingState = currentPostingThreadState.get(); // 获取当前线程的事件发送队列 List&lt;Object&gt; eventQueue = postingState.eventQueue; // 添加事件 eventQueue.add(event); // 如果不在发送中 if (!postingState.isPosting) &#123; // 判断是否在主线程 postingState.isMainThread = isMainThread(); // 修改发送中状态 postingState.isPosting = true; if (postingState.canceled) &#123; throw new EventBusException("Internal error. Abort state was not reset"); &#125; try &#123; // 遍历发送队列事件 while (!eventQueue.isEmpty()) &#123; // 从队头开始发送, 同时移除队列中的对应事件 postSingleEvent(eventQueue.remove(0), postingState); &#125; &#125; finally &#123; // 修改发送中状态, 修改主线程判断 postingState.isPosting = false; postingState.isMainThread = false; &#125; &#125; &#125; 由于在业务场景中, 无法判断发送信息在什么线程下执行的, 所以内部维护的currentPostingThreadState是一个ThreadLocal对象, 它可以保证当前线程的数据不会被其他线程共享.在post中, 我们就能看到EventBus会根据当前线程, 将事件发送给当前线程的队列中, 然后遍历执行postSingleEvent进行单个事件的发送, 同时移除掉队列中已发送的事件12345678910111213141516171819202122232425262728293031323334353637/** * 发送单个事件 * @param event * @param postingState * @throws Error */ private void postSingleEvent(Object event, PostingThreadState postingState) throws Error &#123; // event 是对应eventType的实例 Class&lt;?&gt; eventClass = event.getClass(); // 默认没有找到订阅者 boolean subscriptionFound = false; // 默认true, 判断是否触发eventType的父类或接口的订阅 if (eventInheritance) &#123; // 查找获取所有eventType的父类和接口 List&lt;Class&lt;?&gt;&gt; eventTypes = lookupAllEventTypes(eventClass); int countTypes = eventTypes.size(); // 循环发送 for (int h = 0; h &lt; countTypes; h++) &#123; Class&lt;?&gt; clazz = eventTypes.get(h); subscriptionFound |= postSingleEventForEventType(event, postingState, clazz); &#125; &#125; else &#123; subscriptionFound = postSingleEventForEventType(event, postingState, eventClass); &#125; // 如果没有找到订阅者 if (!subscriptionFound) &#123; if (logNoSubscriberMessages) &#123; logger.log(Level.FINE, "No subscribers registered for event " + eventClass); &#125; // 如果我们的builder配置了sendNoSubscriberEvent(默认为true) if (sendNoSubscriberEvent &amp;&amp; eventClass != NoSubscriberEvent.class &amp;&amp; eventClass != SubscriberExceptionEvent.class) &#123; // 会发送一个NoSubscriberEvent的事件, 如果需要判断无订阅者时候的触发情况, 可以接收这个事件做处理 post(new NoSubscriberEvent(this, event)); &#125; &#125; &#125; 这里的流程我们可以分成两步: 通过postSingleEventForEventType根据eventType查找对应的订阅者, 如果找到, 则发送事件 如果没有找到订阅者, 根据构造器内我们通过sendNoSubscriberEvent的配置, 来判断是否需要发送一个无订阅者响应事件 12345678910111213141516171819202122232425262728private boolean postSingleEventForEventType(Object event, PostingThreadState postingState, Class&lt;?&gt; eventClass) &#123; CopyOnWriteArrayList&lt;Subscription&gt; subscriptions; synchronized (this) &#123; // 根据eventType获取订阅者 subscriptions = subscriptionsByEventType.get(eventClass); &#125; if (subscriptions != null &amp;&amp; !subscriptions.isEmpty()) &#123; for (Subscription subscription : subscriptions) &#123; postingState.event = event; postingState.subscription = subscription; boolean aborted = false; try &#123; // 发送给订阅者 postToSubscription(subscription, event, postingState.isMainThread); aborted = postingState.canceled; &#125; finally &#123; postingState.event = null; postingState.subscription = null; postingState.canceled = false; &#125; if (aborted) &#123; break; &#125; &#125; return true; &#125; return false; &#125; postSingleEventForEventType方法就执行了上面的第一步动作, 如果找到了订阅者, 就会返回true; 否则, 返回false.最终我们通过调用postToSubscription将事件发送给订阅者.咱们继续往下走.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 订阅发布 * @param subscription 新注册的订阅者 * @param event eventType * @param isMainThread 是否主线程 */ private void postToSubscription(Subscription subscription, Object event, boolean isMainThread) &#123; // 订阅方法的指定线程 switch (subscription.subscriberMethod.threadMode) &#123; // 相同线程内 case POSTING: invokeSubscriber(subscription, event); break; // 主线程内, 不阻塞 case MAIN: if (isMainThread) &#123; // 订阅者的调用 invokeSubscriber(subscription, event); &#125; else &#123; // 通过handler处理 mainThreadPoster.enqueue(subscription, event); &#125; break; // 主线程, 阻塞 case MAIN_ORDERED: if (mainThreadPoster != null) &#123; mainThreadPoster.enqueue(subscription, event); &#125; else &#123; // temporary: technically not correct as poster not decoupled from subscriber invokeSubscriber(subscription, event); &#125; break; // 后台线程, case BACKGROUND: if (isMainThread) &#123; // 实现了Runnable backgroundPoster.enqueue(subscription, event); &#125; else &#123; invokeSubscriber(subscription, event); &#125; break; // 异步线程 case ASYNC: asyncPoster.enqueue(subscription, event); break; default: throw new IllegalStateException("Unknown thread mode: " + subscription.subscriberMethod.threadMode); &#125; &#125; 默认的线程模式一般是POSTING会走发送信息时所在的线程, 这样避免了线程切换所存在的可能开销.我们首先看下invokeSubscriber方法, 它的作用就是做到了订阅者的调用12345678910void invokeSubscriber(Subscription subscription, Object event) &#123; try &#123; // 订阅方法的调用 subscription.subscriberMethod.method.invoke(subscription.subscriber, event); &#125; catch (InvocationTargetException e) &#123; handleSubscriberException(subscription, event, e.getCause()); &#125; catch (IllegalAccessException e) &#123; throw new IllegalStateException("Unexpected exception", e); &#125; &#125; 其实可以看出, 这里就是获取订阅方法, 通过反射将事件作为参数调用. 我们看下走UI线程的流程, 在判断当前线程非主线程的情况下, 我们会调用到mainThreadPoster.enqueue(subscription, event);,首先, 我们回到EventBus的构造函数中, 找到mainThreadPoster的相关申明1mainThreadPoster = mainThreadSupport != null ? mainThreadSupport.createPoster(this) : null; 1234567891011121314151617181920212223242526public interface MainThreadSupport &#123; boolean isMainThread(); Poster createPoster(EventBus eventBus); class AndroidHandlerMainThreadSupport implements MainThreadSupport &#123; private final Looper looper; public AndroidHandlerMainThreadSupport(Looper looper) &#123; this.looper = looper; &#125; @Override public boolean isMainThread() &#123; return looper == Looper.myLooper(); &#125; @Override public Poster createPoster(EventBus eventBus) &#123; return new HandlerPoster(eventBus, looper, 10); &#125; &#125;&#125; 可以看到他是个HandlerPoster对象, 然后再回来看HandlerPoster.enqueue对应的代码123456789101112public void enqueue(Subscription subscription, Object event) &#123; PendingPost pendingPost = PendingPost.obtainPendingPost(subscription, event); synchronized (this) &#123; queue.enqueue(pendingPost); if (!handlerActive) &#123; handlerActive = true; if (!sendMessage(obtainMessage())) &#123; throw new EventBusException("Could not send handler message"); &#125; &#125; &#125; &#125; 这里首先维护了内部的PendingPost, 并且将对应的pendingPost加入执行队列中.HandlerPoster继承于Handler, 根据他前面传入的Looper可以判定保证信息的执行是在主线程中做处理的, 现在我们看下handleMessage的处理1234567891011121314151617181920212223242526272829303132@Override public void handleMessage(Message msg) &#123; boolean rescheduled = false; try &#123; long started = SystemClock.uptimeMillis(); while (true) &#123; PendingPost pendingPost = queue.poll(); if (pendingPost == null) &#123; synchronized (this) &#123; // Check again, this time in synchronized pendingPost = queue.poll(); if (pendingPost == null) &#123; handlerActive = false; return; &#125; &#125; &#125; // 调用订阅者 eventBus.invokeSubscriber(pendingPost); long timeInMethod = SystemClock.uptimeMillis() - started; if (timeInMethod &gt;= maxMillisInsideHandleMessage) &#123; if (!sendMessage(obtainMessage())) &#123; throw new EventBusException("Could not send handler message"); &#125; rescheduled = true; return; &#125; &#125; &#125; finally &#123; handlerActive = rescheduled; &#125; &#125; 这里做的处理, 主要就是调用了EventBus对象的invokeSubscriber方法, 最终走到了订阅者的方法的执行.至于其他的几个线程模式, 查看对应的POST也可以大致知道他的原理, 这里就暂且不表了. 解绑相对前面的, 其实解绑的逻辑就非常简单了, 我们先看代码12345678910111213141516171819/** * 解绑 */ /** Unregisters the given subscriber from all event classes. */ public synchronized void unregister(Object subscriber) &#123; // 根据订阅者获取对应的eventType List&lt;Class&lt;?&gt;&gt; subscribedTypes = typesBySubscriber.get(subscriber); // 如果不为空 if (subscribedTypes != null) &#123; // 遍历解绑 for (Class&lt;?&gt; eventType : subscribedTypes) &#123; unsubscribeByEventType(subscriber, eventType); &#125; // 移除相关的eventType typesBySubscriber.remove(subscriber); &#125; else &#123; logger.log(Level.WARNING, "Subscriber to unregister was not registered before: " + subscriber.getClass()); &#125; &#125; 我们在绑定相关的解析中, 已经知道其实内部管理订阅事件和订阅者是通过typesBySubscriber和subscriptionsByEventType来实现的, 而这里就是移除掉与对应订阅者相关的对象即可.]]></content>
      <categories>
        <category>源码解析</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>源码解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RxJava2源码解析(二)]]></title>
    <url>%2F2018%2F02%2F08%2FRxJava2%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%902%2F</url>
    <content type="text"><![CDATA[前言本篇主要解析RxJava的线程切换的原理实现 subscribeOn首先, 我们先看下subscribeOn()方法, 老样子, 先上Demo12345678910111213Observable&lt;Integer&gt; observable = Observable .create(new ObservableOnSubscribe&lt;Integer&gt;() &#123; @Override public void subscribe(ObservableEmitter&lt;Integer&gt; emitter) throws Exception &#123; emitter.onNext(123); emitter.onComplete(); &#125; &#125;);observable .subscribeOn(Schedulers.io()) .subscribe(getObserver()); subscribeOn操作符源码里其实是返回了一个ObservableSubscribeOn对象, 而从上篇我们已经知道, 订阅的动作其实在每个Observable的subscribeActual(observer)中执行, 所以我们直接去看ObservableSubscribeOn中的对应重载方法就行了.12345678@Override public void subscribeActual(final Observer&lt;? super T&gt; s) &#123; final SubscribeOnObserver&lt;T&gt; parent = new SubscribeOnObserver&lt;T&gt;(s); s.onSubscribe(parent); parent.setDisposable(scheduler.scheduleDirect(new SubscribeTask(parent))); &#125; 123456789101112final class SubscribeTask implements Runnable &#123; private final SubscribeOnObserver&lt;T&gt; parent; SubscribeTask(SubscribeOnObserver&lt;T&gt; parent) &#123; this.parent = parent; &#125; @Override public void run() &#123; source.subscribe(parent); &#125; &#125; SubscribeTask是一个Runnable的实现类, 执行内容就是修饰后的Observer订阅上游的动作, 我们先看scheduler.scheduleDirect(runable)方法1234567891011121314151617@NonNullpublic Disposable scheduleDirect(@NonNull Runnable run) &#123; return scheduleDirect(run, 0L, TimeUnit.NANOSECONDS);&#125;@NonNullpublic Disposable scheduleDirect(@NonNull Runnable run, long delay, @NonNull TimeUnit unit) &#123; final Worker w = createWorker(); final Runnable decoratedRun = RxJavaPlugins.onSchedule(run); DisposeTask task = new DisposeTask(decoratedRun, w); w.schedule(task, delay, unit); return task;&#125; 这里createWorker是个抽象方法, 我们需要找到对应的修饰类, 我们返回去看Schedulers.io(), IO是IoScheduler的实例, 它的重载方法代码如下1234final AtomicReference&lt;CachedWorkerPool&gt; pool;public Worker createWorker() &#123; return new EventLoopWorker(pool.get()); &#125; 可以看到IO线程实际使用的是一个有线程缓存的线程调度器.它内部通过ScheduledExecutorService实例来尝试重用之前worker开始使用的实例, 由于本篇着重在流程实现原理, 所以略过细节处.在EventLoopWorker中, 我们看下对应的重载方法12345678public Disposable schedule(@NonNull Runnable action, long delayTime, @NonNull TimeUnit unit) &#123; if (tasks.isDisposed()) &#123; // don't schedule, we are unsubscribed return EmptyDisposable.INSTANCE; &#125; return threadWorker.scheduleActual(action, delayTime, unit, tasks); &#125; 继续往下, 其实这个时候已经是在线程池目标线程执行相关的工作了. 再深入就是线程池的操作了, 所以这里我们不再赘述12345678910111213141516171819202122232425262728public ScheduledRunnable scheduleActual(final Runnable run, long delayTime, @NonNull TimeUnit unit, @Nullable DisposableContainer parent) &#123; Runnable decoratedRun = RxJavaPlugins.onSchedule(run); ScheduledRunnable sr = new ScheduledRunnable(decoratedRun, parent); if (parent != null) &#123; if (!parent.add(sr)) &#123; return sr; &#125; &#125; Future&lt;?&gt; f; try &#123; if (delayTime &lt;= 0) &#123; f = executor.submit((Callable&lt;Object&gt;)sr); &#125; else &#123; f = executor.schedule((Callable&lt;Object&gt;)sr, delayTime, unit); &#125; sr.setFuture(f); &#125; catch (RejectedExecutionException ex) &#123; if (parent != null) &#123; parent.remove(sr); &#125; RxJavaPlugins.onError(ex); &#125; return sr; &#125; 由此我们可以看出来, 每次每个subscribeOn操作符执行的时候, 其实在source.subscribe(parent);订阅动作就做了线程切换, 所以在多次调subscribeOn的时候, 就会一直切换线程, 直到离ObservableSource最近的subscribeOn线程切换生效. observeOn废话不说, 我们直接看ObservableObserveOn.subscribeActual(observer)123456789protected void subscribeActual(Observer&lt;? super T&gt; observer) &#123; if (scheduler instanceof TrampolineScheduler) &#123; source.subscribe(observer); &#125; else &#123; Scheduler.Worker w = scheduler.createWorker(); source.subscribe(new ObserveOnObserver&lt;T&gt;(observer, w, delayError, bufferSize)); &#125; &#125; 熟悉的配方, 当相同想成的时候, 直接订阅, 而当不同线程的时候, 可以看到我们获取目标切换线程对应的worker实例以及装饰对应的Observer成ObserveOnOberver,后面的流程我们心知肚明, 就是Observer层层订阅上去, 然后我们看当碰到最上流的ObservableSource往下执行的时候, 做什么操作.具体我们看ObserveOnOberver代码, 我们这里着重看下onSubscribe和onNext方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Overridepublic void onSubscribe(Disposable s) &#123; if (DisposableHelper.validate(this.s, s)) &#123; this.s = s; // 发送的数据是集合队列形式的时候 if (s instanceof QueueDisposable) &#123; @SuppressWarnings("unchecked") QueueDisposable&lt;T&gt; qd = (QueueDisposable&lt;T&gt;) s; int m = qd.requestFusion(QueueDisposable.ANY | QueueDisposable.BOUNDARY); //是同步模式的时候 if (m == QueueDisposable.SYNC) &#123; sourceMode = m; queue = qd; done = true; actual.onSubscribe(this); // 线程调度 schedule(); return; &#125; // 异步模式 if (m == QueueDisposable.ASYNC) &#123; sourceMode = m; queue = qd; actual.onSubscribe(this); return; &#125; &#125; queue = new SpscLinkedArrayQueue&lt;T&gt;(bufferSize); actual.onSubscribe(this); &#125;&#125;@Overridepublic void onNext(T t) &#123; // 是否已经调用到onComplete 或者 onError, 如果是, 则不再执行后面的onNext if (done) &#123; return; &#125; // 如果是非异步操作, 将数据添加到队列中 if (sourceMode != QueueDisposable.ASYNC) &#123; queue.offer(t); &#125; // 线程调度 schedule();&#125; 大概的注释都加在代码上了, 我们再补充看下看onSubscribe方法, 首先判断发送的数据是否属于QueueDisposable, 如果不是, 直接执行下游的onSubscribe,这里我卡了一下, 看不到他的线程切换是在哪里做, 后来往回看, 发现在我们执行ObservableSubscribeOn.subscribeActual(observer)的时候, onSubscribe()方法本身的确不是在切换后的线程内执行的. 但是, 当我们发送的是集合数据, 那么我们需要判断是哪种线程模式进行线程调度. 我们来看具体的schedule()方法代码123456void schedule() &#123; // 判断当前自增值是否为0, 原子性保证worker.schedule(this);不会在调用结束前被重复调用 if (getAndIncrement() == 0) &#123; worker.schedule(this); &#125; &#125; 这个时候就是在指定线程内run了, Disposable schedule(@NonNull Runnable run)传入的是个Runnable的实现类, 我们来找重载的run方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798@Overridepublic void run() &#123; if (outputFused) &#123; drainFused(); &#125; else &#123; drainNormal(); &#125;&#125;void drainNormal() &#123; int missed = 1; final SimpleQueue&lt;T&gt; q = queue; final Observer&lt;? super T&gt; a = actual; // 无限循环 for (;;) &#123; // 判断是否被取消, 或者调用onError 或者调用onComplete则退出循环 if (checkTerminated(done, q.isEmpty(), a)) &#123; return; &#125; // 无限循环 for (;;) &#123; boolean d = done; T v; try &#123; // 队列数据分发 v = q.poll(); &#125; catch (Throwable ex) &#123; Exceptions.throwIfFatal(ex); s.dispose(); q.clear(); a.onError(ex); worker.dispose(); return; &#125; boolean empty = v == null; // 判断是否应该被终止 if (checkTerminated(d, empty, a)) &#123; return; &#125; if (empty) &#123; break; &#125; a.onNext(v); &#125; // 原子性保证worker.schedule(this)的调用 missed = addAndGet(-missed); if (missed == 0) &#123; break; &#125; &#125;&#125;// 判断循环是否终止boolean checkTerminated(boolean d, boolean empty, Observer&lt;? super T&gt; a) &#123; // 如果订阅已经被取消, 则清除队列, 终止 if (cancelled) &#123; queue.clear(); return true; &#125; // 如果调用过onError 或者 onComplete if (d) &#123; Throwable e = error; // 默认false if (delayError) &#123; // 等到队列为空的时候再调用onError或者onComplete if (empty) &#123; if (e != null) &#123; a.onError(e); &#125; else &#123; a.onComplete(); &#125; worker.dispose(); return true; &#125; &#125; else &#123; // 如果有抛出异常, 走下游的onError // 线程任务停止 if (e != null) &#123; queue.clear(); a.onError(e); worker.dispose(); return true; &#125; // 没有, 走下游的onComplete // 线程任务停止 else if (empty) &#123; a.onComplete(); worker.dispose(); return true; &#125; &#125; &#125; // 否则不结束 return false;&#125; 由此我们可以得出结论, observeOn的操作符可以保证我们下流操作线程切换生效 总结到这里, 我们线程切换的原理大体流程就基本分析完毕了, 可以看出subscribeOn操作符只对上游生效, 而且因为他是在订阅的时候进行线程切换, 而我们每个操作符中间都有订阅动作, 所以越接近我们的ObservableSource的订阅的subscribeOn越是最后生效的. 而observeOn生效在我们的onNext,onComplete, onError方法内, 所以每次的observeOn针对它的下游都可以生效.]]></content>
      <categories>
        <category>源码解析</category>
      </categories>
      <tags>
        <tag>源码解析</tag>
        <tag>rxJava2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RxJava2源码解析(一)]]></title>
    <url>%2F2018%2F02%2F07%2FRxJava2%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%901%2F</url>
    <content type="text"><![CDATA[前言最近组内大佬打算分享RxJava2的源码, 赶紧先预习一波, 防止技术分享会上有听没懂.大概个人准备了几天的时间, 打算先整理以下自己的源码阅读记录.RxJava2的源码解析系列打算分别从以下三面来阐述: 数据源的订阅和响应原理 线程切换的原理 背压的实现(Flowable) 本篇主要尝试阐明数据源的订阅和响应原理 基础使用的Demo抛开线程切换和背压, 我们来写一个单纯的发送数据, 订阅响应的Demo,为了便于理解, 我们抛开链式调用来写123456789101112131415161718192021222324252627282930313233// 被观察者Observable&lt;Integer&gt; observable = Observable.create(new ObservableOnSubscribe&lt;Integer&gt;() &#123; @Override public void subscribe(ObservableEmitter&lt;Integer&gt; emitter) throws Exception &#123; Log.e(TAG, "subscribe"); emitter.onNext(123); emitter.onComplete(); &#125;&#125;);// 观察者Observer&lt;Integer&gt; observer = new Observer&lt;Integer&gt;() &#123; @Override public void onSubscribe(Disposable d) &#123; Log.e(TAG, "onSubscribe"); &#125; @Override public void onNext(Integer integer) &#123; Log.e(TAG, "onNext" + integer); &#125; @Override public void onError(Throwable e) &#123; Log.e(TAG, "onError"); &#125; @Override public void onComplete() &#123; Log.e(TAG, "onComplete"); &#125;&#125;;// 订阅observable.subscribe(observer); ObservableSource我们首先来看当我们创建一个Observable(被观察者)的时候, 实际上他做了什么12345678910111213public static &lt;T&gt; Observable&lt;T&gt; create(ObservableOnSubscribe&lt;T&gt; source) &#123; // npe校验 ObjectHelper.requireNonNull(source, "source is null"); return RxJavaPlugins.onAssembly(new ObservableCreate&lt;T&gt;(source)); &#125;public static &lt;T&gt; Observable&lt;T&gt; onAssembly(@NonNull Observable&lt;T&gt; source) &#123; Function&lt;? super Observable, ? extends Observable&gt; f = onObservableAssembly; if (f != null) &#123; return apply(f, source); &#125; return source;&#125; RxJavaPlugins.onAssembly()这个方法主要是为了hook使用, 本篇暂且不表. 所以这里Observable.create()返回的是一个ObervableCreate对象.它继承于Observable, 是ObservableSource的实现类 observable.subscribe(observer)我们主要看订阅的时候做了什么, 先上源码1234567891011121314151617181920212223public final void subscribe(Observer&lt;? super T&gt; observer) &#123; // npe校验 ObjectHelper.requireNonNull(observer, "observer is null"); try &#123; // hook, 主要返回的就是我们的observer observer = RxJavaPlugins.onSubscribe(this, observer); // npe校验 ObjectHelper.requireNonNull(observer, "Plugin returned null Observer"); subscribeActual(observer); &#125; catch (NullPointerException e) &#123; // NOPMD throw e; &#125; catch (Throwable e) &#123; Exceptions.throwIfFatal(e); // can't call onError because no way to know if a Disposable has been set or not // can't call onSubscribe because the call might have set a Subscription already RxJavaPlugins.onError(e); NullPointerException npe = new NullPointerException("Actually not, but can't throw other exceptions due to RS"); npe.initCause(e); throw npe; &#125; &#125; 可以看到这里实际执行的是subscribeActual(observer)这个方法, 这里调用是个抽象接口, 我们在ObervableCreate找具体的实现123456789101112131415@Overrideprotected void subscribeActual(Observer&lt;? super T&gt; observer) &#123; // 包装数据发射器 CreateEmitter&lt;T&gt; parent = new CreateEmitter&lt;T&gt;(observer); // 订阅监听 observer.onSubscribe(parent); try &#123; // 上游的执行 source.subscribe(parent); &#125; catch (Throwable ex) &#123; Exceptions.throwIfFatal(ex); parent.onError(ex); &#125; &#125; 12emitter.onNext(123);emitter.onComplete(); 从source.subscribe(parent);我们就会走到以下我们自己写的数据发送事件.这里的emitter通过源码我们可以看到是将observer包装后的CreateEmitter类对象, 我们在往里面看.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081static final class CreateEmitter&lt;T&gt; extends AtomicReference&lt;Disposable&gt; implements ObservableEmitter&lt;T&gt;, Disposable &#123; private static final long serialVersionUID = -3434801548987643227L; final Observer&lt;? super T&gt; observer; CreateEmitter(Observer&lt;? super T&gt; observer) &#123; this.observer = observer; &#125; @Override public void onNext(T t) &#123; if (t == null) &#123; onError(new NullPointerException("onNext called with null. Null values are generally not allowed in 2.x operators and sources.")); return; &#125; if (!isDisposed()) &#123; observer.onNext(t); &#125; &#125; @Override public void onError(Throwable t) &#123; if (!tryOnError(t)) &#123; RxJavaPlugins.onError(t); &#125; &#125; @Override public boolean tryOnError(Throwable t) &#123; if (t == null) &#123; t = new NullPointerException("onError called with null. Null values are generally not allowed in 2.x operators and sources."); &#125; if (!isDisposed()) &#123; try &#123; observer.onError(t); &#125; finally &#123; dispose(); &#125; return true; &#125; return false; &#125; @Override public void onComplete() &#123; if (!isDisposed()) &#123; try &#123; observer.onComplete(); &#125; finally &#123; dispose(); &#125; &#125; &#125; @Override public void setDisposable(Disposable d) &#123; DisposableHelper.set(this, d); &#125; @Override public void setCancellable(Cancellable c) &#123; setDisposable(new CancellableDisposable(c)); &#125; @Override public ObservableEmitter&lt;T&gt; serialize() &#123; return new SerializedEmitter&lt;T&gt;(this); &#125; @Override public void dispose() &#123; DisposableHelper.dispose(this); &#125; @Override public boolean isDisposed() &#123; return DisposableHelper.isDisposed(get()); &#125; &#125; 通过之前将observer传入CreateEmitter, 调用emitter.onNext最终调用走到了observer.onNext.整体的流程非常的清晰. 下面我们看下, 如果中间有多重数据转换, 是什么样的流程 数据转换实现流程以第一个基础demo为例, 我们改造下Observable(被观察者), 将他进行一次数据转换, 并且做一次筛除.这个demo的意思就是发送123, 中间做+1处理, 然后筛选出大于122的数据发送给观察者.这个很容易理解.123456789101112131415161718192021222324Observable&lt;Integer&gt; observable = Observable .create(new ObservableOnSubscribe&lt;Integer&gt;() &#123; @Override public void subscribe(ObservableEmitter&lt;Integer&gt; emitter) throws Exception &#123; Log.e(TAG, "subscribe"); emitter.onNext(123); emitter.onComplete(); &#125; &#125;) .map(new Function&lt;Integer, Integer&gt;() &#123; @Override public Integer apply(Integer integer) throws Exception &#123; Log.e(TAG, "map"); return integer + 1; &#125; &#125;) .filter(new Predicate&lt;Integer&gt;() &#123; @Override public boolean test(Integer integer) throws Exception &#123; Log.e(TAG, "filter"); return integer &gt; 122; &#125; &#125;); 我们依旧来看下map操作符的源码1234public final &lt;R&gt; Observable&lt;R&gt; map(Function&lt;? super T, ? extends R&gt; mapper) &#123; ObjectHelper.requireNonNull(mapper, "mapper is null"); return RxJavaPlugins.onAssembly(new ObservableMap&lt;T, R&gt;(this, mapper)); &#125; 是不是很眼熟? 忽略掉hook, 这里返回的是ObservableMap对象.同样, filter操作符返回的是一个ObservableFilter1234public final Observable&lt;T&gt; filter(Predicate&lt;? super T&gt; predicate) &#123; ObjectHelper.requireNonNull(predicate, "predicate is null"); return RxJavaPlugins.onAssembly(new ObservableFilter&lt;T&gt;(this, predicate)); &#125; 不论是ObservableMap还是ObservableFilter他们都继承于AbstractObservableWithUpstream抽象类, 它继承于Observable, 带有上游的Observable1234567891011121314151617181920abstract class AbstractObservableWithUpstream&lt;T, U&gt; extends Observable&lt;U&gt; implements HasUpstreamObservableSource&lt;T&gt; &#123; /** The source consumable Observable. */ // 上游Obervable protected final ObservableSource&lt;T&gt; source; /** * Constructs the ObservableSource with the given consumable. * @param source the consumable Observable */ AbstractObservableWithUpstream(ObservableSource&lt;T&gt; source) &#123; this.source = source; &#125; @Override public final ObservableSource&lt;T&gt; source() &#123; return source; &#125;&#125; 这时候, 我们重新看下订阅的处理, 当我们执行observable.subscribe(observer)的时候, observable最终返回的是ObservableFilter对象, 所以我们需要看这个类对象的subscribeActual(observer)方法.他的代码很简洁, 实际就是将我们的observer和filter操作符的具体操作方法包装成一个FilterObserver对象, 然后由上游ObservableMap对象来subscribe(订阅)它.1234@Override public void subscribeActual(Observer&lt;? super T&gt; s) &#123; source.subscribe(new FilterObserver&lt;T&gt;(s, predicate)); &#125; 我们已经知道Observable.subscribe(observer)方法实际调用的是对应实现类的subscribeActual(observer)方法, 所以我们直接去看ObservableMap.subscribeActual(observer)方法就可以了, 他的方法与FilterObserver内的类似, 这时候是将前面传进来的FilterObserver对象和我们map操作符做的操作包装成一个MapObserver对象, 交给上游.1234@Override public void subscribeActual(Observer&lt;? super U&gt; t) &#123; source.subscribe(new MapObserver&lt;T, U&gt;(t, function)); &#125; 这时候我们的上游是ObservableCreate对象,它的subscribeActual(observer)方法上文有提到, 他将MapObserver对象包装进CreateEmitter对象, 这个时候, 才开始执行订阅动作, 然后我们走到CreateEmitter的onNext()方法,实际会执行到下游观察者的onNext方法, 在这层, 我们的观察者是MapObserver.它继承于BasicFuseableObserver, 表示一个流程执行中间的观察者对象. 现在我们看MapObserver的onNext的执行, 这里我们主要关注主流程的执行逻辑, 忽略掉其他代码, 可以看到它最终调用的是actual.onNext(v), 首先将我们map操作符的逻辑处理返回的数据赋值给v, 这里的actual指的是我们下游的observer(观察者), 那么这个时候是我们的FilterObserver对象, 将v对象通过onNext传递下去.123456789101112131415161718192021222324252627282930313233343536373839404142static final class MapObserver&lt;T, U&gt; extends BasicFuseableObserver&lt;T, U&gt; &#123; final Function&lt;? super T, ? extends U&gt; mapper; MapObserver(Observer&lt;? super U&gt; actual, Function&lt;? super T, ? extends U&gt; mapper) &#123; super(actual); this.mapper = mapper; &#125; @Override public void onNext(T t) &#123; if (done) &#123; return; &#125; if (sourceMode != NONE) &#123; actual.onNext(null); return; &#125; U v; try &#123; v = ObjectHelper.requireNonNull(mapper.apply(t), "The mapper function returned a null value."); &#125; catch (Throwable ex) &#123; fail(ex); return; &#125; actual.onNext(v); &#125; @Override public int requestFusion(int mode) &#123; return transitiveBoundaryFusion(mode); &#125; @Nullable @Override public U poll() throws Exception &#123; T t = qs.poll(); return t != null ? ObjectHelper.&lt;U&gt;requireNonNull(mapper.apply(t), "The mapper function returned a null value.") : null; &#125; &#125; 然后我们看FilterObserver的源码, 他的onNext逻辑就是会执行我们传进去的Predicate对象的test方法, 如果符合筛选逻辑, 就会通过调用下游的onNext将数据传下去, 这个时候的下游是我们new的Observer, 这时候的执行,我们应该就清楚了.123456789101112131415161718192021222324252627282930313233343536373839404142static final class FilterObserver&lt;T&gt; extends BasicFuseableObserver&lt;T, T&gt; &#123; final Predicate&lt;? super T&gt; filter; FilterObserver(Observer&lt;? super T&gt; actual, Predicate&lt;? super T&gt; filter) &#123; super(actual); this.filter = filter; &#125; @Override public void onNext(T t) &#123; if (sourceMode == NONE) &#123; boolean b; try &#123; b = filter.test(t); &#125; catch (Throwable e) &#123; fail(e); return; &#125; if (b) &#123; actual.onNext(t); &#125; &#125; else &#123; actual.onNext(null); &#125; &#125; @Override public int requestFusion(int mode) &#123; return transitiveBoundaryFusion(mode); &#125; @Nullable @Override public T poll() throws Exception &#123; for (;;) &#123; T v = qs.poll(); if (v == null || filter.test(v)) &#123; return v; &#125; &#125; &#125; &#125; 总结订阅和数据的传输的原理就是如此. 我们用流程图来总结下上面的整个流程.总的来说, 订阅的动作是层层递归上传到最开始的Observable, 然后从最开始的Observable将数据一层层往下传.当然, 从装饰模式来讲, 他这里的实际动作就是将Observable做了层层装饰来传递订阅, 对设计模式有兴趣的同学可以看看相关的书籍, 对于理解这段代码有点睛之用]]></content>
      <categories>
        <category>源码解析</category>
      </categories>
      <tags>
        <tag>源码解析</tag>
        <tag>RxJava2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap源码解析(一)]]></title>
    <url>%2F2018%2F02%2F02%2FHashMap%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%901%2F</url>
    <content type="text"><![CDATA[前言本篇主要了解下HashMap的源码, 以便了解其常用方法的实现原理.本篇以android SDK API26内的Java源码为准 HashMap是什么HashMap是基于实现Map接口的哈希表, 但是他和HashTable有一定的区别, 主要区分在HashMap可以传null的键值对, 而且他不是线程安全的, 如果需要支持同步, 则需要调用Collections.synchronizedMap(Map&lt;K,V&gt; m)方法. 同时, HashMap不能保证时间推移下map内顺序不变. 构造函数国际惯例, 我们先看下他的构造函数, 他需要两个参数, 分别是初始容量initialCapacity(默认为 16)和负载因子loadFactor(默认为0.75f),奇怪的是, threshold的注释说明它应该是等于初始容量 * 负载因子, 而在tableSizeFor()方法的计算中, 我们获取到的是初始容量的两倍数据, 这点我们先压下疑问往后看12345678910111213public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; // threshold 表示下次需要扩容时的容纳最大值(初始容量 * 负载因子), 如果超出这个值, 则会进行扩容 this.threshold = tableSizeFor(initialCapacity); &#125; 这里threshold的计算方法, 我们姑且看下, MAXIMUM_CAPACITY为1&lt;&lt;30, 位移运算后值为$2^{29}$123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 这段代码的意思就是会获取等于或大于cap最小的2的幂次,我们以默认值默认值$2^4$为例尝试计算一下, 得到的结果是$2^5$. get(Object key)我们首先看下如果对HashMap进行查找.1234public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; 这里getNode才是真正用来实现Map.get的方法.要注意的是, 这里的定位哈希桶数组的位置的算法, 由于tab.length永远是2的幂次, 这里的(n - 1) &amp; hash就相当于hash % n的操作, 而&amp;比%具有更高的效率, 所以这里的位运算相当于是一个小的优化1234567891011121314151617181920212223242526272829303132/** * 实现map的get方法 * Implements Map.get and related methods * * @param hash hash for key key的hash值 * @param key the key key * @return the node, or null if none 返回目标节点, 如果没有则返回 */final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // tab为空, 并且获取到的目标节点不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 如果hash和key相同 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) // 返回目标节点 return first; if ((e = first.next) != null) &#123; // 红黑树情况 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 链表情况 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; put同样, put的实际实现是以下方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 如果tab为空, 则调用resize分配内存 if ((tab = table) == null || (n = tab.length) == 0)&#123; n = (tab = resize()).length; &#125; // 通过(n - 1) &amp; hash]获取存入位置, 得到插入位置中的节点p if ((p = tab[i = (n - 1) &amp; hash]) == null) // 节点p为空, 则直接插入 tab[i] = newNode(hash, key, value, null); else &#123; // 节点p不为空, 插入位置冲突 Node&lt;K,V&gt; e; K k; // 与当前节点第一个节点相同(hash和key都相同) if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))&#123; // 节点赋值tab[i] e = p; &#125; // 与第一个节点不相同 // 红黑树情况 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 链表情况 else &#123; // p从表头向后移动 for (int binCount = 0; ; ++binCount) &#123; // 如果移动到链表尾部 if ((e = p.next) == null) &#123; // 插入到尾部 p.next = newNode(hash, key, value, null); // 如果达到链-&gt;树阈值 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st // 替换红黑树 treeifyBin(tab, hash); break; &#125; // 找到目标相同节点(hash&amp;&amp;key) if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; // p后移 p = p.next p = e; &#125; &#125; // 处理hash和key相同的情况 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 如果size &gt; threshold时, 进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; put具体的流程图可以看下图 扩容resize该方法主要作用就是针对map进行容量初始化或者扩容双倍容量, 另外, 扩容之后, 需要重新计算键值对的位置, 并移动到目标位置上.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 超过最大容量, 无法扩容, 只能改变阈值 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 容量加倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // 阈值加倍 newThr = oldThr &lt;&lt; 1; // double threshold &#125; // 用阈值初始值新的容量 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; // 当阈值==0的时候 else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; // 将旧tab中的Node转移到新tab中, 分链表和红黑树两种情况 table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; resize做了两步工作, 一步是计算新的阈值和容量, 一步是键值对重新映射.之前我们有个疑问, 就是threshold的注释明明标注它说是等于初始容量*负载因子, 而在我们的tableSizeFor内并没有看到相关的逻辑代码, 这个问题就可以在这里得到解决.方法的前段逻辑如下: 判断当前哈希桶数组(oldCap)是否有值, 即哈希桶数组已经被初始化 有且长度超过最大值, 则不做扩容 有且没有超过最大值, 如果扩容后仍然小于最大值, 则做扩容处理 但是, 当哈希桶数组没有数据 初始阈值(oldThr)有值且大于0 , 哈希桶数组容量长度直接沿用老的阈值大小 初始阈值没有设置时, 阈值就会设为 加载因子 * 容量 如果新设置的阈值等于0, 则会赋值为加载因子 * 新的容量大小 removeNode删除的动作与上面的比较来说, 就容易理解了.主要可以分为三个动作: 寻找定位哈希桶数组索引位置 遍历链表找到键值相等的节点 删除目标节点 12345678910111213141516171819202122232425262728293031323334353637383940final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null; &#125; 总结本篇主要解释了几个常用方法的实现原理, 在此做下记录. 不过关于红黑树的相关知识, 就不在这里多加说明了.]]></content>
      <categories>
        <category>源码解析</category>
      </categories>
      <tags>
        <tag>源码解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LruCache解析]]></title>
    <url>%2F2018%2F01%2F31%2FLruCache%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言在学习Glide的时候, 我们会看到Glide的二级缓存, 分别分为内存缓存和磁盘缓存, 而不论哪种缓存都使用到了Lru算法, 本篇主要看一下Android里的LruCache的实现 Lrucache实现原理以v4包的LruCahce类源码为准, 我们先看下他的构造函数1234567public LruCache(int maxSize) &#123; if (maxSize &lt;= 0) &#123; throw new IllegalArgumentException("maxSize &lt;= 0"); &#125; this.maxSize = maxSize; this.map = new LinkedHashMap&lt;K, V&gt;(0, 0.75f, true); &#125; 主要关注的是,LruCache内部通过LinkedHashMap用来管理缓存列表, LinkedHashMap是一个由数组+双向链表的数据结构实现的(我们以api26代码为准)1234567891011121314151617181920212223/** * Constructs a new &#123;@code LinkedHashMap&#125; instance with the specified * capacity, load factor and a flag specifying the ordering behavior. * * @param initialCapacity * the initial capacity of this hash map. * @param loadFactor * the initial load factor. * @param accessOrder * &#123;@code true&#125; if the ordering should be done based on the last * access (from least-recently accessed to most-recently * accessed), and &#123;@code false&#125; if the ordering should be the * order in which the entries were inserted. * @throws IllegalArgumentException * when the capacity is less than zero or the load factor is * less or equal to zero. */ public LinkedHashMap( int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); init(); this.accessOrder = accessOrder; &#125; 它的构造函数中的accessOrder表示的是如果为true,则为访问顺序; 否则, 为插入顺序排序, 我们可以看下accessOrder的相关的处理逻辑, 当我们调用map.get(key)和map.put()的使用, 都会调用到afterNodeAccess()方法, 该方法的作用就是将命中获取的引用对象, 放到链表的尾部, 就是说明, LinkedHashMap本身每次访问读取的时候, 都会把读取到的值放在尾部, 那么越不常用的对象越会在链表的头部12345678public V get(Object key) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) return null; if (accessOrder) afterNodeAccess(e); return e.value; &#125; 这一段代码的处理就是判断目标节点的前后是否有对象, 摘除出目标节点, 将其放在last123456789101112131415161718192021222324void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last LinkedHashMapEntry&lt;K,V&gt; last; if (accessOrder &amp;&amp; (last = tail) != e) &#123; LinkedHashMapEntry&lt;K,V&gt; p = (LinkedHashMapEntry&lt;K,V&gt;)e, b = p.before, a = p.after; p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125; tail = p; ++modCount; &#125; &#125; 我们可以由此了解到LruCache类是通过LinkedHashMap来做缓存的Lru(Least Recently Used)管理, 我们在来看下LruCache的几个主要的方法 get()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public final V get(K key) &#123; if (key == null) &#123; throw new NullPointerException("key == null"); &#125; V mapValue; synchronized (this) &#123; // LinkedHashMap 的get(key)方法会重新链接排序 mapValue = map.get(key); if (mapValue != null) &#123; // 命中次数 hitCount++; return mapValue; &#125; // 非命中次数 missCount++; &#125; // create是个空方法, 可以自己实现 V createdValue = create(key); if (createdValue == null) &#123; return null; &#125; synchronized (this) &#123; createCount++; mapValue = map.put(key, createdValue); // 如果对应的key之前是有值, 说明是有冲突的 if (mapValue != null) &#123; // 有冲突的情况, 则替换为旧值 // There was a conflict so undo that last put map.put(key, mapValue); &#125; else &#123; size += safeSizeOf(key, createdValue); &#125; &#125; // 冲突的情况下 if (mapValue != null) &#123; entryRemoved(false, key, createdValue, mapValue); return mapValue; &#125; else &#123; trimToSize(maxSize); return createdValue; &#125; &#125; put()12345678910111213141516171819202122232425public final V put(K key, V value) &#123; if (key == null || value == null) &#123; throw new NullPointerException("key == null || value == null"); &#125; V previous; synchronized (this) &#123; // 缓存次数添加 putCount++; size += safeSizeOf(key, value); previous = map.put(key, value); // size是缓存大小数, 如果之前对应key有缓存的情况下, 缓存大小其实是不变的, 所以要减去原来的数 if (previous != null) &#123; size -= safeSizeOf(key, previous); &#125; &#125; if (previous != null) &#123; // 缓存被替换, 调用到的方法 entryRemoved(false, key, previous, value); &#125; trimToSize(maxSize); return previous; &#125; trimToSize()不论是get还是put还是设置最大缓存大小resize,我们都会调用到trimToSize方法, 这个方法就是用来处理当超出缓存大小要求的时候, 删除最老的缓存, 直到缓存大小低于要求1234567891011121314151617181920212223242526272829public void trimToSize(int maxSize) &#123; while (true) &#123; K key; V value; synchronized (this) &#123; if (size &lt; 0 || (map.isEmpty() &amp;&amp; size != 0)) &#123; throw new IllegalStateException(getClass().getName() + ".sizeOf() is reporting inconsistent results!"); &#125; if (size &lt;= maxSize || map.isEmpty()) &#123; break; &#125; Map.Entry&lt;K, V&gt; toEvict = map.entrySet().iterator().next(); key = toEvict.getKey(); value = toEvict.getValue(); // LinkedHashMap构造函数中的accessOrder字段为true, 表示有读取排序 // 从最少使用顺序排序到最多排序 // 所以移除第一个value, 等于是移除最少使用的缓存 // map存储缓存, 直接移除第一个 map.remove(key); size -= safeSizeOf(key, value); evictionCount++; &#125; entryRemoved(true, key, value, null); &#125; &#125; 总结现在, 我们可以了解到, 真正辅助LruCache实现它的算法的LinkedHashMap, 它会以读取的顺序来做顺序排序, 最近读取的在队尾, 当我们调用LruCache.put的时候, 将插入元素放在map队尾, 然后通过调用trimToSize判断是否超出缓存大小, 如果超出, 则移除map的队首对象.当我们调用LruCache.get的时候, 直接读取map对应key的value, 并由于LinkedHashMap的内部机制, 对读取顺序重排序, 将对应的元素更新到队尾]]></content>
      <categories>
        <category>源码解析</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>源码解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈谈GC和引用]]></title>
    <url>%2F2018%2F01%2F12%2F%E8%B0%88%E8%B0%88GC%E5%92%8C%E5%BC%95%E7%94%A8%2F</url>
    <content type="text"><![CDATA[前言A拿了一串代码和一篇文章来问我, ...当productA变为null时（表明它所引用的Product已经无需存在于内存中），这时指向这个Product对象的就是由弱引用对象weakProductA了，那么显然这时候相应的Product对象时弱可达的， 所以指向它的弱引用会被清除，这个Product对象随即会被回收，指向它的弱引用对象会进入引用队列中。 根据文章上述引用内容, 当他在执行下文代码的putnull方法时, 为什么userWeakReference.get()对象不为null, 难道userWeakReference.get() 和 user 不是一个对象吗?123456789101112131415161718192021222324252627282930313233343536public class MainActivity extends AppCompatActivity &#123; private User user; public static final int period = 2000; private WeakReference&lt;User&gt; userWeakReference; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); user = new User(); userWeakReference = new WeakReference&lt;&gt;(user); Observable.interval(period, TimeUnit.MILLISECONDS) .subscribe(new Consumer&lt;Long&gt;() &#123; @Override public void accept(Long aLong) throws Exception &#123; Log.d("gc", String.format("user is %s null", (null == user) ? "" : "not") + String.format(" ****" + " userWeakReference.get() is %s null", (null == userWeakReference.get()) ? "" : "not")); &#125; &#125;); &#125; public void putnull(View view) &#123; Log.i("gc", "============ user = null =============="); user = null; &#125; public void excutegc(View view) &#123; Log.i("gc", "========== gc done ============="); System.runFinalization(); System.gc(); &#125;&#125; 我们不妨先看下打印日志当user为空的时候, userWeakReference.get()不为空, 直到GC以后, 才为空. 对象的初始化这个问题的道理其实很简单.首先我们来看下下面代码的含义1User user = new User(); 当虚拟机遇到一条new指令的时候, 在类加载检查通过以后, 会为新生对象分配内存, 然后将分配到的内存空间都初始化为零值, 然后通过对象头(Object Header)对对象进行一些必要的设置(譬如对象GC分代年龄等等), 最后, 把对象按照程序员的意愿进行初始化(执行&lt;init&gt;方法), 这个时候, 从Java程序角度上来讲, 一个新的对象就产生了.而user这个引用变量通过=指向的就是这个新生成的对象的内存地址. 需要注意的是, 真正的对象是new User(), 而user表示的是引用. 这时候当我们执行下面的代码1user = null; null既不是对象, 也不是类型, 它是一种特殊的值, 这里可以表示为user引用没有指向任何对象.但是从内存分配上来说, new User()这个对象仍然存在, 只是没有引用指向它.1234567891011/** * Returns this reference object's referent. If this reference object has * been cleared, either by the program or by the garbage collector, then * this method returns &lt;code&gt;null&lt;/code&gt;. * * @return The object to which this reference refers, or * &lt;code&gt;null&lt;/code&gt; if this reference object has been cleared */ public T get() &#123; return getReferent(); &#125; 然后我们看下Reference.get()返回的是什么, 这个源码的注释给了我们答案, 它指向目标引用地址.那么我们就可以解释, 为什么user为空的时候, userWeakReference.get()仍然不为空. GC我们先复习下GC的一些基础知识 如何判断对象可回收在当前常用的虚拟机, 都是使用可达性分析算法, 通过可达判断(GC Root作为起始点, 引用链向下搜索, 如果对象和GC Root之前没有引用链, 则认为不可达, 即GC可回收)GC是否可以回收.GC Roots的对象可包括以下几种: 虚拟机栈中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI(Native方法)引用的对象 引用级别同样, 我们在看下WeakReference是什么. 在判断对象的引用链是否可达的时候, 我们都需要用到引用.引用级别可分为四层, 引用强度分别自强到弱 强引用: 代码中最常见的, 譬如上面的user就是强引用, 强引用只要存在, GC就永远不会回收它 软引用SoftReference: 软引用只有在内存不足时, GC才会回收. 当要发生OOM的时候, GC会把这些对象列进回收范围进行第二次回收, 如果这次回收后还是没有足够的内存, 则会报OOM 弱引用WeakReference: 无论内存是否足够, GC肯定会回收. 所以弱引用关联的对象无法存活到下一次GC.LeakCanary就是通过使用WeakReference和引用队列通过二次回收判定来判断是否存在内存泄漏. 虚引用PhantomReference:最弱的一种引用关系, 一个对象是否有虚引用的存在, 完全不会对其生存时间构成影响, 也无法通过虚引用来取得一个对象实例。他存在的唯一目的即是能在这个对象被收集器回收时受到一个系统通知. 结论 由此可以理解, 当发生GC时, WeakReference引用相关的对象就不会再存活, 这也是为什么,上面的代码里, 要等到GC发生后userWeakReference.get()才为空. 从这个问题我们引申出来的还是比较基础的东西, 不过不妨碍我们再去做一次巩固.]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Enum的正确使用方式]]></title>
    <url>%2F2017%2F12%2F26%2FEnum%E7%9A%84%E6%AD%A3%E7%A1%AE%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[前言看到目前项目里用到蛮多枚举, 才有了这篇小文章分享 为什么使用Enumjava中的Enum是包含固定常量集的数据类型.当我们需要预定义一组代表某种数据的值时一般都会使用枚举, 而当要保证类型安全时, 我们经常会使用Enum。 比如, 当我们要保证常量使用正常时, 我们经常使用Enum在编译时校验确保类型安全 使用Enum的缺点在Android开发者官网上, 有这样一段话 enums often require more than twice as much memory as static constants. You should strictly avoid using enums on Android. Enum中的每个值都是一个对象,每个声明都将使用一些运行时内存来简单引用该对象,所以Enum相较于static int会占用更多的内存. 另外添加单个Enum将增加最终DEX文件的大小（是static int的13倍）. 解决方案Google提供了注解库通过Typedef协助我们解决了Enum的问题,它可以确保特定参数, 返回值或字段引用特定的常量集,还可以完成代码以自动提供允许的常量. 我们可以通过使用@IntDef和@StringDef来帮助我们在编译时检查像Enum这项的变量赋值. 使用姿势 首先我们需要依赖注解库 1dependencies &#123;compile 'com.android.support:support-annotations:24.2.0'&#125; 直接上代码了, 因为还是蛮简单的 12345678910111213141516171819202122232425public class Person &#123; public static final int MALE = 0; public static final int FEMALE = 1; private int sex; public String getSexValue()&#123; if(MALE == sex)&#123; return "男"; &#125;else if(FEMALE == sex)&#123; return "女"; &#125; return ""; &#125; public void setSex(@sexDef int sex) &#123; this.sex = sex; &#125; // 定义该注解被保留的时间长短 // RetentionPolicy.CLASS 注解被保留到class文件, 但jvm加载class文件时候被遗弃, 这是默认生命周期; 用于在编译时进行一些预处理操作, 比如生成一些辅助代码(ButterKnife) // RetentionPolicy.RUNTIME 注解不仅被保存到class文件中, jvm加载class文件之后, 仍然存在;用于在运行时去动态获取注解信息 // RetentionPolicy.SOURCE 注解只保留在源文件, 当Java文件编译成class文件的时候, 注解被遗弃; 用于做一些检查性操作 @Retention(RetentionPolicy.SOURCE) // 使用@IntDef定义声明常量作为枚举 @IntDef(&#123;MALE, FEMALE&#125;) // 使用@interface声明新的枚举注解类型 public @interface sexDef&#123;&#125; &#125; 当我们调用setSex设置性别的时候, 如果输入非指定类型, 则编译不会通过 总结与普通static常量相比, Enum的使用至少为整个apk添加至少两倍以上的字节数，并且使用5到10倍的RAM内存。所以建议尽量避免使用Enum, 当需要使用上述特性时,建议以@IntDef 或 @StringDef 替代使用。 更多的可以看看[The price of ENUMs][https://www.youtube.com/watch?v=Hzs6OBcvNQE&amp;feature=youtu.be]视频, 需科学上网]]></content>
      <categories>
        <category>android学习记录</category>
      </categories>
      <tags>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Glide源码解析]]></title>
    <url>%2F2017%2F12%2F22%2FGlide%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%901%2F</url>
    <content type="text"><![CDATA[基于v4最新版本的Glide解析, 从最开始的简单加载开始看源码, 仅作个人记录.一个Glide加载图片的核心用法如下:123GlideApp.with(this) .load(uri) .into(imageViewLookup); 我们通过一步步链式调用进去查看 Glide.with : 同步生命周期12345678910111213private RequestManager supportFragmentGet(@NonNull Context context, @NonNull FragmentManager fm, @Nullable Fragment parentHint) &#123; SupportRequestManagerFragment current = getSupportRequestManagerFragment(fm, parentHint); RequestManager requestManager = current.getRequestManager(); if (requestManager == null) &#123; Glide glide = Glide.get(context); requestManager = factory.build( glide, current.getGlideLifecycle(), current.getRequestManagerTreeNode(), context); current.setRequestManager(requestManager); &#125; return requestManager; &#125; 通过getSupportRequestManagerFragment(final FragmentManager fm, Fragment parentHint)方法调用, 在Glide.with(context)中传入的组件中,新增一个子Fragment, 这个Fragment类根据传入的是support.fragment或者是fragment来决定是RequestManagerFragment还是SupportRequestManagerFragment,然后通过current.SupportRequestManagerFragment() 将Glide的生命周期与这个子fragment的声明周期绑定, 实现了组件与Glide加载同步的功能 图片的加载我们通过暴露的into的API跳进去, 最终到了RequestBuilder.into(@NonNull Y target, @Nullable RequestListener&lt;TranscodeType&gt; targetListener, @NonNull RequestOptions options), 详细代码如下:123456789101112131415161718192021222324252627282930313233343536373839404142private &lt;Y extends Target&lt;TranscodeType&gt;&gt; Y into( @NonNull Y target, @Nullable RequestListener&lt;TranscodeType&gt; targetListener, @NonNull RequestOptions options) &#123; // 判断是否在主线程 Util.assertMainThread(); // target是否为空判断 Preconditions.checkNotNull(target); // load()方法是否已经被调用, 如果没被调用, 则将抛出异常 if (!isModelSet) &#123; throw new IllegalArgumentException("You must call #load() before calling #into()"); &#125; options = options.autoClone(); // 创建请求 Request request = buildRequest(target, targetListener, options); // 获取target当前的请求 Request previous = target.getRequest(); // 如果请求相同, 而且当前请求设置可以使用内存缓存 // 则请求回收 if (request.isEquivalentTo(previous) &amp;&amp; !isSkipMemoryCacheWithCompletePreviousRequest(options, previous)) &#123; request.recycle(); // If the request is completed, beginning again will ensure the result is re-delivered, // triggering RequestListeners and Targets. If the request is failed, beginning again will // restart the request, giving it another chance to complete. If the request is already // running, we can let it continue running without interruption. // 如果当前请求不在执行, 则会重新开始请求 if (!Preconditions.checkNotNull(previous).isRunning()) &#123; // Use the previous request rather than the new one to allow for optimizations like skipping // setting placeholders, tracking and un-tracking Targets, and obtaining View dimensions // that are done in the individual Request. previous.begin(); &#125; return target; &#125; requestManager.clear(target); target.setRequest(request); // 请求追踪 requestManager.track(target, request); return target; &#125; 然后通过requestManager.track()发起Request执行, 如果当前状态(status)既不是RUNNING也不是COMPLETE, 则会执行onSizeReady, 到这里直到Engine.load()才开始资源的加载, 相关的代码及注释如下:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102public &lt;R&gt; LoadStatus load( GlideContext glideContext, Object model, Key signature, int width, int height, Class&lt;?&gt; resourceClass, Class&lt;R&gt; transcodeClass, Priority priority, DiskCacheStrategy diskCacheStrategy, Map&lt;Class&lt;?&gt;, Transformation&lt;?&gt;&gt; transformations, boolean isTransformationRequired, boolean isScaleOnlyOrNoTransform, Options options, boolean isMemoryCacheable, boolean useUnlimitedSourceExecutorPool, boolean useAnimationPool, boolean onlyRetrieveFromCache, ResourceCallback cb) &#123; Util.assertMainThread(); long startTime = LogTime.getLogTime(); // 创建缓存key EngineKey key = keyFactory.buildKey(model, signature, width, height, transformations, resourceClass, transcodeClass, options); // 从存活资源内读取数据, 内部缓存由value为弱引用对象的map做管理, 做手动的计数管理 // 当资源计数为0时, 则回收 EngineResource&lt;?&gt; active = loadFromActiveResources(key, isMemoryCacheable); if (active != null) &#123; // 如果命中, 则回调加载 cb.onResourceReady(active, DataSource.MEMORY_CACHE); if (Log.isLoggable(TAG, Log.VERBOSE)) &#123; logWithTimeAndKey("Loaded resource from active resources", startTime, key); &#125; return null; &#125; // 获取内存缓存数据 // 当内存缓存中有命中, 则删除Cache, 并将目标资源加到activeResources中 EngineResource&lt;?&gt; cached = loadFromCache(key, isMemoryCacheable); if (cached != null) &#123; // 如果命中, 则回调加载 cb.onResourceReady(cached, DataSource.MEMORY_CACHE); if (Log.isLoggable(TAG, Log.VERBOSE)) &#123; logWithTimeAndKey("Loaded resource from cache", startTime, key); &#125; return null; &#125; // EngineJob : 调度DecodeJob，添加，移除资源回调，并notify回调 EngineJob&lt;?&gt; current = jobs.get(key, onlyRetrieveFromCache); // 当前存活的资源和内存缓存都没有的情况下 // 1. 先判断是否有资源(resouce什么时候回调true 不明), 如果有, 则回调加载 // 2. 如果加载失败, 则加载抛出异常 // 3. 否则, 在资源回调中添加 if (current != null) &#123; current.addCallback(cb); if (Log.isLoggable(TAG, Log.VERBOSE)) &#123; logWithTimeAndKey("Added to existing load", startTime, key); &#125; // 返回当前的LoadStatus return new LoadStatus(cb, current); &#125; // 当资源回调中都没有的情况 EngineJob&lt;R&gt; engineJob = engineJobFactory.build( key, isMemoryCacheable, useUnlimitedSourceExecutorPool, useAnimationPool, onlyRetrieveFromCache); // 实现了Runnable接口，调度任务的核心类，整个请求的繁重工作都在这里完成：处理来自缓存或者原始的资源，应用转换动画以及transcode。 // 负责根据缓存类型获取不同的Generator加载数据，数据加载成功后回调DecodeJob的onDataFetcherReady方法对资源进行处理 DecodeJob&lt;R&gt; decodeJob = decodeJobFactory.build( glideContext, model, key, signature, width, height, resourceClass, transcodeClass, priority, diskCacheStrategy, transformations, isTransformationRequired, isScaleOnlyOrNoTransform, onlyRetrieveFromCache, options, engineJob); jobs.put(key, engineJob); engineJob.addCallback(cb); engineJob.start(decodeJob); if (Log.isLoggable(TAG, Log.VERBOSE)) &#123; logWithTimeAndKey("Started new load", startTime, key); &#125; return new LoadStatus(cb, engineJob); &#125; 这里的流程图可以看下图: 资源图片的缓存当无法再当前存活的资源以及缓存内找到对应key的资源时, 会通过engineJob开始执行decodeJob, 所以我们可以直接看decodeJob的run().123456789101112131415161718192021222324/** * 根据不同的runReason执行不同任务 */ private void runWrapped() &#123; switch (runReason) &#123; // 首次请求时 case INITIALIZE: stage = getNextStage(Stage.INITIALIZE); currentGenerator = getNextGenerator(); // load数据 runGenerators(); break; case SWITCH_TO_SOURCE_SERVICE: // load数据 runGenerators(); break; case DECODE_DATA: // 数据处理 decodeFromRetrievedData(); break; default: throw new IllegalStateException("Unrecognized run reason: " + runReason); &#125; &#125; 核心的执行流程如下代码:1234567891011121314151617181920212223242526272829/** * 执行Generators */ private void runGenerators() &#123; // 获取当前线程 currentThread = Thread.currentThread(); startFetchTime = LogTime.getLogTime(); boolean isStarted = false; // currentGenerator.startNext() : 从当前策略对应的Generator获取数据，数据获取成功则回调DecodeJob的onDataFetcherReady对资源进行处理。否则尝试从下一个策略的Generator获取数据 while (!isCancelled &amp;&amp; currentGenerator != null &amp;&amp; !(isStarted = currentGenerator.startNext())) &#123; stage = getNextStage(stage); // 根据Stage获取到相应的Generator后会执行currentGenerator.startNext()，如果中途startNext返回true，则直接回调，否则最终会得到SOURCE的stage，重新调度任务 currentGenerator = getNextGenerator(); if (stage == Stage.SOURCE) &#123; // 重新调度当前任务 reschedule(); return; &#125; &#125; // We've run out of stages and generators, give up. if ((stage == Stage.FINISHED || isCancelled) &amp;&amp; !isStarted) &#123; notifyFailed(); &#125; // Otherwise a generator started a new load and we expect to be called back in // onDataFetcherReady. &#125; 我们看下DecodeJob的执行流程 总结到这里, 整体的流程大致是搞清楚了, 至于说是缓存的原理机制, 在之前Engine.load()的方法内, 删除缓存的方法进去可以看到一个LruCache的类文件, 从名字可以推断是Glide自己实现的Lru算法作为缓存的处理, 关于Lru的算法原理, 在本篇内就不再做赘述了, 而ActiveCache用到了引用计数算法.Glide用到了大量的抽象工厂类, 另外方法内经常是包括了十来个参数, 在阅读的经过上还是有点困难(对我而言).相应的代码注释可看Github上我补充的注释]]></content>
      <categories>
        <category>android学习记录</category>
        <category>源码解析</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>源码解析</tag>
        <tag>Glide</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ObjectBox-Java (android)使用手册]]></title>
    <url>%2F2017%2F12%2F19%2FObjectBox%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[前前言本篇主要是方便自己记忆所写, 基本是撸完官方文档后的笔记 前言ObjectBox是一款由greenrobot出的基于noSql的ORM数据库, 但又支持表关系的定义以及事务的处理, 另外在性能上有着非常卓越的表现(关于性能比较, 可以看这篇),同时可以接入rxJava的扩展库, 并与google最新出的框架组件(Android Architecture Components)中的LiveData结合使用, 支持Kotlin.目前版本更新到1.2.1 依赖 在项目根目录的gradle添加它的依赖仓库地址 1234567891011121314151617buildscript &#123; ext.objectboxVersion = '1.2.1' repositories &#123; jcenter() maven &#123; url "http://objectbox.net/beta-repo/" &#125; &#125; dependencies &#123; classpath 'com.android.tools.build:gradle:2.3.3' classpath "io.objectbox:objectbox-gradle-plugin:$objectboxVersion" &#125;&#125;allprojects &#123; repositories &#123; jcenter() maven &#123; url "http://objectbox.net/beta-repo/" &#125; &#125;&#125; 在应用项目模块(app module)中添加插件 12apply plugin: 'com.android.application'apply plugin: 'io.objectbox' 基本使用 准备ObjectBox对象单例并实例化, 可以放在application的onCreate()中 12// MyObjectBox类文件这时候是引用不到, 它是根据实体类自动生成(build), 用来设置BoxStore对象boxStore = MyObjectBox.builder().androidContext(applicationContext).build(); 添加一个对象类, 添加@Entity注解, 进行表映射 1234567891011@Entitypublic class User&#123; // 主键, 必须有, 并且必须是long类型 @Id private long id; private String userName; private int userAge; // 必须有 public User()&#123;&#125;&#125; P.S 这时候记得build一下, MyObjectBox就自动生成了 这时候我们就可以通过Box&lt;User&gt;对象来针对这张表做增删改查工作了1Box&lt;User&gt; userBox = boxStore.boxFor(User.class).build(); 增删改查Box分别有put 添加or修改, query 查找, remove 移除 等开放API可调用.在调用put时, 当Entity的Id不设置, 则会自动为其赋值, 并新增数据. 当有设置Id, 并在表内有对应Id, 则会被覆盖, 相当于更新对应数据.另外关于@Id,有几点需要注意: 0和-1(0xFFFFFFFFFFFFFFFF)不能作为Id的值使用 0 或者null(如果类型是Long, 但不建议使用Long, 使用long的速度会更快)会是通知永远新增一笔新数据 如果put一个id比当前最大id大的对象, ObjectBox可能会抛出异常 如果要自己分配id, 可以使用注解@Id(assignable = true) 相关的方法, 可以参考JavaDoc中关于Box和QueryBuilder类中的方法 注解除了本文其他地方已提到的注解, 补充几个比较大概率会用到的, 其他的建议大家可以看看JavaDoc中的io.objectbox.annotation包:123456789101112@Entitypublic class User&#123; @Id private long id; @Index private String uid; @NameInDb("userName") private String name; @Transient private boolean country;&#125; @Index: 因为在ObjectBox中主键是必须设置为long类型的id, 当我们业务上需要另外主键时, 可以再标注@Index, 在ObjectBox中查询时根据他标注的字段来查询, 会加快查询速度 @NameInDb: 字段在数据库中的命名 @Transient: 忽略字段, 不在表中生成 数据迁移ObjectBox可以实现大部分的数据迁移自动化, 当我们要删除或者新增一个字段的时候, 针对数据库我们是不需要做任何操作的. 但是当我们需要重命名字段名或者表名, 或者需要更改字段类型时, 我们需要使用@Uid通知ObjectBox 下面我们会分别举两个例子: 重命名操作, 实体类重命名或者字段重命名操作流程都一样, 区别只在于是在在哪里放@Uid, 以实体类重命名为例: 在类名上添加@Uid 1234567891011@Entity@Uidpublic class User&#123; @Id private long id; private String userName; private int userAge; public User()&#123;&#125;&#125; rebuild一下, 在Gradle Console中会找到下面类似一段 123 错误: [ObjectBox] UID operations for entity &quot;User2&quot;: [Rename] apply the current UID using @Uid(6966387148602341622L) - [Change/reset] apply a new UID using @Uid(2383770126231565339L)1 个错误 copy [Rename]的@Uid值6966387148602341622L, 并针对实体类进行重命名 1234567891011@Entity@Uid(6966387148602341622L)public class User2&#123; @Id private long id; private String userName; private int userAge; public User2()&#123;&#125;&#125; 重新编译, 就已经迁移成功, 这时候@Uid(6966387148602341622L)这条代码就没有用了, 相关记录会在objectbox-models/default.json中体现 变更字段类型, 要注意的是, 会导致原类型字段Column的数据会被清空, 大体流程与重命名流程大致相同, 但是赋值的@Uid 需要使用的是[Change/reset]的值, 表示是一个新字段. P.S 前文提到了objectbox-models/default.json这个JSON文件, 这个文件相当于是我们做Migration时处理的文件记录, 所以是需要加入VCS控制 关系 以后补充 事务ObjectBox的所有操作都是在事务中运行的, 只是这个对我们来说是透明的, 我们不需要关注, 但是当我们需要进行多个操作的时候, 通过显示事务来控制, 可以大大提高app的效率和一致性.在BoxStore中, 提供了四个方法来执行显示事务: runInReadTx : 在事务中运行给定的Runnable, 不可并发处理 runIxTx : 只读事务, 可以并发处理 runInTxAsync : 在单独的线程中运行, 事务完成后会回调callback(可能为空) callInTx : 和runIxTx类似, 不过允许返回值并可以抛出一个异常 要注意的是, 事务的提交开销较大, 所以在使用隐式事务时, 譬如大批量调用put时, 我们需要统一写到一个事务里去提交1234for(User user: userList)&#123; user.plusAge(); box.put(user);&#125; 以上的demo我们应该优化为下面这种:1234for(User user: userList)&#123; user.plusAge();&#125;box.put(userList); 数据库查看 在项目app gradle文件中, 必须在&#39;io.objectbox&#39;插件apply之前依赖一下代码 12debugCompile "io.objectbox:objectbox-android-objectbrowser:1.2.1"releaseCompile "io.objectbox:objectbox-android:1.2.1" 清单文件申请权限 1&lt;uses-permission android:name="android.permission.INTERNET"/&gt; 然后在BoxStore构建之后, 加入以下代码 123if(BuildConfig.DEBUG)&#123; new AndroidObjectBrowser(boxStore).start(this); &#125; 运行后, 就可以从设备的通知栏点击进入查看数据库, 也可以通过在cmd中输入adb forward tcp:8090 tcp:8090, 打开浏览器, 输入http://localhost:8090/index.html 网址查看 后记关于它和rxJava如何使用, 如何做数据的观测, 以及和LiveData的搭配使用, 鉴于目前篇幅过长, 而且LiveData我目前还没有玩过, 所以暂时不写. 后续可能会新补一篇. 具体可以看Demo]]></content>
      <categories>
        <category>android学习记录</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>ObjectBox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用gradle多aar发布私有maven]]></title>
    <url>%2F2017%2F12%2F19%2F%E5%9F%BA%E4%BA%8Eas3.0%20%E5%A4%9Aaar%E6%89%93%E5%8C%85%E5%8F%91%E5%B8%83%2F</url>
    <content type="text"><![CDATA[前言为了精简目前底层的基础组件库, 拆分出必要依赖项目(有一定精简)和完全的依赖项目,第一想法是在library上构建变种(Variant)版本, 一次发布所有的变种,在研究了一些相关的资料后,最后完美解决 基础部署到maven仓库我们可以通过gradle部署到远程或者本地的maven仓库,首先添加maven插件, 然后我们通过updaloadArchives任务自动生成POM文件, 并打包部署到指定的仓库中 12345678apply plugin: &apos;maven&apos; // 添加maven插件uploadArchives &#123; repositories &#123; mavenDeployer &#123; repository(url: &quot;maven仓库地址&quot;) &#125; &#125; &#125; 当然我们也可以通过authentication来添加服务器的认证信息, 也可以定义快照(snapshot)仓库123456789101112apply plugin: &apos;maven&apos; // 添加maven插件uploadArchives &#123; repositories &#123; mavenDeployer &#123; repository(url: &quot;maven仓库地址&quot;)&#123; authentication(userName: &quot;yourUserName&quot;, password: &quot;yourPsw&quot;) &#125; snapshotRepository(url: &quot;maven snapshot仓库地址&quot;)&#123; authentication(userName: &quot;yourUserName&quot;, password: &quot;yourPsw&quot;) &#125; &#125; &#125; POM文件的自定义我们可以针对POM做自定义处理, 最常见的就是设置版本号等等123456789101112apply plugin: &apos;maven&apos; // 添加maven插件uploadArchives &#123; repositories &#123; mavenDeployer &#123; repository(url: &quot;maven仓库地址&quot;) &#125; pom.groupId = &quot;com.maven.test&quot; pom.artifactId = &quot;myLibrary&quot; pom.version = &quot;1.0.0&quot; pom.packaging = &quot;aar&quot; &#125; &#125; 针对上面的设置, 我们依赖引用的就应该是1implementation &quot;com.maven.test:myLibrary:1.0.0&quot; Maven默认每个项目只会处理一个artifact, 当我们library没有设置productFlavor和buildType时, 默认上传的是release的variant.当我们两个variant代码不同, 依赖不同时, 需要生产不同的POM进行上传,这种情况下我们需要显示声明每个artifact, 并针对每个POM进行自定义上传.在这方面我们可以分别参考MavenDeployer和MavenPom开放的API1234567891011121314151617181920212223242526272829303132333435363738394041424344// 上略mavenDeployer &#123; repository(url: &quot;仓库地址&quot;) android.libraryVariants.all &#123;variant-&gt; def isFlavor = !variant.flavorName.isEmpty() def _name = &quot;$&#123;variant.name&#125;&quot; // 生成多个pom addFilter(_name)&#123;artifact, file-&gt; true &#125; // 对应pom属性设置 pom(_name).artifactId = project.archivesBaseName + &quot;-&quot; + _name pom(_name).version = &quot;1.0.0&quot; pom(_name).groupId = &quot;com.maven.test&quot; pom(_name).packaging = &apos;aar&apos; // 自定义pom的依赖集 pom(_name).withXml&#123; def root = asNode() def depsNode = root[&quot;dependencies&quot;][0] ?: root.appendNode(&quot;dependencies&quot;) def addDep = &#123; if (it.group == null) return // Avoid empty dependency nodes def dependencyNode = depsNode.appendNode(&apos;dependency&apos;) dependencyNode.appendNode(&apos;groupId&apos;, it.group) dependencyNode.appendNode(&apos;artifactId&apos;, it.name) dependencyNode.appendNode(&apos;version&apos;, it.version) if (it.hasProperty(&apos;optional&apos;) &amp;&amp; it.optional) &#123; dependencyNode.appendNode(&apos;optional&apos;, &apos;true&apos;) &#125; &#125; // 添加基本依赖 configurations.api.allDependencies.each addDep configurations.implementation.allDependencies.each addDep // 添加特殊依赖 if (isFlavor) &#123; configurations[&quot;$&#123;_name&#125;Implementation&quot;].allDependencies.each addDep def flavorName = variant.flavorName configurations[&quot;$&#123;flavorName&#125;Implementation&quot;].allDependencies.each addDep configurations[&quot;$&#123;_name&#125;Api&quot;].allDependencies.each addDep configurations[&quot;$&#123;flavorName&#125;Api&quot;].allDependencies.each addDep &#125; &#125; &#125; &#125; 相关demo可以看这里 依赖对应的组件库在成功发布后, 我们仓库内容应该如下图 假设我们的flavor分别为full和simple,当我们去依赖的时候, 就可以通过12releaseImplementation &quot;com.maven.test:libraryNameFullRelease:1.0.0&quot;debugImplementation &quot;com.maven.test:libraryNameFullDebug:1.0.0&quot;]]></content>
      <categories>
        <category>android学习记录</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>gradle</tag>
      </tags>
  </entry>
</search>
